[Embedding Output] Shape: (1, 3, 768)
[Embedding Output] Token 0 First 3: [-2.4773023  -1.2636504   0.38269287]
[Embedding Output] Token 0 Last 3: [ 0.56940025 -0.4918722   0.05794763]
[Embedding Output] Token 1 First 3: [-0.47206733 -0.11836139 -2.429505  ]
[Embedding Output] Token 1 Last 3: [ 2.0445411  -0.3396468  -0.59749377]
[Embedding Output] Token 2 First 3: [-0.40647197  1.5855645  -3.363341  ]
[Embedding Output] Token 2 Last 3: [ 5.721009   3.1960166 -1.2484151]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-2.0524375 -1.0469306  0.3170599]
[RMSNorm(raw)] Token 0 Last 3: [ 0.47174639 -0.40751463  0.04800944]
[RMSNorm(raw)] Token 1 First 3: [-0.27921414 -0.07000733 -1.4369818 ]
[RMSNorm(raw)] Token 1 Last 3: [ 1.2092868  -0.20089123 -0.35340026]
[RMSNorm(raw)] Token 2 First 3: [-0.21069618  0.82188296 -1.7433997 ]
[RMSNorm(raw)] Token 2 Last 3: [ 2.9655051   1.6566664  -0.64712036]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [13.771751 11.625393 10.998746]
[RMSNorm(weight)] Last 3: [28.65078  11.849464 11.724117]
--------------------
[layer0_attention_norm] Shape: (1, 3, 768)
[layer0_attention_norm] Token 0 First 3: [-30.318098  -13.21791     3.8043213]
[layer0_attention_norm] Token 0 Last 3: [13.987648  -5.236345   0.6108777]
[layer0_attention_norm] Token 1 First 3: [ -4.124482    -0.88387007 -17.24198   ]
[layer0_attention_norm] Token 1 Last 3: [35.856297  -2.5813446 -4.4967065]
[layer0_attention_norm] Token 2 First 3: [ -3.1123514  10.3765955 -20.91861  ]
[layer0_attention_norm] Token 2 Last 3: [87.92954   21.287275  -8.2340355]
--------------------
[layer0_attention_norm] Shape: (1, 3, 768)
[layer0_attention_norm] Token 0 First 3: [-30.318098  -13.21791     3.8043213]
[layer0_attention_norm] Token 0 Last 3: [13.987648  -5.236345   0.6108777]
[layer0_attention_norm] Token 1 First 3: [ -4.124482    -0.88387007 -17.24198   ]
[layer0_attention_norm] Token 1 Last 3: [35.856297  -2.5813446 -4.4967065]
[layer0_attention_norm] Token 2 First 3: [ -3.1123514  10.3765955 -20.91861  ]
[layer0_attention_norm] Token 2 Last 3: [87.92954   21.287275  -8.2340355]
--------------------
[layer0_wq_weight] Shape: (768, 768)
[layer0_wq_weight] First 3: [ 0.00445754 -0.00865422 -0.00513644]
[layer0_wq_weight] Last 3: [ 0.00634343  0.00257639 -0.00143187]
--------------------
[layer0_wk_weight] Shape: (768, 256)
[layer0_wk_weight] First 3: [ 0.01747953  0.01080757 -0.00312103]
[layer0_wk_weight] Last 3: [-0.00118842  0.00795038  0.01187154]
--------------------
[layer0_wv_weight] Shape: (768, 256)
[layer0_wv_weight] First 3: [ 0.01653893  0.01165733 -0.00459494]
[layer0_wv_weight] Last 3: [0.00102983 0.0020934  0.01529037]
--------------------
[layer0_wq] Shape: (1, 3, 768)
[layer0_wq] Token 0 First 3: [ 0.38878322  3.3515396  -3.145893  ]
[layer0_wq] Token 0 Last 3: [-1.575072   4.6258264 -7.586489 ]
[layer0_wq] Token 1 First 3: [ 20.873734  -10.324043    2.4454143]
[layer0_wq] Token 1 Last 3: [-1.0839994  1.4893976  4.9638634]
[layer0_wq] Token 2 First 3: [-1.6471853  2.9702644 -4.8156204]
[layer0_wq] Token 2 Last 3: [ 1.2293016  -0.23432428 -0.27904558]
--------------------
[layer0_wk] Shape: (1, 3, 256)
[layer0_wk] Token 0 First 3: [0.94825447 0.5784214  0.1543442 ]
[layer0_wk] Token 0 Last 3: [0.31736666 0.30611068 3.1419642 ]
[layer0_wk] Token 1 First 3: [ 8.656712  12.975434   7.8711734]
[layer0_wk] Token 1 Last 3: [1.1842489 1.3707243 7.117685 ]
[layer0_wk] Token 2 First 3: [ 2.791897 -4.009481 -4.848618]
[layer0_wk] Token 2 Last 3: [ 3.1282878 -1.7282258  2.64325  ]
--------------------
[layer0_wv] Shape: (1, 3, 256)
[layer0_wv] Token 0 First 3: [-0.19047922  0.6316551  -2.8215938 ]
[layer0_wv] Token 0 Last 3: [-0.17566693  2.9423106  -0.35499778]
[layer0_wv] Token 1 First 3: [-0.76146674 -3.5735493  -2.3586912 ]
[layer0_wv] Token 1 Last 3: [ 1.2854877 -2.9398885 -1.3001916]
[layer0_wv] Token 2 First 3: [-0.36871025 -2.6020956   2.7435017 ]
[layer0_wv] Token 2 Last 3: [-1.5750332   3.4985502  -0.08559763]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 0.07426769  0.6402311  -0.60094726]
[RMSNorm(raw)] Last 3: [ 0.2228409  -0.04247699 -0.05058382]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 1.045915   1.5819957 -1.7596381]
[RMSNorm(weight)] Last 3: [0.7152014 1.480038  1.0114112]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [0.13659267 0.08331954 0.02223273]
[RMSNorm(raw)] Last 3: [ 0.441297   -0.243795    0.37287435]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.8005053   0.32878378 -0.18482322]
[RMSNorm(weight)] Last 3: [0.97024024 0.3276495  1.0799285 ]
--------------------
[layer0_q_norm_out] Shape: (1, 3, 768)
[layer0_q_norm_out] Token 0 First 3: [0.15194538 1.6530739  0.4565024 ]
[layer0_q_norm_out] Token 0 Last 3: [-0.5578238  2.3688042 -3.150817 ]
[layer0_q_norm_out] Token 1 First 3: [ 6.344235  -3.9600155 -0.2759629]
[layer0_q_norm_out] Token 1 Last 3: [-0.17910054  0.35581297  0.96177495]
[layer0_q_norm_out] Token 2 First 3: [-0.6886321   1.56714     0.74750847]
[layer0_q_norm_out] Token 2 Last 3: [ 0.38221702 -0.10534456 -0.10174486]
--------------------
[layer0_k_norm_out] Shape: (1, 3, 256)
[layer0_k_norm_out] Token 0 First 3: [0.24593583 0.11071365 0.01812361]
[layer0_k_norm_out] Token 0 Last 3: [0.09007058 0.05854157 0.9413521 ]
[layer0_k_norm_out] Token 1 First 3: [3.1730647 3.5100057 1.3062397]
[layer0_k_norm_out] Token 1 Last 3: [0.4750002  0.37048033 3.01383   ]
[layer0_k_norm_out] Token 2 First 3: [ 0.7091173  -0.75156534 -0.5575631 ]
[layer0_k_norm_out] Token 2 Last 3: [ 0.8694611 -0.3236743  0.775552 ]
--------------------
[layer0_attention_out_core] Shape: (1, 3, 768)
[layer0_attention_out_core] Token 0 First 3: [-0.25445393  0.1491451  -2.7377057 ]
[layer0_attention_out_core] Token 0 Last 3: [ 0.09763408  1.8359556  -0.53255785]
[layer0_attention_out_core] Token 1 First 3: [-0.66801935 -2.8855937  -2.4337022 ]
[layer0_attention_out_core] Token 1 Last 3: [ 0.53733635  0.07066944 -0.8163879 ]
[layer0_attention_out_core] Token 2 First 3: [-0.3686662 -2.600934   2.7411032]
[layer0_attention_out_core] Token 2 Last 3: [-0.45574924  2.3872366  -0.38453197]
--------------------
[layer0_wo_weight] Shape: (768, 768)
[layer0_wo_weight] First 3: [-0.00612173  0.00328428  0.01023447]
[layer0_wo_weight] Last 3: [ 0.00251389 -0.00388765  0.00994184]
--------------------
[layer0_attention_out_proj] Shape: (1, 3, 768)
[layer0_attention_out_proj] Token 0 First 3: [-0.4544037  -0.17469761  0.28585997]
[layer0_attention_out_proj] Token 0 Last 3: [-0.40702158  0.34152552 -0.8219159 ]
[layer0_attention_out_proj] Token 1 First 3: [-0.55603266 -0.497955    0.22468469]
[layer0_attention_out_proj] Token 1 Last 3: [-0.41408783  0.44367325 -0.778626  ]
[layer0_attention_out_proj] Token 2 First 3: [-0.31088307 -0.81278676 -0.10969768]
[layer0_attention_out_proj] Token 2 Last 3: [-0.16756716 -0.0180161  -0.36768198]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.97857845 -0.376219    0.6156121 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.876539   0.7354903 -1.7700323]
[RMSNorm(raw)] Token 1 First 3: [-0.87194204 -0.78086764  0.35233906]
[RMSNorm(raw)] Token 1 Last 3: [-0.6493514   0.69574577 -1.2210016 ]
[RMSNorm(raw)] Token 2 First 3: [-0.5120631  -1.3387609  -0.18068571]
[RMSNorm(raw)] Token 2 Last 3: [-0.27600396 -0.02967476 -0.60561794]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.044775   -0.79712045 -0.9070395 ]
[RMSNorm(weight)] Last 3: [-0.5334996 -0.761816  -0.8248024]
--------------------
[layer0_ffn_norm] Shape: (1, 3, 768)
[layer0_ffn_norm] Token 0 First 3: [-3.9581296  -0.07632715  0.05722759]
[layer0_ffn_norm] Token 0 Last 3: [-0.4089058   0.17518201 -0.3101054 ]
[layer0_ffn_norm] Token 1 First 3: [-3.5268095  -0.15842207  0.03275361]
[layer0_ffn_norm] Token 1 Last 3: [-0.3029227   0.16571549 -0.21391656]
[layer0_ffn_norm] Token 2 First 3: [-2.0711799  -0.2716072  -0.01679663]
[layer0_ffn_norm] Token 2 Last 3: [-0.12875596 -0.00706805 -0.10610281]
--------------------
[layer0_post_attention_norm] Shape: (1, 3, 768)
[layer0_post_attention_norm] Token 0 First 3: [-3.9581296  -0.07632715  0.05722759]
[layer0_post_attention_norm] Token 0 Last 3: [-0.4089058   0.17518201 -0.3101054 ]
[layer0_post_attention_norm] Token 1 First 3: [-3.5268095  -0.15842207  0.03275361]
[layer0_post_attention_norm] Token 1 Last 3: [-0.3029227   0.16571549 -0.21391656]
[layer0_post_attention_norm] Token 2 First 3: [-2.0711799  -0.2716072  -0.01679663]
[layer0_post_attention_norm] Token 2 Last 3: [-0.12875596 -0.00706805 -0.10610281]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-3.28426    -0.6838445   0.22450912]
[RMSNorm(raw)] Token 0 Last 3: [ 0.08190678 -0.16161975 -0.12868626]
[RMSNorm(raw)] Token 1 First 3: [-2.0160434  -0.13954106 -1.208328  ]
[RMSNorm(raw)] Token 1 Last 3: [ 0.87804115 -0.08768789 -0.40907446]
[RMSNorm(raw)] Token 2 First 3: [-1.0357071   0.54925996 -1.412964  ]
[RMSNorm(raw)] Token 2 Last 3: [ 2.3376715  1.3330431 -0.5662151]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [3.77951   4.540169  2.8462136]
[RMSNorm(weight)] Last 3: [16.326456   4.2164984  4.4546223]
--------------------
[layer0pre_ffn_norm] Shape: (1, 3, 768)
[layer0pre_ffn_norm] First 5 values: [-15.69715404510498, -3.78861403465271, 0.863510012626648, 0.11310478299856186, -2.3407304286956787]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.3285847306251526, 0.49131229519844055, -1.5951420068740845, -1.394097089767456, -0.1103953868150711]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.6238850951194763, -0.448580265045166, 0.3001956641674042, -0.788280725479126, 0.7452108860015869]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-0.03572672978043556, -0.00803972315043211, -0.05149708315730095, -0.03731193020939827, 0.10775332897901535]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.36337128 -0.08177083 -0.5237692 ]
[RMSNorm(raw)] Token 0 Last 3: [ 0.04353513 -0.5263594  -0.70886415]
[RMSNorm(raw)] Token 1 First 3: [ 0.8444333 -1.1323532  1.1115534]
[RMSNorm(raw)] Token 1 Last 3: [-2.7646968   0.05577787  0.8370497 ]
[RMSNorm(raw)] Token 2 First 3: [0.23773474 0.12361632 0.27303323]
[RMSNorm(raw)] Token 2 Last 3: [-0.8339144  -1.1290069   0.49991396]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [10.105892   -0.4197408  -0.60602194]
[RMSNorm(weight)] Last 3: [ 0.584427   -0.3238199  -0.46090156]
--------------------
[layer0_post_ffn_norm] Shape: (1, 3, 768)
[layer0_post_ffn_norm] Token 0 First 3: [-4.0355625  -0.04744828 -0.20635357]
[layer0_post_ffn_norm] Token 0 Last 3: [ 0.06897824 -0.35591376 -0.38214755]
[layer0_post_ffn_norm] Token 1 First 3: [ 9.378185   -0.65705836  0.43792766]
[layer0_post_ffn_norm] Token 1 Last 3: [-4.3804603   0.03771589  0.4512522 ]
[layer0_post_ffn_norm] Token 2 First 3: [2.6402564  0.0717295  0.10756911]
[layer0_post_ffn_norm] Token 2 Last 3: [-1.3212765  -0.763412    0.26950285]
--------------------
[layer0_decoder_block_out] Shape: (1, 3, 768)
[layer0_decoder_block_out] Token 0 First 3: [-10.470995    -1.3874258    0.23356688]
[layer0_decoder_block_out] Token 0 Last 3: [ 0.22947268 -0.67260396 -0.63430536]
[layer0_decoder_block_out] Token 1 First 3: [ 5.3793087 -0.9338418 -1.9588237]
[layer0_decoder_block_out] Token 1 Last 3: [-2.6388419  -0.13621542 -0.36015812]
[layer0_decoder_block_out] Token 2 First 3: [ 0.16260457  1.3856869  -3.2725685 ]
[layer0_decoder_block_out] Token 2 Last 3: [ 4.270976   2.4255364 -1.085015 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.31603807 -0.04187562  0.00704957]
[RMSNorm(raw)] Token 0 Last 3: [ 0.006926   -0.02030069 -0.01914475]
[RMSNorm(raw)] Token 1 First 3: [ 1.4250249  -0.24738269 -0.51890916]
[RMSNorm(raw)] Token 1 Last 3: [-0.6990518  -0.03608463 -0.09540897]
[RMSNorm(raw)] Token 2 First 3: [ 0.00804418  0.06855103 -0.16189654]
[RMSNorm(raw)] Token 2 Last 3: [ 0.21128856  0.1199932  -0.05367655]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.8597732 25.799156  28.01981  ]
[RMSNorm(weight)] Last 3: [18.319323 19.970665 23.224823]
--------------------
[layer1_attention_norm] Shape: (1, 3, 768)
[layer1_attention_norm] Token 0 First 3: [-0.9037972  -1.1222311   0.20457722]
[layer1_attention_norm] Token 0 Last 3: [ 0.13380562 -0.42571905 -0.4637783 ]
[layer1_attention_norm] Token 1 First 3: [  4.075248   -6.6296473 -15.058645 ]
[layer1_attention_norm] Token 1 Last 3: [-13.505207   -0.7567187  -2.3112655]
[layer1_attention_norm] Token 2 First 3: [ 0.02300452  1.8371097  -4.698207  ]
[layer1_attention_norm] Token 2 Last 3: [ 4.0819516  2.5163372 -1.300305 ]
--------------------
[layer1_attention_norm] Shape: (1, 3, 768)
[layer1_attention_norm] Token 0 First 3: [-0.9037972  -1.1222311   0.20457722]
[layer1_attention_norm] Token 0 Last 3: [ 0.13380562 -0.42571905 -0.4637783 ]
[layer1_attention_norm] Token 1 First 3: [  4.075248   -6.6296473 -15.058645 ]
[layer1_attention_norm] Token 1 Last 3: [-13.505207   -0.7567187  -2.3112655]
[layer1_attention_norm] Token 2 First 3: [ 0.02300452  1.8371097  -4.698207  ]
[layer1_attention_norm] Token 2 Last 3: [ 4.0819516  2.5163372 -1.300305 ]
--------------------
[layer1_wq_weight] Shape: (768, 768)
[layer1_wq_weight] First 3: [0.00488685 0.02569935 0.00155882]
[layer1_wq_weight] Last 3: [ 0.01844487 -0.00501002 -0.00070104]
--------------------
[layer1_wk_weight] Shape: (768, 256)
[layer1_wk_weight] First 3: [6.4348970e-03 5.4460187e-03 3.8879181e-05]
[layer1_wk_weight] Last 3: [-0.00149681 -0.00389845 -0.0027174 ]
--------------------
[layer1_wv_weight] Shape: (768, 256)
[layer1_wv_weight] First 3: [-0.00325681 -0.00202511 -0.00400134]
[layer1_wv_weight] Last 3: [-0.00277166 -0.00622062 -0.00241642]
--------------------
[layer1_wq] Shape: (1, 3, 768)
[layer1_wq] Token 0 First 3: [ 0.6020445   0.54000854 -0.27589345]
[layer1_wq] Token 0 Last 3: [0.0157626  0.20035572 0.10561507]
[layer1_wq] Token 1 First 3: [11.923886   3.4112525  2.3316917]
[layer1_wq] Token 1 Last 3: [ 0.06888762  0.08781987 -3.662224  ]
[layer1_wq] Token 2 First 3: [ 1.09651    -0.18383908  0.16506284]
[layer1_wq] Token 2 Last 3: [0.2746516  0.32836068 0.13232976]
--------------------
[layer1_wk] Shape: (1, 3, 256)
[layer1_wk] Token 0 First 3: [-0.03235107 -0.00239249 -0.0098518 ]
[layer1_wk] Token 0 Last 3: [0.29814214 0.37504876 0.24564995]
[layer1_wk] Token 1 First 3: [2.036902  7.4043837 3.8635213]
[layer1_wk] Token 1 Last 3: [0.61091113 0.3592233  0.27752268]
[layer1_wk] Token 2 First 3: [-0.00305349  0.13639456 -0.03937037]
[layer1_wk] Token 2 Last 3: [ 0.5214632   0.5952597  -0.16652456]
--------------------
[layer1_wv] Shape: (1, 3, 256)
[layer1_wv] Token 0 First 3: [ 0.01666162 -0.12408508 -0.05918738]
[layer1_wv] Token 0 Last 3: [0.01286142 0.5118027  0.077032  ]
[layer1_wv] Token 1 First 3: [ 3.7969851  2.1245432 -6.693057 ]
[layer1_wv] Token 1 Last 3: [ 1.1989137  -6.0926704   0.19096881]
[layer1_wv] Token 2 First 3: [-0.05144462  0.20037204 -0.11742687]
[layer1_wv] Token 2 Last 3: [-0.26381123  0.25859958 -0.01289966]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 1.220898   1.095094  -0.5594898]
[RMSNorm(raw)] Last 3: [0.40334237 0.4822174  0.19433421]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [2.2619982 0.9464675 1.4487991]
[RMSNorm(weight)] Last 3: [1.5345104 1.3420688 1.3173643]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.03533321 -0.00261303 -0.01075995]
[RMSNorm(raw)] Last 3: [ 0.3442344   0.39294982 -0.10992814]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.10979937  0.6358879   0.7863416 ]
[RMSNorm(weight)] Last 3: [1.331181  1.4334608 1.5650191]
--------------------
[layer1_q_norm_out] Shape: (1, 3, 768)
[layer1_q_norm_out] Token 0 First 3: [ 3.982567   2.1315649 -1.3700781]
[layer1_q_norm_out] Token 0 Last 3: [0.08469384 0.9947899  0.51886   ]
[layer1_q_norm_out] Token 1 First 3: [11.6596575  1.9904225  1.7116246]
[layer1_q_norm_out] Token 1 Last 3: [ 0.02919967  0.03439815 -1.4193251 ]
[layer1_q_norm_out] Token 2 First 3: [ 5.6597576 -0.5662217  0.6395934]
[layer1_q_norm_out] Token 2 Last 3: [1.0222754  1.1293863  0.45034313]
--------------------
[layer1_k_norm_out] Shape: (1, 3, 256)
[layer1_k_norm_out] Token 0 First 3: [-0.03145364 -0.00427463 -0.01922094]
[layer1_k_norm_out] Token 0 Last 3: [0.7590909 0.9967965 0.6881795]
[layer1_k_norm_out] Token 1 First 3: [0.46666843 3.1174023  1.7762262 ]
[layer1_k_norm_out] Token 1 Last 3: [0.36652574 0.2249776  0.18320593]
[layer1_k_norm_out] Token 2 First 3: [-0.00179438  0.14729269 -0.04642636]
[layer1_k_norm_out] Token 2 Last 3: [ 0.8024727   0.95622796 -0.2819678 ]
--------------------
[layer1_attention_out_core] Shape: (1, 3, 768)
[layer1_attention_out_core] Token 0 First 3: [-0.04234916  0.15705055 -0.10965356]
[layer1_attention_out_core] Token 0 Last 3: [-0.10857499  0.40065193  0.03755889]
[layer1_attention_out_core] Token 1 First 3: [ 0.02577601 -0.01489792 -0.12572   ]
[layer1_attention_out_core] Token 1 Last 3: [-0.01597719  0.39158484  0.06434444]
[layer1_attention_out_core] Token 2 First 3: [-0.03159368  0.11967382 -0.10720775]
[layer1_attention_out_core] Token 2 Last 3: [-0.04905331  0.4177737   0.05558712]
--------------------
[layer1_wo_weight] Shape: (768, 768)
[layer1_wo_weight] First 3: [ 0.00987351 -0.01336465 -0.00462248]
[layer1_wo_weight] Last 3: [-0.00847637  0.00027818  0.01232663]
--------------------
[layer1_attention_out_proj] Shape: (1, 3, 768)
[layer1_attention_out_proj] Token 0 First 3: [ 0.31764206 -0.06900977  0.4591617 ]
[layer1_attention_out_proj] Token 0 Last 3: [-0.16883856 -0.07537713 -0.5294762 ]
[layer1_attention_out_proj] Token 1 First 3: [ 0.0697134  -0.05535886  0.27938825]
[layer1_attention_out_proj] Token 1 Last 3: [-0.08247791 -0.0161375  -0.41859668]
[layer1_attention_out_proj] Token 2 First 3: [ 0.26231086 -0.0645192   0.44654799]
[layer1_attention_out_proj] Token 2 Last 3: [-0.17679113 -0.05822853 -0.51320624]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.5108649  -0.11098867  0.7384715 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.27154368 -0.12122932 -0.8515586 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.16939904 -0.13451844  0.67889535]
[RMSNorm(raw)] Token 1 Last 3: [-0.20041598 -0.03921309 -1.0171628 ]
[RMSNorm(raw)] Token 2 First 3: [ 0.42827913 -0.10534152  0.72908604]
[RMSNorm(raw)] Token 2 Last 3: [-0.2886497  -0.09507065 -0.83792   ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 9.916991   -0.22180787 -0.461959  ]
[RMSNorm(weight)] Last 3: [ 0.92886245 -0.23041537 -0.3878438 ]
--------------------
[layer1_ffn_norm] Shape: (1, 3, 768)
[layer1_ffn_norm] Token 0 First 3: [ 5.577108   -0.08637051  0.39732796]
[layer1_ffn_norm] Token 0 Last 3: [-0.5237704  -0.09329622 -0.5212869 ]
[layer1_ffn_norm] Token 1 First 3: [ 1.8493278  -0.1046812   0.36527354]
[layer1_ffn_norm] Token 1 Last 3: [-0.38657486 -0.03017779 -0.62266254]
[layer1_ffn_norm] Token 2 First 3: [ 4.6755195  -0.08197595  0.3922782 ]
[layer1_ffn_norm] Token 2 Last 3: [-0.55676556 -0.07316492 -0.51293796]
--------------------
[layer1_post_attention_norm] Shape: (1, 3, 768)
[layer1_post_attention_norm] Token 0 First 3: [ 5.577108   -0.08637051  0.39732796]
[layer1_post_attention_norm] Token 0 Last 3: [-0.5237704  -0.09329622 -0.5212869 ]
[layer1_post_attention_norm] Token 1 First 3: [ 1.8493278  -0.1046812   0.36527354]
[layer1_post_attention_norm] Token 1 Last 3: [-0.38657486 -0.03017779 -0.62266254]
[layer1_post_attention_norm] Token 2 First 3: [ 4.6755195  -0.08197595  0.3922782 ]
[layer1_post_attention_norm] Token 2 Last 3: [-0.55676556 -0.07316492 -0.51293796]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.13063274 -0.03934011  0.0168405 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.0078557  -0.02044421 -0.03084627]
[RMSNorm(raw)] Token 1 First 3: [ 0.770537   -0.11070144 -0.1698646 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.3224945  -0.0177367  -0.10476384]
[RMSNorm(raw)] Token 2 First 3: [ 0.19518955  0.05259699 -0.11620259]
[RMSNorm(raw)] Token 2 Last 3: [ 0.14984632  0.09490421 -0.06446791]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.4646384 15.870649  10.00157  ]
[RMSNorm(weight)] Last 3: [18.942238 14.909328 16.246273]
--------------------
[layer1pre_ffn_norm] Shape: (1, 3, 768)
[layer1pre_ffn_norm] First 5 values: [-0.32196244597435, -0.6636931896209717, 0.1852719783782959, 0.05095164105296135, -0.05923396348953247]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.031667061150074005, 0.007200334221124649, -0.05640583485364914, -0.08974205702543259, -0.14102353155612946]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.1698382943868637, -0.007069284096360207, 0.0318203940987587, 0.09003636986017227, 0.047567423433065414]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.0031313267536461353, 0.0002444256388116628, 0.0005596232367679477, -0.0022983953822404146, -0.0025644295383244753]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.9609086  0.07500677 0.1717313 ]
[RMSNorm(raw)] Token 0 Last 3: [ 0.3223664   0.48770204 -0.17629473]
[RMSNorm(raw)] Token 1 First 3: [-0.11865096 -0.7407358   0.5320677 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.8891847  -0.16764513  0.80838627]
[RMSNorm(raw)] Token 2 First 3: [ 0.6595267  -0.33193916  1.517142  ]
[RMSNorm(raw)] Token 2 Last 3: [-1.6566662  -0.31596452  0.24225622]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [10.632843   -0.12636146 -0.4821924 ]
[RMSNorm(weight)] Last 3: [ 0.06762192 -0.0255863  -0.22973666]
--------------------
[layer1_post_ffn_norm] Shape: (1, 3, 768)
[layer1_post_ffn_norm] Token 0 First 3: [11.178099    0.0655288   0.08892377]
[layer1_post_ffn_norm] Token 0 Last 3: [ 0.3441654   0.47522354 -0.13579336]
[layer1_post_ffn_norm] Token 1 First 3: [-1.380248  -0.6471353  0.2755087]
[layer1_post_ffn_norm] Token 1 Last 3: [-0.9493131  -0.16335571  0.6226703 ]
[layer1_post_ffn_norm] Token 2 First 3: [ 7.6721706  -0.28999484  0.78558767]
[layer1_post_ffn_norm] Token 2 Last 3: [-1.7686932  -0.30788016  0.18660109]
--------------------
[layer1_decoder_block_out] Shape: (1, 3, 768)
[layer1_decoder_block_out] Token 0 First 3: [ 6.2842116 -1.4082675  0.7198186]
[layer1_decoder_block_out] Token 0 Last 3: [ 0.04986772 -0.29067665 -1.2913855 ]
[layer1_decoder_block_out] Token 1 First 3: [ 5.8483887 -1.6856585 -1.3180416]
[layer1_decoder_block_out] Token 1 Last 3: [-3.97473    -0.32974893 -0.36015034]
[layer1_decoder_block_out] Token 2 First 3: [12.510295   1.0137161 -2.0947027]
[layer1_decoder_block_out] Token 2 Last 3: [ 1.9455173  2.0444913 -1.411352 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.17506078 -0.03923044  0.02005216]
[RMSNorm(raw)] Token 0 Last 3: [ 0.00138918 -0.00809745 -0.03597444]
[RMSNorm(raw)] Token 1 First 3: [ 0.49062425 -0.14141072 -0.11057116]
[RMSNorm(raw)] Token 1 Last 3: [-0.3334421  -0.0276628  -0.03021319]
[RMSNorm(raw)] Token 2 First 3: [ 0.47487384  0.03847929 -0.07951207]
[RMSNorm(raw)] Token 2 Last 3: [ 0.0738492   0.07760612 -0.05357301]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.027485 27.366955 31.784855]
[RMSNorm(weight)] Last 3: [19.356092 25.680681 30.136742]
--------------------
[layer2_attention_norm] Shape: (1, 3, 768)
[layer2_attention_norm] Token 0 First 3: [ 0.70505464 -1.1128482   0.65740705]
[layer2_attention_norm] Token 0 Last 3: [ 0.02827821 -0.21604544 -1.1201267 ]
[layer2_attention_norm] Token 1 First 3: [ 1.9759817 -4.0113916 -3.6250594]
[layer2_attention_norm] Token 1 Last 3: [-6.787578   -0.73806244 -0.9407403 ]
[layer2_attention_norm] Token 2 First 3: [ 1.9125472  1.0915402 -2.6067917]
[layer2_attention_norm] Token 2 Last 3: [ 1.5032811  2.070584  -1.6680889]
--------------------
[layer2_attention_norm] Shape: (1, 3, 768)
[layer2_attention_norm] Token 0 First 3: [ 0.70505464 -1.1128482   0.65740705]
[layer2_attention_norm] Token 0 Last 3: [ 0.02827821 -0.21604544 -1.1201267 ]
[layer2_attention_norm] Token 1 First 3: [ 1.9759817 -4.0113916 -3.6250594]
[layer2_attention_norm] Token 1 Last 3: [-6.787578   -0.73806244 -0.9407403 ]
[layer2_attention_norm] Token 2 First 3: [ 1.9125472  1.0915402 -2.6067917]
[layer2_attention_norm] Token 2 Last 3: [ 1.5032811  2.070584  -1.6680889]
--------------------
[layer2_wq_weight] Shape: (768, 768)
[layer2_wq_weight] First 3: [ 0.00587441 -0.00147753 -0.00971008]
[layer2_wq_weight] Last 3: [ 0.00050299 -0.00523375 -0.00758126]
--------------------
[layer2_wk_weight] Shape: (768, 256)
[layer2_wk_weight] First 3: [ 0.00721993  0.00940384 -0.00149919]
[layer2_wk_weight] Last 3: [0.00381705 0.01920059 0.00587659]
--------------------
[layer2_wv_weight] Shape: (768, 256)
[layer2_wv_weight] First 3: [-0.00530868 -0.00125764 -0.00236829]
[layer2_wv_weight] Last 3: [-0.00375193 -0.00973588 -0.00529384]
--------------------
[layer2_wq] Shape: (1, 3, 768)
[layer2_wq] Token 0 First 3: [-0.3519657  -0.00750759 -0.01915854]
[layer2_wq] Token 0 Last 3: [ 0.08472966  0.2154177  -0.39027578]
[layer2_wq] Token 1 First 3: [-2.3599281 -0.5978446 -1.6482645]
[layer2_wq] Token 1 Last 3: [-0.20874585  1.2770715   0.4883021 ]
[layer2_wq] Token 2 First 3: [-0.03570092  0.07411927 -0.31069806]
[layer2_wq] Token 2 Last 3: [ 0.03217764  0.2801669  -1.0960107 ]
--------------------
[layer2_wk] Shape: (1, 3, 256)
[layer2_wk] Token 0 First 3: [-1.0680449  -2.003046   -0.49614537]
[layer2_wk] Token 0 Last 3: [ 2.0322363   0.64200824 -0.44320318]
[layer2_wk] Token 1 First 3: [-3.159189   -5.367249   -0.59634864]
[layer2_wk] Token 1 Last 3: [ 3.7767591   1.2039595  -0.23702212]
[layer2_wk] Token 2 First 3: [-0.23309714 -3.2209604  -0.26020753]
[layer2_wk] Token 2 Last 3: [3.2415779  0.80244493 0.20710224]
--------------------
[layer2_wv] Shape: (1, 3, 256)
[layer2_wv] Token 0 First 3: [ 0.11758802 -0.06063265 -0.2094607 ]
[layer2_wv] Token 0 Last 3: [-0.06492032  0.13119197 -0.00428692]
[layer2_wv] Token 1 First 3: [-0.7326917  -0.49684355 -0.09198776]
[layer2_wv] Token 1 Last 3: [-0.32355055 -0.25540203 -3.3471773 ]
[layer2_wv] Token 2 First 3: [ 0.33330482 -0.25834233  0.36198124]
[layer2_wv] Token 2 Last 3: [ 0.34275118 -0.25899807  2.0313709 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-1.0053648 -0.0214449 -0.054725 ]
[RMSNorm(raw)] Last 3: [ 0.02829811  0.24638829 -0.96386904]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.8257338 -0.6169131  1.2461963]
[RMSNorm(weight)] Last 3: [1.0662664 0.8675798 0.8730121]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-1.1534741 -2.1632628 -0.5358303]
[RMSNorm(raw)] Last 3: [2.115424   0.52366817 0.13515303]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [1.4677651  0.46466437 0.58142126]
[RMSNorm(weight)] Last 3: [0.7740327 0.961506  1.1952598]
--------------------
[layer2_q_norm_out] Shape: (1, 3, 768)
[layer2_q_norm_out] Token 0 First 3: [-1.8355284  -0.00821526 -0.12292309]
[layer2_q_norm_out] Token 0 Last 3: [ 0.18787044  0.43171507 -0.7844203 ]
[layer2_q_norm_out] Token 1 First 3: [-3.4754221  -0.18473831 -2.986386  ]
[layer2_q_norm_out] Token 1 Last 3: [-0.2615982  1.4465216  0.554702 ]
[layer2_q_norm_out] Token 2 First 3: [-0.12582423  0.05481203 -1.347205  ]
[layer2_q_norm_out] Token 2 Last 3: [ 0.05847144  0.4601498  -1.8053384 ]
--------------------
[layer2_k_norm_out] Shape: (1, 3, 256)
[layer2_k_norm_out] Token 0 First 3: [-2.846503  -3.168454  -0.8473735]
[layer2_k_norm_out] Token 0 Last 3: [ 3.8936257  1.3600303 -1.0507687]
[layer2_k_norm_out] Token 1 First 3: [-4.6185203 -4.657076  -0.5586904]
[layer2_k_norm_out] Token 1 Last 3: [ 3.9692125   1.3990233  -0.30824655]
[layer2_k_norm_out] Token 2 First 3: [-0.37538913 -3.0786793  -0.26853964]
[layer2_k_norm_out] Token 2 Last 3: [3.7528312 1.0271783 0.296696 ]
--------------------
[layer2_attention_out_core] Shape: (1, 3, 768)
[layer2_attention_out_core] Token 0 First 3: [ 0.11970575 -0.06294458 -0.20312753]
[layer2_attention_out_core] Token 0 Last 3: [-0.06466437  0.13080373 -0.0034723 ]
[layer2_attention_out_core] Token 1 First 3: [-0.1341721  -0.19765101 -0.15935282]
[layer2_attention_out_core] Token 1 Last 3: [-0.0649932   0.12984052 -0.00924848]
[layer2_attention_out_core] Token 2 First 3: [ 0.23153156 -0.16657698  0.09532863]
[layer2_attention_out_core] Token 2 Last 3: [-0.18725549 -0.1734848  -1.9795852 ]
--------------------
[layer2_wo_weight] Shape: (768, 768)
[layer2_wo_weight] First 3: [-0.00604033 -0.00260302  0.00849657]
[layer2_wo_weight] Last 3: [ 0.0038065  -0.00293189  0.00012073]
--------------------
[layer2_attention_out_proj] Shape: (1, 3, 768)
[layer2_attention_out_proj] Token 0 First 3: [ 0.14375658 -0.0091245   0.04285117]
[layer2_attention_out_proj] Token 0 Last 3: [-0.1773602  -0.0231474   0.02192172]
[layer2_attention_out_proj] Token 1 First 3: [-0.05999969  0.05207866  0.02681793]
[layer2_attention_out_proj] Token 1 Last 3: [-0.03987963 -0.01117762 -0.03519292]
[layer2_attention_out_proj] Token 2 First 3: [-0.01561083 -0.05943557  0.06471428]
[layer2_attention_out_proj] Token 2 Last 3: [-0.18710431 -0.04478119  0.19797283]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.77292037 -0.04905868  0.23039323]
[RMSNorm(raw)] Token 0 Last 3: [-0.9535933  -0.12445409  0.11786413]
[RMSNorm(raw)] Token 1 First 3: [-0.3411372   0.29610103  0.15247734]
[RMSNorm(raw)] Token 1 Last 3: [-0.22674163 -0.06355204 -0.20009461]
[RMSNorm(raw)] Token 2 First 3: [-0.05469663 -0.2082481   0.22674344]
[RMSNorm(raw)] Token 2 Last 3: [-0.655569   -0.15690264  0.6936497 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [12.173349   -0.41412753 -0.67901385]
[RMSNorm(weight)] Last 3: [ 0.7784221  -0.37571615 -0.24614103]
--------------------
[layer2_ffn_norm] Shape: (1, 3, 768)
[layer2_ffn_norm] Token 0 First 3: [10.18195    -0.02874213  0.07395304]
[layer2_ffn_norm] Token 0 Last 3: [-1.6958915  -0.07769468  0.08885293]
[layer2_ffn_norm] Token 1 First 3: [-4.4939194   0.17347744  0.04894311]
[layer2_ffn_norm] Token 1 Last 3: [-0.40324232 -0.03967452 -0.15084311]
[layer2_ffn_norm] Token 2 First 3: [-0.72053784 -0.12200683  0.0727815 ]
[layer2_ffn_norm] Token 2 Last 3: [-1.1658784  -0.09795178  0.52291405]
--------------------
[layer2_post_attention_norm] Shape: (1, 3, 768)
[layer2_post_attention_norm] Token 0 First 3: [10.18195    -0.02874213  0.07395304]
[layer2_post_attention_norm] Token 0 Last 3: [-1.6958915  -0.07769468  0.08885293]
[layer2_post_attention_norm] Token 1 First 3: [-4.4939194   0.17347744  0.04894311]
[layer2_post_attention_norm] Token 1 Last 3: [-0.40324232 -0.03967452 -0.15084311]
[layer2_post_attention_norm] Token 2 First 3: [-0.72053784 -0.12200683  0.0727815 ]
[layer2_post_attention_norm] Token 2 Last 3: [-1.1658784  -0.09795178  0.52291405]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.5385061  -0.04699568  0.02595935]
[RMSNorm(raw)] Token 0 Last 3: [-0.05383123 -0.01204714 -0.03932739]
[RMSNorm(raw)] Token 1 First 3: [ 0.13800249 -0.15407123 -0.12930432]
[RMSNorm(raw)] Token 1 Last 3: [-0.44605738 -0.03763936 -0.05206347]
[RMSNorm(raw)] Token 2 First 3: [ 0.5539027   0.04189401 -0.09499327]
[RMSNorm(raw)] Token 2 Last 3: [ 0.03662875  0.09145171 -0.04174032]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.1377294 29.12203   21.540482 ]
[RMSNorm(weight)] Last 3: [21.01292  24.532494 29.575848]
--------------------
[layer2pre_ffn_norm] Shape: (1, 3, 768)
[layer2pre_ffn_norm] First 5 values: [1.1511802673339844, -1.4156051874160767, 0.5851362347602844, 0.03535951301455498, -1.2509580850601196]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.017499197274446487, -0.07156513631343842, 0.03452305868268013, -0.18165013194084167, 0.017982831224799156]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.024536367505788803, -0.22258220613002777, -0.031082086265087128, 0.0036945641040802, 0.18771475553512573]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.017107129096984863, -0.006304571405053139, -0.01018597837537527, 0.0030394995119422674, 0.0024546142667531967]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.1403486  -0.42025805 -0.67898977]
[RMSNorm(raw)] Token 0 Last 3: [0.2633139  0.6190501  0.30437967]
[RMSNorm(raw)] Token 1 First 3: [ 0.5552903  -0.79627097 -0.37154287]
[RMSNorm(raw)] Token 1 Last 3: [-1.1190192 -0.2306972 -0.7138745]
[RMSNorm(raw)] Token 2 First 3: [ 0.51896816 -0.62194926  0.12255282]
[RMSNorm(raw)] Token 2 Last 3: [-1.15195     0.8140411   0.38483122]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [13.59432     0.26197618 -0.32902798]
[RMSNorm(weight)] Last 3: [0.86832196 0.39831483 0.38518292]
--------------------
[layer2_post_ffn_norm] Shape: (1, 3, 768)
[layer2_post_ffn_norm] Token 0 First 3: [16.642612   -0.5303557  -0.45558313]
[layer2_post_ffn_norm] Token 0 Last 3: [0.4919551  0.86562693 0.4216215 ]
[layer2_post_ffn_norm] Token 1 First 3: [ 8.104084   -1.0048751  -0.24929486]
[layer2_post_ffn_norm] Token 1 Last 3: [-2.090688  -0.3225873 -0.9888467]
[layer2_post_ffn_norm] Token 2 First 3: [ 7.5739875  -0.78488517  0.08222951]
[layer2_post_ffn_norm] Token 2 Last 3: [-2.1522133  1.1382858  0.5330616]
--------------------
[layer2_decoder_block_out] Shape: (1, 3, 768)
[layer2_decoder_block_out] Token 0 First 3: [33.108772  -1.9673653  0.3381885]
[layer2_decoder_block_out] Token 0 Last 3: [-1.1540687   0.4972556  -0.78091115]
[layer2_decoder_block_out] Token 1 First 3: [ 9.458553  -2.517056  -1.5183933]
[layer2_decoder_block_out] Token 1 Last 3: [-6.4686604  -0.69201076 -1.4998403 ]
[layer2_decoder_block_out] Token 2 First 3: [19.363745   0.1068241 -1.9396917]
[layer2_decoder_block_out] Token 2 Last 3: [-1.3725744   3.0848253  -0.35537636]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.0709829  -0.06363916  0.01093952]
[RMSNorm(raw)] Token 0 Last 3: [-0.03733113  0.01608493 -0.02526045]
[RMSNorm(raw)] Token 1 First 3: [ 0.91175437 -0.24263084 -0.14636506]
[RMSNorm(raw)] Token 1 Last 3: [-0.6235446  -0.06670617 -0.14457664]
[RMSNorm(raw)] Token 2 First 3: [ 0.665787    0.00367295 -0.06669275]
[RMSNorm(raw)] Token 2 Last 3: [-0.04719347  0.10606609 -0.01221897]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.924305 34.430294 33.793156]
[RMSNorm(weight)] Last 3: [20.734852 30.933285 39.79521 ]
--------------------
[layer3_attention_norm] Shape: (1, 3, 768)
[layer3_attention_norm] Token 0 First 3: [ 5.2738466  -2.2547543   0.38062045]
[layer3_attention_norm] Token 0 Last 3: [-0.8113866   0.51364464 -1.0305054 ]
[layer3_attention_norm] Token 1 First 3: [ 4.4897566 -8.596482  -5.0925026]
[layer3_attention_norm] Token 1 Last 3: [-13.552649   -2.130147   -5.8980346]
[layer3_attention_norm] Token 2 First 3: [ 3.2785382   0.13013375 -2.3204515 ]
[layer3_attention_norm] Token 2 Last 3: [-1.025743    3.3870385  -0.49847534]
--------------------
[layer3_attention_norm] Shape: (1, 3, 768)
[layer3_attention_norm] Token 0 First 3: [ 5.2738466  -2.2547543   0.38062045]
[layer3_attention_norm] Token 0 Last 3: [-0.8113866   0.51364464 -1.0305054 ]
[layer3_attention_norm] Token 1 First 3: [ 4.4897566 -8.596482  -5.0925026]
[layer3_attention_norm] Token 1 Last 3: [-13.552649   -2.130147   -5.8980346]
[layer3_attention_norm] Token 2 First 3: [ 3.2785382   0.13013375 -2.3204515 ]
[layer3_attention_norm] Token 2 Last 3: [-1.025743    3.3870385  -0.49847534]
--------------------
[layer3_wq_weight] Shape: (768, 768)
[layer3_wq_weight] First 3: [-0.02473447 -0.01605617 -0.00605495]
[layer3_wq_weight] Last 3: [ 0.01121209  0.00192617 -0.00124826]
--------------------
[layer3_wk_weight] Shape: (768, 256)
[layer3_wk_weight] First 3: [-0.01271079 -0.01880059 -0.02217062]
[layer3_wk_weight] Last 3: [-0.00581932  0.0030838  -0.00215899]
--------------------
[layer3_wv_weight] Shape: (768, 256)
[layer3_wv_weight] First 3: [ 0.01061984 -0.01935348  0.00431076]
[layer3_wv_weight] Last 3: [-0.00516676 -0.00436494 -0.00465336]
--------------------
[layer3_wq] Shape: (1, 3, 768)
[layer3_wq] Token 0 First 3: [ 5.149298    0.81521446 -0.0079771 ]
[layer3_wq] Token 0 Last 3: [-0.35990512  0.20092121  0.8846395 ]
[layer3_wq] Token 1 First 3: [17.934929    0.74892235  0.99344885]
[layer3_wq] Token 1 Last 3: [0.23346412 1.3820931  0.23342454]
[layer3_wq] Token 2 First 3: [ 6.5835195   0.18201378 -0.55788743]
[layer3_wq] Token 2 Last 3: [-0.33089313 -0.9129153   0.47696203]
--------------------
[layer3_wk] Shape: (1, 3, 256)
[layer3_wk] Token 0 First 3: [ 1.3309443  -0.29073986 -0.0765827 ]
[layer3_wk] Token 0 Last 3: [ 0.8164075  -0.93297374  0.66864884]
[layer3_wk] Token 1 First 3: [2.3528633 3.8931851 2.306898 ]
[layer3_wk] Token 1 Last 3: [1.3207821 0.6256501 2.1345842]
[layer3_wk] Token 2 First 3: [ 1.8388743  -0.31153476  0.40251   ]
[layer3_wk] Token 2 Last 3: [ 0.7037134 -0.4371307  1.1316484]
--------------------
[layer3_wv] Shape: (1, 3, 256)
[layer3_wv] Token 0 First 3: [ 0.34679782 -0.4807308   0.49506605]
[layer3_wv] Token 0 Last 3: [-0.39309198  0.26045468  0.00853865]
[layer3_wv] Token 1 First 3: [-1.0989865  -3.7851734   0.29182562]
[layer3_wv] Token 1 Last 3: [ 1.3615583  2.3455358 -0.5230398]
[layer3_wv] Token 2 First 3: [ 0.00902442 -0.8375053   0.04783652]
[layer3_wv] Token 2 Last 3: [0.32763106 0.18167055 0.56844175]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 7.1058555   1.124968   -0.01100812]
[RMSNorm(raw)] Last 3: [-0.27999702 -0.7724958   0.40359843]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [1.0256937  0.39373994 0.46513218]
[RMSNorm(weight)] Last 3: [ 0.51806813 -0.01536733  0.40556532]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 1.0158488  -0.2219084  -0.05845207]
[RMSNorm(raw)] Last 3: [ 0.4770193  -0.2963135   0.76709944]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.26536262 0.8183484  0.8023181 ]
[RMSNorm(weight)] Last 3: [0.40208873 0.5758684  0.27553514]
--------------------
[layer3_q_norm_out] Shape: (1, 3, 768)
[layer3_q_norm_out] Token 0 First 3: [14.394286    1.5679129  -0.01612836]
[layer3_q_norm_out] Token 0 Last 3: [-0.7981191   0.28899375  1.8163761 ]
[layer3_q_norm_out] Token 1 First 3: [13.674378    0.39287347  0.5478435 ]
[layer3_q_norm_out] Token 1 Last 3: [0.17065927 0.65528476 0.15798506]
[layer3_q_norm_out] Token 2 First 3: [13.635581    0.2593748  -0.83572835]
[layer3_q_norm_out] Token 2 Last 3: [-0.42505455 -0.7606246   0.5672839 ]
--------------------
[layer3_k_norm_out] Shape: (1, 3, 256)
[layer3_k_norm_out] Token 0 First 3: [ 1.2854171  -0.4035068  -0.10534921]
[layer3_k_norm_out] Token 0 Last 3: [ 0.87367857 -1.1221697   0.65096813]
[layer3_k_norm_out] Token 1 First 3: [1.2077912 2.8718536 1.6867085]
[layer3_k_norm_out] Token 1 Last 3: [0.751254   0.39997387 1.1045512 ]
[layer3_k_norm_out] Token 2 First 3: [ 1.5772742  -0.3839934   0.49175438]
[layer3_k_norm_out] Token 2 Last 3: [ 0.6688234  -0.46695107  0.9784623 ]
--------------------
[layer3_attention_out_core] Shape: (1, 3, 768)
[layer3_attention_out_core] Token 0 First 3: [-0.89972264 -3.2715428   0.26380813]
[layer3_attention_out_core] Token 0 Last 3: [-0.31081608  0.313634    0.02071866]
[layer3_attention_out_core] Token 1 First 3: [-0.00473759 -0.87486625  0.05158858]
[layer3_attention_out_core] Token 1 Last 3: [ 0.30580702  1.0655005  -0.18200263]
[layer3_attention_out_core] Token 2 First 3: [ 0.00907198 -0.83749807  0.04794095]
[layer3_attention_out_core] Token 2 Last 3: [0.03179004 0.61752194 0.00283276]
--------------------
[layer3_wo_weight] Shape: (768, 768)
[layer3_wo_weight] First 3: [-0.01820808  0.00922823  0.00901432]
[layer3_wo_weight] Last 3: [ 0.00399009 -0.0074626  -0.00954604]
--------------------
[layer3_attention_out_proj] Shape: (1, 3, 768)
[layer3_attention_out_proj] Token 0 First 3: [ 0.524817   -0.44527254  0.18817118]
[layer3_attention_out_proj] Token 0 Last 3: [-0.2033813   0.1351473   0.04402608]
[layer3_attention_out_proj] Token 1 First 3: [ 0.32553655 -0.1624299   0.07306834]
[layer3_attention_out_proj] Token 1 Last 3: [-0.3989301  -0.01728198  0.0739347 ]
[layer3_attention_out_proj] Token 2 First 3: [ 0.33771282 -0.09558898  0.03372383]
[layer3_attention_out_proj] Token 2 Last 3: [-0.36386263  0.00366533  0.03889031]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.7069858 -1.4482646  0.6120334]
[RMSNorm(raw)] Token 0 Last 3: [-0.66150486  0.43957138  0.14319637]
[RMSNorm(raw)] Token 1 First 3: [ 1.0523988  -0.5251055   0.23621626]
[RMSNorm(raw)] Token 1 Last 3: [-1.2896664  -0.0558694   0.23901704]
[RMSNorm(raw)] Token 2 First 3: [ 1.3538938  -0.38321707  0.13519913]
[RMSNorm(raw)] Token 2 Last 3: [-1.4587286   0.01469433  0.15591158]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 6.8564596  -0.29878563 -0.7979584 ]
[RMSNorm(weight)] Last 3: [ 0.92992675 -0.2565053   0.15757611]
--------------------
[layer3_ffn_norm] Shape: (1, 3, 768)
[layer3_ffn_norm] Token 0 First 3: [13.410865   -1.0155439   0.12365623]
[layer3_ffn_norm] Token 0 Last 3: [-1.2766559   0.32681897  0.1657607 ]
[layer3_ffn_norm] Token 1 First 3: [ 8.268128   -0.3682115   0.04772552]
[layer3_ffn_norm] Token 1 Last 3: [-2.4889617 -0.0415386  0.2766804]
[layer3_ffn_norm] Token 2 First 3: [10.636811   -0.26871732  0.02731585]
[layer3_ffn_norm] Token 2 Last 3: [-2.8152392   0.01092516  0.18047951]
--------------------
[layer3_post_attention_norm] Shape: (1, 3, 768)
[layer3_post_attention_norm] Token 0 First 3: [13.410865   -1.0155439   0.12365623]
[layer3_post_attention_norm] Token 0 Last 3: [-1.2766559   0.32681897  0.1657607 ]
[layer3_post_attention_norm] Token 1 First 3: [ 8.268128   -0.3682115   0.04772552]
[layer3_post_attention_norm] Token 1 Last 3: [-2.4889617 -0.0415386  0.2766804]
[layer3_post_attention_norm] Token 2 First 3: [10.636811   -0.26871732  0.02731585]
[layer3_post_attention_norm] Token 2 Last 3: [-2.8152392   0.01092516  0.18047951]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.4553291  -0.09331789  0.01444844]
[RMSNorm(raw)] Token 0 Last 3: [-0.07604324  0.0257805  -0.01924448]
[RMSNorm(raw)] Token 1 First 3: [ 1.3677025  -0.22261289 -0.1134694 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.6911256  -0.05659702 -0.09437292]
[RMSNorm(raw)] Token 2 First 3: [ 0.9128396  -0.00492599 -0.05818866]
[RMSNorm(raw)] Token 2 Last 3: [-0.12742437  0.09419569 -0.00532166]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 0.69816935 21.76266    18.668678  ]
[RMSNorm(weight)] Last 3: [12.635019 17.804846 20.606947]
--------------------
[layer3pre_ffn_norm] Shape: (1, 3, 768)
[layer3pre_ffn_norm] First 5 values: [2.471395254135132, -2.1241633892059326, 0.2841816544532776, 0.07607882469892502, -1.4525970220565796]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.09224289655685425, 0.16000831127166748, -0.1455739140510559, 0.3375048041343689, 0.17760667204856873]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.2701706886291504, 0.12798739969730377, 0.1644618958234787, 0.052683036774396896, 0.05081144720315933]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.01571427285671234, -0.0016158910002559423, -0.001595079549588263, 0.0048733907751739025, -0.007364287972450256]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.90169674 -0.09272104 -0.09152686]
[RMSNorm(raw)] Token 0 Last 3: [-1.4952463  -0.39534923 -0.40035132]
[RMSNorm(raw)] Token 1 First 3: [ 0.76870805 -0.38016728  0.7845749 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.39003426  0.13020293 -0.5725348 ]
[RMSNorm(raw)] Token 2 First 3: [ 0.02654615 -0.13442913  0.30692586]
[RMSNorm(raw)] Token 2 Last 3: [-0.37286422  0.65442187  0.02394187]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [16.193014    0.28928578 -0.3589789 ]
[RMSNorm(weight)] Last 3: [1.9483447  0.8291663  0.99229074]
--------------------
[layer3_post_ffn_norm] Shape: (1, 3, 768)
[layer3_post_ffn_norm] Token 0 First 3: [15.502885   -0.11954392 -0.05867065]
[layer3_post_ffn_norm] Token 0 Last 3: [-4.4085016  -0.7231595  -0.79761624]
[layer3_post_ffn_norm] Token 1 First 3: [13.216409   -0.49014425  0.5029291 ]
[layer3_post_ffn_norm] Token 1 Last 3: [-1.1499554   0.23816282 -1.1406558 ]
[layer3_post_ffn_norm] Token 2 First 3: [ 0.45640832 -0.17331757  0.19674596]
[layer3_post_ffn_norm] Token 2 Last 3: [-1.0993322   1.1970464   0.04769916]
--------------------
[layer3_decoder_block_out] Shape: (1, 3, 768)
[layer3_decoder_block_out] Token 0 First 3: [62.022522  -3.1024532  0.4031741]
[layer3_decoder_block_out] Token 0 Last 3: [-6.8392262   0.10091507 -1.4127667 ]
[layer3_decoder_block_out] Token 1 First 3: [30.943089  -3.3754117 -0.9677386]
[layer3_decoder_block_out] Token 1 Last 3: [-10.107578    -0.49538654  -2.3638155 ]
[layer3_decoder_block_out] Token 2 First 3: [30.456964  -0.3352108 -1.7156298]
[layer3_decoder_block_out] Token 2 Last 3: [-5.287146    4.2927966  -0.12719768]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.6640981  -0.08324052  0.01081738]
[RMSNorm(raw)] Token 0 Last 3: [-0.18350019  0.00270761 -0.0379053 ]
[RMSNorm(raw)] Token 1 First 3: [ 2.2621605  -0.24676667 -0.0707486 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.73893607 -0.03621629 -0.17281178]
[RMSNorm(raw)] Token 2 First 3: [ 0.5310524  -0.00584479 -0.02991399]
[RMSNorm(raw)] Token 2 Last 3: [-0.0921875   0.07484987 -0.00221784]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.5011961 34.03876   43.62872  ]
[RMSNorm(weight)] Last 3: [20.042173 27.509361 35.31812 ]
--------------------
[layer4_attention_norm] Shape: (1, 3, 768)
[layer4_attention_norm] Token 0 First 3: [ 7.490432   -2.9166446   0.48276588]
[layer4_attention_norm] Token 0 Last 3: [-3.8612428   0.07719214 -1.3766493 ]
[layer4_attention_norm] Token 1 First 3: [10.182427  -8.646399  -3.1574192]
[layer4_attention_norm] Token 1 Last 3: [-15.5488205  -1.0325032  -6.276199 ]
[layer4_attention_norm] Token 2 First 3: [ 2.3903708  -0.20479412 -1.335023  ]
[layer4_attention_norm] Token 2 Last 3: [-1.9398254   2.133922   -0.08054773]
--------------------
[layer4_attention_norm] Shape: (1, 3, 768)
[layer4_attention_norm] Token 0 First 3: [ 7.490432   -2.9166446   0.48276588]
[layer4_attention_norm] Token 0 Last 3: [-3.8612428   0.07719214 -1.3766493 ]
[layer4_attention_norm] Token 1 First 3: [10.182427  -8.646399  -3.1574192]
[layer4_attention_norm] Token 1 Last 3: [-15.5488205  -1.0325032  -6.276199 ]
[layer4_attention_norm] Token 2 First 3: [ 2.3903708  -0.20479412 -1.335023  ]
[layer4_attention_norm] Token 2 Last 3: [-1.9398254   2.133922   -0.08054773]
--------------------
[layer4_wq_weight] Shape: (768, 768)
[layer4_wq_weight] First 3: [ 0.01592363 -0.01662864 -0.02666767]
[layer4_wq_weight] Last 3: [-0.01365836 -0.00613161  0.00130188]
--------------------
[layer4_wk_weight] Shape: (768, 256)
[layer4_wk_weight] First 3: [ 0.00164668 -0.00545619  0.01094678]
[layer4_wk_weight] Last 3: [ 0.0078556  -0.00755361  0.00768446]
--------------------
[layer4_wv_weight] Shape: (768, 256)
[layer4_wv_weight] First 3: [-0.00628117 -0.0009031  -0.00225539]
[layer4_wv_weight] Last 3: [ 0.00414543  0.01529113 -0.00027923]
--------------------
[layer4_wq] Shape: (1, 3, 768)
[layer4_wq] Token 0 First 3: [-1.1796062   0.14301056 -0.35320356]
[layer4_wq] Token 0 Last 3: [-0.16241476  0.52838904 -0.4454298 ]
[layer4_wq] Token 1 First 3: [-1.5524094   0.5208032   0.15295708]
[layer4_wq] Token 1 Last 3: [ 0.7468646  1.6700901 -0.1410721]
[layer4_wq] Token 2 First 3: [-0.259391    0.40877205  0.43143773]
[layer4_wq] Token 2 Last 3: [-0.17430235 -0.18833554 -0.0521788 ]
--------------------
[layer4_wk] Shape: (1, 3, 256)
[layer4_wk] Token 0 First 3: [0.34481382 0.66375524 0.22309569]
[layer4_wk] Token 0 Last 3: [ 0.41371664 -0.28607953  0.31332487]
[layer4_wk] Token 1 First 3: [3.6708865  4.312921   0.71239203]
[layer4_wk] Token 1 Last 3: [2.6373823 0.7866889 1.2314327]
[layer4_wk] Token 2 First 3: [ 0.02894698 -0.03158087 -0.06896902]
[layer4_wk] Token 2 Last 3: [0.7412464  0.01619609 0.67479295]
--------------------
[layer4_wv] Shape: (1, 3, 256)
[layer4_wv] Token 0 First 3: [ 0.16768792  0.019885   -0.1573407 ]
[layer4_wv] Token 0 Last 3: [-0.16187274 -0.05542997 -0.02866983]
[layer4_wv] Token 1 First 3: [-1.1349002 -1.4666905  3.7296944]
[layer4_wv] Token 1 Last 3: [-1.2816797   0.30147514 -0.4116332 ]
[layer4_wv] Token 2 First 3: [ 0.46644127 -0.09310225 -0.13246277]
[layer4_wv] Token 2 Last 3: [-0.08533567  0.23224813 -0.147165  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-1.8101813   0.21945885 -0.54201347]
[RMSNorm(raw)] Last 3: [-0.4064122  -0.4391327  -0.12166274]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.6341116  0.50397134 0.5234268 ]
[RMSNorm(weight)] Last 3: [0.6786536  0.24180123 0.13257591]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [0.3471327  0.66821903 0.22459602]
[RMSNorm(raw)] Last 3: [0.6882363  0.01503783 0.62653524]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.03273107  0.4136296   0.63725376]
[RMSNorm(weight)] Last 3: [-0.06064456  0.54502785  0.6246264 ]
--------------------
[layer4_q_norm_out] Shape: (1, 3, 768)
[layer4_q_norm_out] Token 0 First 3: [-2.9580383   0.33005983 -0.8257178 ]
[layer4_q_norm_out] Token 0 Last 3: [-0.38889214  0.93594104 -0.71959674]
[layer4_q_norm_out] Token 1 First 3: [-1.3218135   0.4081271   0.12141529]
[layer4_q_norm_out] Token 1 Last 3: [ 0.6919175  1.1445725 -0.0881779]
[layer4_q_norm_out] Token 2 First 3: [-0.9258049  1.3427761  1.4355639]
[layer4_q_norm_out] Token 2 Last 3: [-0.68222535 -0.5453155  -0.13779227]
--------------------
[layer4_k_norm_out] Shape: (1, 3, 256)
[layer4_k_norm_out] Token 0 First 3: [0.3357707 0.9446142 0.3677207]
[layer4_k_norm_out] Token 0 Last 3: [ 0.39124054 -0.44497335  0.51245916]
[layer4_k_norm_out] Token 1 First 3: [1.4347075  2.4634986  0.47128135]
[layer4_k_norm_out] Token 1 Last 3: [1.0010326  0.49111652 0.80836844]
[layer4_k_norm_out] Token 2 First 3: [ 0.02599714 -0.04145096 -0.10484435]
[layer4_k_norm_out] Token 2 Last 3: [0.6464985  0.02323386 1.0178857 ]
--------------------
[layer4_attention_out_core] Shape: (1, 3, 768)
[layer4_attention_out_core] Token 0 First 3: [ 0.39800805 -0.08154533 -0.1092445 ]
[layer4_attention_out_core] Token 0 Last 3: [-0.26193526  0.18152466 -0.15795308]
[layer4_attention_out_core] Token 1 First 3: [ 0.17642042 -0.1827023   0.24569017]
[layer4_attention_out_core] Token 1 Last 3: [-0.23018505  0.20797914 -0.16404971]
[layer4_attention_out_core] Token 2 First 3: [ 0.40682715 -0.12847035 -0.02051398]
[layer4_attention_out_core] Token 2 Last 3: [-0.09675363  0.21285239 -0.14039133]
--------------------
[layer4_wo_weight] Shape: (768, 768)
[layer4_wo_weight] First 3: [ 0.00493999 -0.00394484  0.00969866]
[layer4_wo_weight] Last 3: [-0.0099477  -0.01196462  0.01185504]
--------------------
[layer4_attention_out_proj] Shape: (1, 3, 768)
[layer4_attention_out_proj] Token 0 First 3: [ 0.20265082 -0.07899566  0.05800129]
[layer4_attention_out_proj] Token 0 Last 3: [-0.20244376 -0.19419147 -0.08344389]
[layer4_attention_out_proj] Token 1 First 3: [ 0.19435677 -0.08710262  0.00168492]
[layer4_attention_out_proj] Token 1 Last 3: [-0.21772495 -0.16021895 -0.06902602]
[layer4_attention_out_proj] Token 2 First 3: [ 0.20039013 -0.0945462   0.05224222]
[layer4_attention_out_proj] Token 2 Last 3: [-0.19486219 -0.20578593 -0.1254811 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.8737269  -0.34058896  0.25007194]
[RMSNorm(raw)] Token 0 Last 3: [-0.8728342 -0.8372545 -0.3597675]
[RMSNorm(raw)] Token 1 First 3: [ 0.93356866 -0.41838667  0.00809331]
[RMSNorm(raw)] Token 1 Last 3: [-1.0458149  -0.7695919  -0.33155793]
[RMSNorm(raw)] Token 2 First 3: [ 0.8435967  -0.3980179   0.21992782]
[RMSNorm(raw)] Token 2 Last 3: [-0.8203253  -0.8663118  -0.52824676]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 7.199853    0.04357725 -0.8263968 ]
[RMSNorm(weight)] Last 3: [1.6208159  0.28626564 1.6498514 ]
--------------------
[layer4_ffn_norm] Shape: (1, 3, 768)
[layer4_ffn_norm] Token 0 First 3: [ 7.164432   -0.35543087  0.04341329]
[layer4_ffn_norm] Token 0 Last 3: [-2.2875376 -1.0769317 -0.9533304]
[layer4_ffn_norm] Token 1 First 3: [ 7.6551256e+00 -4.3661878e-01  1.4050241e-03]
[layer4_ffn_norm] Token 1 Last 3: [-2.740888   -0.98989964 -0.8785792 ]
[layer4_ffn_norm] Token 2 First 3: [ 6.917369   -0.41536242  0.03818017]
[layer4_ffn_norm] Token 2 Last 3: [-2.1499214 -1.114307  -1.3997754]
--------------------
[layer4_post_attention_norm] Shape: (1, 3, 768)
[layer4_post_attention_norm] Token 0 First 3: [ 7.164432   -0.35543087  0.04341329]
[layer4_post_attention_norm] Token 0 Last 3: [-2.2875376 -1.0769317 -0.9533304]
[layer4_post_attention_norm] Token 1 First 3: [ 7.6551256e+00 -4.3661878e-01  1.4050241e-03]
[layer4_post_attention_norm] Token 1 Last 3: [-2.740888   -0.98989964 -0.8785792 ]
[layer4_post_attention_norm] Token 2 First 3: [ 6.917369   -0.41536242  0.03818017]
[layer4_post_attention_norm] Token 2 Last 3: [-2.1499214 -1.114307  -1.3997754]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 2.1236002 -0.1061351  0.0137074]
[RMSNorm(raw)] Token 0 Last 3: [-0.28013375 -0.02995752 -0.07262416]
[RMSNorm(raw)] Token 1 First 3: [ 2.891109   -0.28553122 -0.07238096]
[RMSNorm(raw)] Token 1 Last 3: [-0.96238434 -0.11125189 -0.242864  ]
[RMSNorm(raw)] Token 2 First 3: [ 0.70384187 -0.01413496 -0.03159011]
[RMSNorm(raw)] Token 2 Last 3: [-0.14005654  0.05985804 -0.0287563 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 0.7999581 24.128704  24.076937 ]
[RMSNorm(weight)] Last 3: [12.247454 19.558992 17.148891]
--------------------
[layer4pre_ffn_norm] Shape: (1, 3, 768)
[layer4pre_ffn_norm] First 5 values: [3.8223915100097656, -2.6670374870300293, 0.3437395691871643, 0.1513570100069046, -2.135024070739746]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.16701078414916992, -0.3796190917491913, -0.10919365286827087, -0.25281181931495667, -0.722220242023468]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.049079351127147675, 0.21765528619289398, 0.08470813930034637, 0.06561513245105743, -0.04838669300079346]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.0225722324103117, 0.024761103093624115, 0.0014759897021576762, -0.010350880213081837, -0.001558830263093114]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.9152687  1.004024   0.05984907]
[RMSNorm(raw)] Token 0 Last 3: [ 0.3735964   0.17992128 -0.27388787]
[RMSNorm(raw)] Token 1 First 3: [-0.35506937  1.2262214   0.58793086]
[RMSNorm(raw)] Token 1 Last 3: [-0.24692357  0.06392344 -0.73530954]
[RMSNorm(raw)] Token 2 First 3: [ 1.386188   -0.23695078  0.27627727]
[RMSNorm(raw)] Token 2 Last 3: [-0.09575335  0.2333632  -0.14056489]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [12.417652    0.65506524 -0.50579554]
[RMSNorm(weight)] Last 3: [2.3341024 1.4635769 1.7548206]
--------------------
[layer4_post_ffn_norm] Shape: (1, 3, 768)
[layer4_post_ffn_norm] Token 0 First 3: [12.280757    1.6617253   0.02957768]
[layer4_post_ffn_norm] Token 0 Last 3: [ 1.2456087   0.4432499  -0.75451195]
[layer4_post_ffn_norm] Token 1 First 3: [-4.7641973   2.0294766   0.29055804]
[layer4_post_ffn_norm] Token 1 Last 3: [-0.8232685  0.1574803 -2.025646 ]
[layer4_post_ffn_norm] Token 2 First 3: [18.599388   -0.39216903  0.13653746]
[layer4_post_ffn_norm] Token 2 Last 3: [-0.31925148  0.57490814 -0.38723105]
--------------------
[layer4_decoder_block_out] Shape: (1, 3, 768)
[layer4_decoder_block_out] Token 0 First 3: [81.467705   -1.7961588   0.47616506]
[layer4_decoder_block_out] Token 0 Last 3: [-7.8811555 -0.5327667 -3.1206088]
[layer4_decoder_block_out] Token 1 First 3: [33.834015  -1.7825539 -0.6757756]
[layer4_decoder_block_out] Token 1 Last 3: [-13.671736   -1.327806   -5.2680407]
[layer4_decoder_block_out] Token 2 First 3: [55.97372   -1.1427423 -1.5409123]
[layer4_decoder_block_out] Token 2 Last 3: [-7.756319   3.753398  -1.9142041]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 4.3601837  -0.09613113  0.02548454]
[RMSNorm(raw)] Token 0 Last 3: [-0.42180258 -0.02851388 -0.16701622]
[RMSNorm(raw)] Token 1 First 3: [ 2.359767   -0.12432493 -0.04713224]
[RMSNorm(raw)] Token 1 Last 3: [-0.9535407  -0.09260836 -0.3674216 ]
[RMSNorm(raw)] Token 2 First 3: [ 0.74350804 -0.01517923 -0.02046819]
[RMSNorm(raw)] Token 2 Last 3: [-0.10302845  0.04985699 -0.02542668]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.2742711 13.574836  40.0837   ]
[RMSNorm(weight)] Last 3: [ 7.2143354  9.382518  10.386372 ]
--------------------
[layer5_attention_norm] Shape: (1, 3, 768)
[layer5_attention_norm] Token 0 First 3: [ 9.91624   -1.4010954  1.0469993]
[layer5_attention_norm] Token 0 Last 3: [-3.4648278 -0.2960459 -1.9017087]
[layer5_attention_norm] Token 1 First 3: [ 5.36675   -1.8120155 -1.9363667]
[layer5_attention_norm] Token 1 Last 3: [-7.832703 -0.961508 -4.183599]
[layer5_attention_norm] Token 2 First 3: [ 1.6909388 -0.2212348 -0.8409089]
[layer5_attention_norm] Token 2 Last 3: [-0.8463102   0.5176411  -0.28951767]
--------------------
[layer5_attention_norm] Shape: (1, 3, 768)
[layer5_attention_norm] Token 0 First 3: [ 9.91624   -1.4010954  1.0469993]
[layer5_attention_norm] Token 0 Last 3: [-3.4648278 -0.2960459 -1.9017087]
[layer5_attention_norm] Token 1 First 3: [ 5.36675   -1.8120155 -1.9363667]
[layer5_attention_norm] Token 1 Last 3: [-7.832703 -0.961508 -4.183599]
[layer5_attention_norm] Token 2 First 3: [ 1.6909388 -0.2212348 -0.8409089]
[layer5_attention_norm] Token 2 Last 3: [-0.8463102   0.5176411  -0.28951767]
--------------------
[layer5_wq_weight] Shape: (768, 768)
[layer5_wq_weight] First 3: [-0.00045388 -0.00047459  0.00024978]
[layer5_wq_weight] Last 3: [-0.00011499  0.01079142  0.00551624]
--------------------
[layer5_wk_weight] Shape: (768, 256)
[layer5_wk_weight] First 3: [ 0.00180028  0.00320952 -0.00021685]
[layer5_wk_weight] Last 3: [-0.00382065  0.00201735  0.00854593]
--------------------
[layer5_wv_weight] Shape: (768, 256)
[layer5_wv_weight] First 3: [ 0.00647135 -0.00163155 -0.00294039]
[layer5_wv_weight] Last 3: [ 0.01151015  0.00085583 -0.0019759 ]
--------------------
[layer5_wq] Shape: (1, 3, 768)
[layer5_wq] Token 0 First 3: [ 0.24075536 -1.0586799  -0.76907516]
[layer5_wq] Token 0 Last 3: [-1.1109087   0.03774244  0.45013633]
[layer5_wq] Token 1 First 3: [-0.13774216 -1.6153525  -1.1515296 ]
[layer5_wq] Token 1 Last 3: [-0.7201518 -1.2513192  0.2851545]
[layer5_wq] Token 2 First 3: [ 0.3490157  -0.17112431 -0.53211284]
[layer5_wq] Token 2 Last 3: [ 0.13226214 -0.19190909  0.08443584]
--------------------
[layer5_wk] Shape: (1, 3, 256)
[layer5_wk] Token 0 First 3: [-0.4699714  0.6821896  0.6498809]
[layer5_wk] Token 0 Last 3: [-0.9996102 -2.0366464  0.9860319]
[layer5_wk] Token 1 First 3: [-1.8627963  0.7224432  2.0083132]
[layer5_wk] Token 1 Last 3: [-0.7296849 -4.750493  -0.2650132]
[layer5_wk] Token 2 First 3: [-0.02396433  0.01056591  0.02295139]
[layer5_wk] Token 2 Last 3: [-0.03448109 -0.7241686   0.48777938]
--------------------
[layer5_wv] Shape: (1, 3, 256)
[layer5_wv] Token 0 First 3: [-0.27767852 -0.15801445 -0.5842159 ]
[layer5_wv] Token 0 Last 3: [-0.8252869   0.16736433  0.32325894]
[layer5_wv] Token 1 First 3: [-0.03207281 -0.8689667  -0.0114775 ]
[layer5_wv] Token 1 Last 3: [ 0.7542536 -1.0651649  1.1209257]
[layer5_wv] Token 2 First 3: [-0.08578521 -0.12290604  0.07919659]
[layer5_wv] Token 2 Last 3: [ 0.06584032  0.02292902 -0.18468125]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 0.27687424 -1.2175064  -0.8844542 ]
[RMSNorm(raw)] Last 3: [ 0.3062525  -0.44436482  0.19551088]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.6662733   0.01928045 -0.24241346]
[RMSNorm(weight)] Last 3: [-0.13606963  0.11041968  0.22385123]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.48668706  0.7064533   0.67299545]
[RMSNorm(raw)] Last 3: [-0.07510502 -1.5773484   1.062457  ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.61307096 0.15289946 1.8555077 ]
[RMSNorm(weight)] Last 3: [3.2869854 2.3220716 2.1894727]
--------------------
[layer5_q_norm_out] Shape: (1, 3, 768)
[layer5_q_norm_out] Token 0 First 3: [ 0.46134818 -1.2409805  -0.67005056]
[layer5_q_norm_out] Token 0 Last 3: [-0.52183545  0.02278733  0.29953608]
[layer5_q_norm_out] Token 1 First 3: [-0.14973858 -1.0741912  -0.5691515 ]
[layer5_q_norm_out] Token 1 Last 3: [-0.21072908 -0.47062707  0.11820355]
[layer5_q_norm_out] Token 2 First 3: [ 2.2139874  -0.66403246 -1.5346872 ]
[layer5_q_norm_out] Token 2 Last 3: [ 0.26458085 -0.49343142  0.23927623]
--------------------
[layer5_k_norm_out] Shape: (1, 3, 256)
[layer5_k_norm_out] Token 0 First 3: [-0.78506076  0.8144697   1.9217438 ]
[layer5_k_norm_out] Token 0 Last 3: [-4.4377317 -7.00653    3.2567782]
[layer5_k_norm_out] Token 1 First 3: [-1.8936925  0.5249111  3.6141438]
[layer5_k_norm_out] Token 1 Last 3: [-1.9714146 -9.945767  -0.532693 ]
[layer5_k_norm_out] Token 2 First 3: [-0.08419894  0.02653299  0.14275135]
[layer5_k_norm_out] Token 2 Last 3: [-0.32197413 -5.240064    3.3886774 ]
--------------------
[layer5_attention_out_core] Shape: (1, 3, 768)
[layer5_attention_out_core] Token 0 First 3: [-0.08941164 -0.12362467  0.06663915]
[layer5_attention_out_core] Token 0 Last 3: [ 0.0207988  -0.04199247 -0.03342557]
[layer5_attention_out_core] Token 1 First 3: [-0.0827911  -0.17821991  0.06912358]
[layer5_attention_out_core] Token 1 Last 3: [-0.1161468  -0.04148326  0.08234348]
[layer5_attention_out_core] Token 2 First 3: [-0.08610683 -0.12296491  0.0780847 ]
[layer5_attention_out_core] Token 2 Last 3: [ 0.06307665  0.02286857 -0.18222196]
--------------------
[layer5_wo_weight] Shape: (768, 768)
[layer5_wo_weight] First 3: [ 0.00487415 -0.00048826 -0.00405926]
[layer5_wo_weight] Last 3: [ 0.00280357 -0.00038661 -0.00169234]
--------------------
[layer5_attention_out_proj] Shape: (1, 3, 768)
[layer5_attention_out_proj] Token 0 First 3: [ 0.23327944  0.00036513 -0.0300253 ]
[layer5_attention_out_proj] Token 0 Last 3: [-0.06771599 -0.00545946  0.06893207]
[layer5_attention_out_proj] Token 1 First 3: [ 0.21436247 -0.04660401 -0.03057681]
[layer5_attention_out_proj] Token 1 Last 3: [0.00759655 0.04400462 0.08853568]
[layer5_attention_out_proj] Token 2 First 3: [ 0.24346602  0.0263529  -0.01436875]
[layer5_attention_out_proj] Token 2 Last 3: [-0.07836638 -0.00738018  0.06361339]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 2.0435407   0.0031986  -0.26302326]
[RMSNorm(raw)] Token 0 Last 3: [-0.59319574 -0.04782516  0.6038487 ]
[RMSNorm(raw)] Token 1 First 3: [ 1.5872147  -0.34507242 -0.22640143]
[RMSNorm(raw)] Token 1 Last 3: [0.05624752 0.3258256  0.65554917]
[RMSNorm(raw)] Token 2 First 3: [ 2.4568748   0.26593357 -0.1449986 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.7908143  -0.07447523  0.64193827]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 9.023434    0.37014082 -0.87789625]
[RMSNorm(weight)] Last 3: [3.8299742  0.26914406 2.2136703 ]
--------------------
[layer5_ffn_norm] Shape: (1, 3, 768)
[layer5_ffn_norm] Token 0 First 3: [ 2.0483295e+01  4.3825279e-03 -3.2116126e-02]
[layer5_ffn_norm] Token 0 Last 3: [-2.8651202  -0.06069702  1.9405706 ]
[layer5_ffn_norm] Token 1 First 3: [15.909342   -0.4727978  -0.02764446]
[layer5_ffn_norm] Token 1 Last 3: [0.27167407 0.41351962 2.1067188 ]
[layer5_ffn_norm] Token 2 First 3: [ 2.4626322e+01  3.6436644e-01 -1.7704872e-02]
[layer5_ffn_norm] Token 2 Last 3: [-3.8196125  -0.09451979  2.062978  ]
--------------------
[layer5_post_attention_norm] Shape: (1, 3, 768)
[layer5_post_attention_norm] Token 0 First 3: [ 2.0483295e+01  4.3825279e-03 -3.2116126e-02]
[layer5_post_attention_norm] Token 0 Last 3: [-2.8651202  -0.06069702  1.9405706 ]
[layer5_post_attention_norm] Token 1 First 3: [15.909342   -0.4727978  -0.02764446]
[layer5_post_attention_norm] Token 1 Last 3: [0.27167407 0.41351962 2.1067188 ]
[layer5_post_attention_norm] Token 2 First 3: [ 2.4626322e+01  3.6436644e-01 -1.7704872e-02]
[layer5_post_attention_norm] Token 2 Last 3: [-3.8196125  -0.09451979  2.062978  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 6.2520914  -0.10987974  0.02723107]
[RMSNorm(raw)] Token 0 Last 3: [-0.6590097  -0.03639385 -0.07236522]
[RMSNorm(raw)] Token 1 First 3: [ 3.4579785  -0.15678391 -0.04889922]
[RMSNorm(raw)] Token 1 Last 3: [-0.9315239  -0.06355789 -0.21976368]
[RMSNorm(raw)] Token 2 First 3: [ 1.3606166  -0.01313983 -0.02631116]
[RMSNorm(raw)] Token 2 Last 3: [-0.19541433  0.06176585  0.00251147]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 0.84669816 20.699423   20.255669  ]
[RMSNorm(weight)] Last 3: [ 9.268532 15.764543 12.364263]
--------------------
[layer5pre_ffn_norm] Shape: (1, 3, 768)
[layer5pre_ffn_norm] First 5 values: [11.54572582244873, -2.384326934814453, 0.5788145661354065, 0.10668393224477768, -3.341318130493164]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.514412522315979, -0.45492058992385864, -0.10842929780483246, 0.12687508761882782, -0.6027365922927856]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.3045462369918823, -0.07555437088012695, 0.10511843860149384, -0.16949664056301117, 1.4805235862731934]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.004483506549149752, -0.010290210135281086, -0.034642741084098816, -0.32568174600601196, 0.0012891842052340508]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.08718245 -0.20009467 -0.6736332 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.9858686 -0.3558363 -0.6855273]
[RMSNorm(raw)] Token 1 First 3: [-1.0472593  -0.41108376 -0.10251213]
[RMSNorm(raw)] Token 1 Last 3: [-0.3095742  -0.3929495  -0.75002724]
[RMSNorm(raw)] Token 2 First 3: [-1.0638479  -0.28710726 -0.55767894]
[RMSNorm(raw)] Token 2 Last 3: [-0.2585504  -0.14398398 -0.45725492]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [13.434189    1.3042507  -0.49401814]
[RMSNorm(weight)] Last 3: [5.2396297 2.5866125 4.2614884]
--------------------
[layer5_post_ffn_norm] Shape: (1, 3, 768)
[layer5_post_ffn_norm] Token 0 First 3: [ 1.258408   -0.46106827 -0.34084618]
[layer5_post_ffn_norm] Token 0 Last 3: [-6.151455  -1.2762469 -3.606894 ]
[layer5_post_ffn_norm] Token 1 First 3: [-15.116339    -0.94724005  -0.05186928]
[layer5_post_ffn_norm] Token 1 Last 3: [-1.9316283 -1.4093575 -3.9462597]
[layer5_post_ffn_norm] Token 2 First 3: [-15.355782    -0.6615671   -0.28217542]
[layer5_post_ffn_norm] Token 2 Last 3: [-1.6132588 -0.5164147 -2.4058414]
--------------------
[layer5_decoder_block_out] Shape: (1, 3, 768)
[layer5_decoder_block_out] Token 0 First 3: [ 1.0320941e+02 -2.2528446e+00  1.0320276e-01]
[layer5_decoder_block_out] Token 0 Last 3: [-16.897732   -1.8697107  -4.786932 ]
[layer5_decoder_block_out] Token 1 First 3: [34.627014  -3.202592  -0.7552893]
[layer5_decoder_block_out] Token 1 Last 3: [-15.33169    -2.323644   -7.1075816]
[layer5_decoder_block_out] Token 2 First 3: [65.24426   -1.439943  -1.8407925]
[layer5_decoder_block_out] Token 2 Last 3: [-13.18919     3.1424634  -2.2570674]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 4.69439220e+00 -1.02468714e-01  4.69408976e-03]
[RMSNorm(raw)] Token 0 Last 3: [-0.76857895 -0.0850422  -0.21772952]
[RMSNorm(raw)] Token 1 First 3: [ 2.050101   -0.18961026 -0.04471709]
[RMSNorm(raw)] Token 1 Last 3: [-0.9077165  -0.13757192 -0.42080614]
[RMSNorm(raw)] Token 2 First 3: [ 0.6685403  -0.01475471 -0.0188621 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.13514607  0.03219997 -0.02312756]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.445863 31.210041 32.21713 ]
[RMSNorm(weight)] Last 3: [11.083166 23.686653 17.063845]
--------------------
[layer6_attention_norm] Shape: (1, 3, 768)
[layer6_attention_norm] Token 0 First 3: [16.176233   -3.3005214   0.15592419]
[layer6_attention_norm] Token 0 Last 3: [-9.286867  -2.0994074 -3.9330323]
[layer6_attention_norm] Token 1 First 3: [ 7.0643673 -6.107354  -1.4853734]
[layer6_attention_norm] Token 1 Last 3: [-10.968089   -3.3961902  -7.6013765]
[layer6_attention_norm] Token 2 First 3: [ 2.3036983  -0.47524968 -0.62654495]
[layer6_attention_norm] Token 2 Last 3: [-1.6329924   0.79490954 -0.41777265]
--------------------
[layer6_attention_norm] Shape: (1, 3, 768)
[layer6_attention_norm] Token 0 First 3: [16.176233   -3.3005214   0.15592419]
[layer6_attention_norm] Token 0 Last 3: [-9.286867  -2.0994074 -3.9330323]
[layer6_attention_norm] Token 1 First 3: [ 7.0643673 -6.107354  -1.4853734]
[layer6_attention_norm] Token 1 Last 3: [-10.968089   -3.3961902  -7.6013765]
[layer6_attention_norm] Token 2 First 3: [ 2.3036983  -0.47524968 -0.62654495]
[layer6_attention_norm] Token 2 Last 3: [-1.6329924   0.79490954 -0.41777265]
--------------------
[layer6_wq_weight] Shape: (768, 768)
[layer6_wq_weight] First 3: [ 0.00935921 -0.01925802  0.0138344 ]
[layer6_wq_weight] Last 3: [-0.00308292 -0.00617976  0.00896006]
--------------------
[layer6_wk_weight] Shape: (768, 256)
[layer6_wk_weight] First 3: [ 0.00425267  0.03804788 -0.00099398]
[layer6_wk_weight] Last 3: [-0.00269153 -0.00222733 -0.00787629]
--------------------
[layer6_wv_weight] Shape: (768, 256)
[layer6_wv_weight] First 3: [-0.00353955 -0.00133898 -0.00403017]
[layer6_wv_weight] Last 3: [0.00144972 0.00838298 0.00647674]
--------------------
[layer6_wq] Shape: (1, 3, 768)
[layer6_wq] Token 0 First 3: [ 0.17183757 -0.01990587  0.19557163]
[layer6_wq] Token 0 Last 3: [-0.33231634 -0.9154841   0.50257456]
[layer6_wq] Token 1 First 3: [0.8473882  1.000194   0.82631046]
[layer6_wq] Token 1 Last 3: [ 1.2095139 -0.8810345  1.8462942]
[layer6_wq] Token 2 First 3: [-0.35564873  0.1067626  -0.27073616]
[layer6_wq] Token 2 Last 3: [-0.26443768 -0.49229693  0.2018949 ]
--------------------
[layer6_wk] Shape: (1, 3, 256)
[layer6_wk] Token 0 First 3: [-0.26652032  0.4507855   0.58695424]
[layer6_wk] Token 0 Last 3: [-2.9942222 -2.892807   2.605007 ]
[layer6_wk] Token 1 First 3: [-1.4003911 -1.0388777 -1.9088132]
[layer6_wk] Token 1 Last 3: [-2.134135  -1.4001663  4.5264335]
[layer6_wk] Token 2 First 3: [-0.03900592  0.11317697  0.08993457]
[layer6_wk] Token 2 Last 3: [-1.4155325 -0.7665363  0.6904025]
--------------------
[layer6_wv] Shape: (1, 3, 256)
[layer6_wv] Token 0 First 3: [ 0.31912845 -0.44485617 -1.2922105 ]
[layer6_wv] Token 0 Last 3: [0.7562324  0.7499386  0.14702895]
[layer6_wv] Token 1 First 3: [ 1.1210947   0.18924087 -1.1318691 ]
[layer6_wv] Token 1 Last 3: [ 0.9125168 -0.8374327  1.2715151]
[layer6_wv] Token 2 First 3: [ 0.16049618 -0.10145817 -0.14981885]
[layer6_wv] Token 2 Last 3: [ 0.18268695  0.29809487 -0.3969986 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 0.10916703 -0.01264604  0.12424509]
[RMSNorm(raw)] Last 3: [-0.45293945 -0.8432259   0.34581366]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.6317787  0.44630456 0.42602766]
[RMSNorm(weight)] Last 3: [-0.22796902  0.10610836 -0.27838936]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.13193068  0.2231441   0.29054922]
[RMSNorm(raw)] Last 3: [-2.19583   -1.1890814  1.0709797]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.38865346 0.25760117 0.8637232 ]
[RMSNorm(weight)] Last 3: [1.7288299 1.0601269 2.0548368]
--------------------
[layer6_q_norm_out] Shape: (1, 3, 768)
[layer6_q_norm_out] Token 0 First 3: [ 0.17813644 -0.01829003  0.17717694]
[layer6_q_norm_out] Token 0 Last 3: [-0.0800643  -0.3160101   0.11317641]
[layer6_q_norm_out] Token 1 First 3: [0.61041677 0.63859683 0.5201804 ]
[layer6_q_norm_out] Token 1 Last 3: [ 0.26191375 -0.27334008  0.37369436]
[layer6_q_norm_out] Token 2 First 3: [-1.221979    0.32513234 -0.81293434]
[layer6_q_norm_out] Token 2 Last 3: [-0.34968328 -0.93269914  0.24954283]
--------------------
[layer6_k_norm_out] Shape: (1, 3, 256)
[layer6_k_norm_out] Token 0 First 3: [-0.183206    0.28062627  0.54150337]
[layer6_k_norm_out] Token 0 Last 3: [-4.044604  -2.9500465  3.9392393]
[layer6_k_norm_out] Token 1 First 3: [-0.7721237 -0.5187415 -1.4125001]
[layer6_k_norm_out] Token 1 Last 3: [-2.3122883 -1.1452945  5.4901953]
[layer6_k_norm_out] Token 2 First 3: [-0.08402398  0.22079024  0.26000816]
[layer6_k_norm_out] Token 2 Last 3: [-5.992047  -2.4496584  3.2716682]
--------------------
[layer6_attention_out_core] Shape: (1, 3, 768)
[layer6_attention_out_core] Token 0 First 3: [ 0.28133425 -0.12054627 -0.41273934]
[layer6_attention_out_core] Token 0 Last 3: [0.5033853  0.14727445 0.13747033]
[layer6_attention_out_core] Token 1 First 3: [ 0.23434763 -0.14509347 -0.39056838]
[layer6_attention_out_core] Token 1 Last 3: [0.51399964 0.03465414 0.21658772]
[layer6_attention_out_core] Token 2 First 3: [ 0.2599039  -0.12240456 -0.37924275]
[layer6_attention_out_core] Token 2 Last 3: [0.42906567 0.12601328 0.04569363]
--------------------
[layer6_wo_weight] Shape: (768, 768)
[layer6_wo_weight] First 3: [ 0.00716766  0.00804153 -0.00512167]
[layer6_wo_weight] Last 3: [-0.00623235 -0.01060564 -0.00195094]
--------------------
[layer6_attention_out_proj] Shape: (1, 3, 768)
[layer6_attention_out_proj] Token 0 First 3: [-0.03166859  0.07504349 -0.13474168]
[layer6_attention_out_proj] Token 0 Last 3: [ 0.04999234 -0.10978962 -0.09111187]
[layer6_attention_out_proj] Token 1 First 3: [-0.04751832  0.07819077 -0.1804846 ]
[layer6_attention_out_proj] Token 1 Last 3: [ 0.06241738 -0.10249111 -0.10271069]
[layer6_attention_out_proj] Token 2 First 3: [-0.0210776   0.06091039 -0.11392127]
[layer6_attention_out_proj] Token 2 Last 3: [ 0.03865227 -0.09749782 -0.06631272]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.20928971  0.49594352 -0.8904738 ]
[RMSNorm(raw)] Token 0 Last 3: [ 0.33038676 -0.72557193 -0.60213536]
[RMSNorm(raw)] Token 1 First 3: [-0.29310775  0.4823049  -1.113285  ]
[RMSNorm(raw)] Token 1 Last 3: [ 0.38500977 -0.63219696 -0.63355136]
[RMSNorm(raw)] Token 2 First 3: [-0.16010758  0.4626814  -0.8653574 ]
[RMSNorm(raw)] Token 2 Last 3: [ 0.29360652 -0.7406032  -0.5037181 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 4.342187    1.5637231  -0.90757465]
[RMSNorm(weight)] Last 3: [2.2172213 2.1360204 3.8225174]
--------------------
[layer6_ffn_norm] Shape: (1, 3, 768)
[layer6_ffn_norm] Token 0 First 3: [-1.1180648   1.2714618  -0.08230235]
[layer6_ffn_norm] Token 0 Last 3: [ 1.0629272 -2.2754085 -2.9038084]
[layer6_ffn_norm] Token 1 First 3: [-1.5658364   1.2364962  -0.10289574]
[layer6_ffn_norm] Token 1 Last 3: [ 1.2386616 -1.9825826 -3.0553124]
[layer6_ffn_norm] Token 2 First 3: [-0.8553246   1.186187   -0.07998095]
[layer6_ffn_norm] Token 2 Last 3: [ 0.9445971 -2.3225467 -2.4291892]
--------------------
[layer6_post_attention_norm] Shape: (1, 3, 768)
[layer6_post_attention_norm] Token 0 First 3: [-1.1180648   1.2714618  -0.08230235]
[layer6_post_attention_norm] Token 0 Last 3: [ 1.0629272 -2.2754085 -2.9038084]
[layer6_post_attention_norm] Token 1 First 3: [-1.5658364   1.2364962  -0.10289574]
[layer6_post_attention_norm] Token 1 Last 3: [ 1.2386616 -1.9825826 -3.0553124]
[layer6_post_attention_norm] Token 2 First 3: [-0.8553246   1.186187   -0.07998095]
[layer6_post_attention_norm] Token 2 Last 3: [ 0.9445971 -2.3225467 -2.4291892]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 6.5345311e+00 -6.2815078e-02  1.3377666e-03]
[RMSNorm(raw)] Token 0 Last 3: [-1.0135337  -0.26531544 -0.492259  ]
[RMSNorm(raw)] Token 1 First 3: [ 2.213745   -0.1316479  -0.05746326]
[RMSNorm(raw)] Token 1 Last 3: [-0.9436558  -0.28834087 -0.68049777]
[RMSNorm(raw)] Token 2 First 3: [ 0.7936761  -0.00312787 -0.02367599]
[RMSNorm(raw)] Token 2 Last 3: [-0.15093027  0.01010652 -0.05776411]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 0.5886444 18.71041   28.212387 ]
[RMSNorm(weight)] Last 3: [ 6.0809855 12.199661   8.061554 ]
--------------------
[layer6pre_ffn_norm] Shape: (1, 3, 768)
[layer6pre_ffn_norm] First 5 values: [10.381046295166016, -1.238110899925232, 0.03907935693860054, -0.4305238723754883, -3.4221527576446533]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.3027931749820709, -0.12573525309562683, -0.746435821056366, -0.5280484557151794, -0.81842041015625]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.2433830350637436, -0.28314492106437683, 0.2785184979438782, 0.3349030315876007, -0.02074873447418213]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-0.020319027826189995, -0.0035622597206383944, 0.019216477870941162, 0.012391391210258007, 0.007738465443253517]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.428961   -0.07520392  0.40568474]
[RMSNorm(raw)] Token 0 Last 3: [ 0.5081968  -0.57192284 -0.50947523]
[RMSNorm(raw)] Token 1 First 3: [ 0.93011165 -0.15189745 -1.2637075 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.55706924 -0.07370447 -0.3165544 ]
[RMSNorm(raw)] Token 2 First 3: [-0.1952197  -1.0466545   0.18584691]
[RMSNorm(raw)] Token 2 Last 3: [ 0.3170003   0.00991868 -0.47574592]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 9.543004    2.2837353  -0.56040716]
[RMSNorm(weight)] Last 3: [4.12661   4.0484886 5.804778 ]
--------------------
[layer6_post_ffn_norm] Shape: (1, 3, 768)
[layer6_post_ffn_norm] Token 0 First 3: [-4.5225377  -0.24694976  0.1783361 ]
[layer6_post_ffn_norm] Token 0 Last 3: [ 2.6053267 -2.887346  -3.4668658]
[layer6_post_ffn_norm] Token 1 First 3: [ 9.80617   -0.498791  -0.5555168]
[layer6_post_ffn_norm] Token 1 Last 3: [-2.8558767 -0.3720962 -2.1540825]
[layer6_post_ffn_norm] Token 2 First 3: [-2.058202   -3.4369361   0.08169697]
[layer6_post_ffn_norm] Token 2 Last 3: [ 1.6251369   0.05007432 -3.2373455 ]
--------------------
[layer6_decoder_block_out] Shape: (1, 3, 768)
[layer6_decoder_block_out] Token 0 First 3: [97.56881    -1.2283325   0.19923651]
[layer6_decoder_block_out] Token 0 Last 3: [-13.229478  -7.032465 -11.157606]
[layer6_decoder_block_out] Token 1 First 3: [42.867348  -2.4648867 -1.4137018]
[layer6_decoder_block_out] Token 1 Last 3: [-16.948904  -4.678323 -12.316977]
[layer6_decoder_block_out] Token 2 First 3: [62.330738  -3.690692  -1.8390765]
[layer6_decoder_block_out] Token 2 Last 3: [-10.619455     0.86999106  -7.923602  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 4.5293255  -0.05702148  0.00924893]
[RMSNorm(raw)] Token 0 Last 3: [-0.61413693 -0.3264601  -0.5179568 ]
[RMSNorm(raw)] Token 1 First 3: [ 2.3803985  -0.13687369 -0.07850202]
[RMSNorm(raw)] Token 1 Last 3: [-0.9411626 -0.2597845 -0.6839544]
[RMSNorm(raw)] Token 2 First 3: [ 2.6196387  -0.15511255 -0.07729278]
[RMSNorm(raw)] Token 2 Last 3: [-0.4463149   0.03656402 -0.33301347]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 4.933473 29.322304 55.57505 ]
[RMSNorm(weight)] Last 3: [13.187588 17.193205 15.006489]
--------------------
[layer7_attention_norm] Shape: (1, 3, 768)
[layer7_attention_norm] Token 0 First 3: [26.874632  -1.7290226  0.5232586]
[layer7_attention_norm] Token 0 Last 3: [-8.713121  -5.9393554 -8.290669 ]
[layer7_attention_norm] Token 1 First 3: [14.12403  -4.150326 -4.441256]
[layer7_attention_norm] Token 1 Last 3: [-13.352827   -4.7263126 -10.947709 ]
[layer7_attention_norm] Token 2 First 3: [15.543555  -4.7033696 -4.372843 ]
[layer7_attention_norm] Token 2 Last 3: [-6.332132   0.6652167 -5.3303766]
--------------------
[layer7_attention_norm] Shape: (1, 3, 768)
[layer7_attention_norm] Token 0 First 3: [26.874632  -1.7290226  0.5232586]
[layer7_attention_norm] Token 0 Last 3: [-8.713121  -5.9393554 -8.290669 ]
[layer7_attention_norm] Token 1 First 3: [14.12403  -4.150326 -4.441256]
[layer7_attention_norm] Token 1 Last 3: [-13.352827   -4.7263126 -10.947709 ]
[layer7_attention_norm] Token 2 First 3: [15.543555  -4.7033696 -4.372843 ]
[layer7_attention_norm] Token 2 Last 3: [-6.332132   0.6652167 -5.3303766]
--------------------
[layer7_wq_weight] Shape: (768, 768)
[layer7_wq_weight] First 3: [-0.01693323 -0.00140211 -0.02172134]
[layer7_wq_weight] Last 3: [1.3851814e-02 4.1004037e-03 5.3754833e-05]
--------------------
[layer7_wk_weight] Shape: (768, 256)
[layer7_wk_weight] First 3: [ 0.01069324 -0.01964005 -0.0015153 ]
[layer7_wk_weight] Last 3: [-0.00540332 -0.00367641 -0.01008447]
--------------------
[layer7_wv_weight] Shape: (768, 256)
[layer7_wv_weight] First 3: [0.00123662 0.00495114 0.00692825]
[layer7_wv_weight] Last 3: [ 0.00368901 -0.00814211 -0.00011372]
--------------------
[layer7_wq] Shape: (1, 3, 768)
[layer7_wq] Token 0 First 3: [-4.8775234   0.15584052  3.461484  ]
[layer7_wq] Token 0 Last 3: [ 0.40856987 -0.3002264   1.481882  ]
[layer7_wq] Token 1 First 3: [-6.826     -7.0576105 11.064029 ]
[layer7_wq] Token 1 Last 3: [-0.6609167 -0.5226141  2.8166752]
[layer7_wq] Token 2 First 3: [ -5.052767 -11.392544   7.42154 ]
[layer7_wq] Token 2 Last 3: [-0.84869105 -0.10468352  0.56959003]
--------------------
[layer7_wk] Shape: (1, 3, 256)
[layer7_wk] Token 0 First 3: [-3.866961  -1.0471171  1.5643374]
[layer7_wk] Token 0 Last 3: [0.28425828 0.15363365 3.2333484 ]
[layer7_wk] Token 1 First 3: [-7.269989   1.723392   3.7828069]
[layer7_wk] Token 1 Last 3: [ 1.4729033 -1.1928282  1.7043465]
[layer7_wk] Token 2 First 3: [-6.8859115   0.8288034   0.85557234]
[layer7_wk] Token 2 Last 3: [0.6862143  0.16251373 5.592122  ]
--------------------
[layer7_wv] Shape: (1, 3, 256)
[layer7_wv] Token 0 First 3: [ 1.9602413  -0.11118907 -0.17077452]
[layer7_wv] Token 0 Last 3: [ 0.9524512  -0.7102244   0.59479284]
[layer7_wv] Token 1 First 3: [ 1.8766528  -1.2879506   0.48589826]
[layer7_wv] Token 1 Last 3: [ 1.8299806  -0.5168458  -0.17167234]
[layer7_wv] Token 2 First 3: [-1.2839499  -0.81251    -0.18086731]
[layer7_wv] Token 2 Last 3: [-0.69810945 -1.0990438  -1.1174041 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-2.7756393   0.08868375  1.9698175 ]
[RMSNorm(raw)] Last 3: [-0.40536308 -0.05000033  0.27205515]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.6483034  -1.0384779   0.16914108]
[RMSNorm(weight)] Last 3: [0.29809374 0.57324547 0.05076126]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-1.3689448  -0.37069044  0.5537918 ]
[RMSNorm(raw)] Last 3: [0.15895122 0.03764386 1.295331  ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.1711627  -0.38196898  0.07157479]
[RMSNorm(weight)] Last 3: [1.1008506  0.86995864 1.0449506 ]
--------------------
[layer7_q_norm_out] Shape: (1, 3, 768)
[layer7_q_norm_out] Token 0 First 3: [-0.97618294 -0.00341236  2.3029945 ]
[layer7_q_norm_out] Token 0 Last 3: [ 0.2852667  -0.25405285  0.8375222 ]
[layer7_q_norm_out] Token 1 First 3: [-0.7353708   0.08318421  3.9623432 ]
[layer7_q_norm_out] Token 1 Last 3: [-0.29815194 -0.2857344   1.0285506 ]
[layer7_q_norm_out] Token 2 First 3: [-0.6888389   0.16992305  3.3634205 ]
[layer7_q_norm_out] Token 2 Last 3: [-0.5261993 -0.0786628  0.285865 ]
--------------------
[layer7_k_norm_out] Shape: (1, 3, 256)
[layer7_k_norm_out] Token 0 First 3: [-1.6032571  -0.22909819  0.5934294 ]
[layer7_k_norm_out] Token 0 Last 3: [0.21140945 0.10170317 2.3407307 ]
[layer7_k_norm_out] Token 1 First 3: [-2.5278044   0.31621817  1.2034531 ]
[layer7_k_norm_out] Token 1 Last 3: [ 0.9186749 -0.6622201  1.0347445]
[layer7_k_norm_out] Token 2 First 3: [-1.8680254  0.1186495  0.2123652]
[layer7_k_norm_out] Token 2 Last 3: [0.33393276 0.07039246 2.6488879 ]
--------------------
[layer7_attention_out_core] Shape: (1, 3, 768)
[layer7_attention_out_core] Token 0 First 3: [ 1.5328718  -0.31140774 -0.11096812]
[layer7_attention_out_core] Token 0 Last 3: [ 1.0375761  -0.69732875 -0.21654549]
[layer7_attention_out_core] Token 1 First 3: [ 1.7499614  -0.3417477  -0.06648379]
[layer7_attention_out_core] Token 1 Last 3: [ 0.39473212 -0.8437508  -0.25345895]
[layer7_attention_out_core] Token 2 First 3: [ 1.2034366  -0.83329815  0.14352152]
[layer7_attention_out_core] Token 2 Last 3: [ 0.68383527 -0.7771842  -0.14673594]
--------------------
[layer7_wo_weight] Shape: (768, 768)
[layer7_wo_weight] First 3: [ 0.0116012  -0.00213546 -0.00463799]
[layer7_wo_weight] Last 3: [ 0.0086222  -0.00452778 -0.00360781]
--------------------
[layer7_attention_out_proj] Shape: (1, 3, 768)
[layer7_attention_out_proj] Token 0 First 3: [ 0.12696594 -0.03130077 -1.1911099 ]
[layer7_attention_out_proj] Token 0 Last 3: [ 0.5630344  -0.11775916 -0.11224168]
[layer7_attention_out_proj] Token 1 First 3: [-0.0863626  -0.08893598 -1.3946869 ]
[layer7_attention_out_proj] Token 1 Last 3: [ 0.67348063 -0.09858789 -0.20907977]
[layer7_attention_out_proj] Token 2 First 3: [-0.07658488 -0.02687559 -1.4624882 ]
[layer7_attention_out_proj] Token 2 Last 3: [ 0.7242523  -0.26976013 -0.11193778]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.2803809  -0.06912199 -2.6303468 ]
[RMSNorm(raw)] Token 0 Last 3: [ 1.2433578  -0.26004943 -0.24786508]
[RMSNorm(raw)] Token 1 First 3: [-0.17151594 -0.17662667 -2.7698452 ]
[RMSNorm(raw)] Token 1 Last 3: [ 1.3375311  -0.19579534 -0.415232  ]
[RMSNorm(raw)] Token 2 First 3: [-0.1454143 -0.0510296 -2.7768757]
[RMSNorm(raw)] Token 2 Last 3: [ 1.3751624  -0.5122027  -0.21254006]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 4.75112    5.1255875 -0.9275312]
[RMSNorm(weight)] Last 3: [3.1045494 1.8965023 5.8769774]
--------------------
[layer7_ffn_norm] Shape: (1, 3, 768)
[layer7_ffn_norm] Token 0 First 3: [ 1.6125042  -0.42341283 -0.19061811]
[layer7_ffn_norm] Token 0 Last 3: [ 5.1034236 -0.7532338 -1.7045625]
[layer7_ffn_norm] Token 1 First 3: [-0.98640877 -1.0819421  -0.2007274 ]
[layer7_ffn_norm] Token 1 Last 3: [ 5.4899626 -0.5671216 -2.8555412]
[layer7_ffn_norm] Token 2 First 3: [-0.83629507 -0.31258625 -0.2012369 ]
[layer7_ffn_norm] Token 2 Last 3: [ 5.644422  -1.4835962 -1.4616332]
--------------------
[layer7_post_attention_norm] Shape: (1, 3, 768)
[layer7_post_attention_norm] Token 0 First 3: [ 1.6125042  -0.42341283 -0.19061811]
[layer7_post_attention_norm] Token 0 Last 3: [ 5.1034236 -0.7532338 -1.7045625]
[layer7_post_attention_norm] Token 1 First 3: [-0.98640877 -1.0819421  -0.2007274 ]
[layer7_post_attention_norm] Token 1 Last 3: [ 5.4899626 -0.5671216 -2.8555412]
[layer7_post_attention_norm] Token 2 First 3: [-0.83629507 -0.31258625 -0.2012369 ]
[layer7_post_attention_norm] Token 2 Last 3: [ 5.644422  -1.4835962 -1.4616332]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 4.5229516e+00 -7.5324312e-02  3.9302369e-04]
[RMSNorm(raw)] Token 0 Last 3: [-0.37057135 -0.35505015 -0.58655167]
[RMSNorm(raw)] Token 1 First 3: [ 2.287575   -0.193731   -0.08818159]
[RMSNorm(raw)] Token 1 Last 3: [-0.62589777 -0.2865109  -0.82873666]
[RMSNorm(raw)] Token 2 First 3: [ 2.3563638  -0.1533989  -0.07818139]
[RMSNorm(raw)] Token 2 Last 3: [-0.19063492 -0.02351232 -0.35962644]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 0.7668445 11.152156  23.036774 ]
[RMSNorm(weight)] Last 3: [6.127179  9.947186  6.2635365]
--------------------
[layer7pre_ffn_norm] Shape: (1, 3, 768)
[layer7pre_ffn_norm] First 5 values: [7.991352081298828, -0.9153527617454529, 0.009447021409869194, -0.10028835386037827, -1.5181305408477783]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.03931618109345436, 0.048888497054576874, 0.13904577493667603, -0.3693363666534424, 0.5871014595031738]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.24236012995243073, 0.29806315898895264, -0.0992790088057518, -0.3870760202407837, -0.04729168117046356]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.09202271699905396, 0.015355514362454414, 0.02995339035987854, -0.15351268649101257, 0.004450017586350441]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [2.0462985 0.3414588 0.6660701]
[RMSNorm(raw)] Token 0 Last 3: [-1.3144966 -1.4547122 -1.1675489]
[RMSNorm(raw)] Token 1 First 3: [-1.5444686  -1.3516644   0.11780916]
[RMSNorm(raw)] Token 1 Last 3: [-0.00122279 -0.7724678  -0.05513322]
[RMSNorm(raw)] Token 2 First 3: [0.46240133 0.5997918  0.14262317]
[RMSNorm(raw)] Token 2 Last 3: [ 1.2411355  -0.14109252 -0.7981809 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 8.953648   3.6267529 -0.616753 ]
[RMSNorm(weight)] Last 3: [4.9957266 5.5258245 8.857075 ]
--------------------
[layer7_post_ffn_norm] Shape: (1, 3, 768)
[layer7_post_ffn_norm] Token 0 First 3: [20.368134    1.5798454   0.25526938]
[layer7_post_ffn_norm] Token 0 Last 3: [ -7.8813624  -9.4931965 -11.508616 ]
[layer7_post_ffn_norm] Token 1 First 3: [-15.373096    -6.253817     0.04515001]
[layer7_post_ffn_norm] Token 1 Last 3: [-0.00733149 -5.0409894  -0.5434522 ]
[layer7_post_ffn_norm] Token 2 First 3: [4.60258    2.7750885  0.05465991]
[layer7_post_ffn_norm] Token 2 Last 3: [ 7.441509  -0.9207451 -7.8677287]
--------------------
[layer7_decoder_block_out] Shape: (1, 3, 768)
[layer7_decoder_block_out] Token 0 First 3: [ 1.19549446e+02 -7.18998909e-02  2.63887763e-01]
[layer7_decoder_block_out] Token 0 Last 3: [-16.007418 -17.278896 -24.370785]
[layer7_decoder_block_out] Token 1 First 3: [26.507843  -9.800646  -1.5692792]
[layer7_decoder_block_out] Token 1 Last 3: [-11.466273 -10.286434 -15.71597 ]
[layer7_decoder_block_out] Token 2 First 3: [66.09702   -1.2281897 -1.9856535]
[layer7_decoder_block_out] Token 2 Last 3: [  2.4664755  -1.5343502 -17.252964 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.2983246e+00 -7.8084337e-04  2.8658598e-03]
[RMSNorm(raw)] Token 0 Last 3: [-0.1738429  -0.18765135 -0.2646703 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.77015394 -0.28474614 -0.04559355]
[RMSNorm(raw)] Token 1 Last 3: [-0.33313897 -0.29886016 -0.4566089 ]
[RMSNorm(raw)] Token 2 First 3: [ 1.0062507  -0.01869777 -0.03022928]
[RMSNorm(raw)] Token 2 Last 3: [ 0.03754924 -0.02335871 -0.26265642]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 4.930264 34.815693 43.649643]
[RMSNorm(weight)] Last 3: [16.629766 19.69869  15.40546 ]
--------------------
[layer8_attention_norm] Shape: (1, 3, 768)
[layer8_attention_norm] Token 0 First 3: [ 7.6994076  -0.02796645  0.12795961]
[layer8_attention_norm] Token 0 Last 3: [-3.0648098 -3.8841372 -4.342038 ]
[layer8_attention_norm] Token 1 First 3: [  4.5672164 -10.19838    -2.0357356]
[layer8_attention_norm] Token 1 Last 3: [-5.8731623 -6.186014  -7.490879 ]
[layer8_attention_norm] Token 2 First 3: [ 5.9673324  -0.66967356 -1.3497266 ]
[layer8_attention_norm] Token 2 Last 3: [ 0.6619843  -0.48349467 -4.3089995 ]
--------------------
[layer8_attention_norm] Shape: (1, 3, 768)
[layer8_attention_norm] Token 0 First 3: [ 7.6994076  -0.02796645  0.12795961]
[layer8_attention_norm] Token 0 Last 3: [-3.0648098 -3.8841372 -4.342038 ]
[layer8_attention_norm] Token 1 First 3: [  4.5672164 -10.19838    -2.0357356]
[layer8_attention_norm] Token 1 Last 3: [-5.8731623 -6.186014  -7.490879 ]
[layer8_attention_norm] Token 2 First 3: [ 5.9673324  -0.66967356 -1.3497266 ]
[layer8_attention_norm] Token 2 Last 3: [ 0.6619843  -0.48349467 -4.3089995 ]
--------------------
[layer8_wq_weight] Shape: (768, 768)
[layer8_wq_weight] First 3: [-0.01079667  0.00651396 -0.00234769]
[layer8_wq_weight] Last 3: [ 0.00997735 -0.00948776  0.00046198]
--------------------
[layer8_wk_weight] Shape: (768, 256)
[layer8_wk_weight] First 3: [-0.02268327  0.008814    0.01363951]
[layer8_wk_weight] Last 3: [-0.00474919  0.00939343 -0.00171755]
--------------------
[layer8_wv_weight] Shape: (768, 256)
[layer8_wv_weight] First 3: [ 7.2040959e-05 -7.4350117e-03 -8.5010724e-03]
[layer8_wv_weight] Last 3: [ 0.01706863 -0.00506921  0.01849164]
--------------------
[layer8_wq] Shape: (1, 3, 768)
[layer8_wq] Token 0 First 3: [0.32174098 1.1916242  0.5739362 ]
[layer8_wq] Token 0 Last 3: [-0.10781452 -0.2855209  -0.73727405]
[layer8_wq] Token 1 First 3: [1.1218615 5.3795233 2.0795324]
[layer8_wq] Token 1 Last 3: [-1.133005   -2.002005   -0.18140215]
[layer8_wq] Token 2 First 3: [0.61798805 0.6243179  1.7667313 ]
[layer8_wq] Token 2 Last 3: [-0.93564236 -0.02334481 -0.49293813]
--------------------
[layer8_wk] Shape: (1, 3, 256)
[layer8_wk] Token 0 First 3: [ 0.13865733 -0.9958149   0.17586005]
[layer8_wk] Token 0 Last 3: [-2.2127419 -1.0766385 -1.9038285]
[layer8_wk] Token 1 First 3: [ 2.5717497 -4.8172245 -1.0279435]
[layer8_wk] Token 1 Last 3: [-4.477601  -0.6040386 -2.2202153]
[layer8_wk] Token 2 First 3: [ 1.9948093 -1.8935864  0.421695 ]
[layer8_wk] Token 2 Last 3: [-2.1450477 -1.5406569 -2.1030214]
--------------------
[layer8_wv] Shape: (1, 3, 256)
[layer8_wv] Token 0 First 3: [ 0.16555882  0.07418986 -0.8510755 ]
[layer8_wv] Token 0 Last 3: [-0.37832254 -0.44652268 -0.6119561 ]
[layer8_wv] Token 1 First 3: [-0.61606383  0.93108124  2.6111784 ]
[layer8_wv] Token 1 Last 3: [-1.5868833   0.33250815 -0.52187234]
[layer8_wv] Token 2 First 3: [0.4943915  0.14672452 1.1862249 ]
[layer8_wv] Token 2 Last 3: [ 0.01977396 -0.70371276  0.0487183 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [0.469412   1.7385497  0.83735853]
[RMSNorm(raw)] Last 3: [-1.0880075  -0.02714641 -0.57321084]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.7458158 -0.2736112  1.6360042]
[RMSNorm(weight)] Last 3: [ 0.03704356  0.4429922  -0.3112579 ]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.09395944 -0.67480177  0.11916941]
[RMSNorm(raw)] Last 3: [-1.2240602  -0.87916774 -1.2000781 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.96977156 -0.3612421  -0.03661092]
[RMSNorm(weight)] Last 3: [ 0.6196683  -0.03704255  0.935068  ]
--------------------
[layer8_q_norm_out] Shape: (1, 3, 768)
[layer8_q_norm_out] Token 0 First 3: [0.8195069 1.262863  2.2072806]
[layer8_q_norm_out] Token 0 Last 3: [-0.18099457 -0.66694987 -0.82200956]
[layer8_q_norm_out] Token 1 First 3: [1.030734  2.0564675 2.8848333]
[layer8_q_norm_out] Token 1 Last 3: [-0.6108526  -1.5018852  -0.06495412]
[layer8_q_norm_out] Token 2 First 3: [0.9669577 0.406447  4.1739345]
[layer8_q_norm_out] Token 2 Last 3: [-1.1283112  -0.03917206 -0.39479443]
--------------------
[layer8_k_norm_out] Shape: (1, 3, 256)
[layer8_k_norm_out] Token 0 First 3: [ 0.18507865 -0.43103498  0.11480651]
[layer8_k_norm_out] Token 0 Last 3: [-2.4285913 -0.7025457 -2.496443 ]
[layer8_k_norm_out] Token 1 First 3: [ 1.8636639 -1.1320255 -0.3643292]
[layer8_k_norm_out] Token 1 Last 3: [-2.6680532  -0.21399064 -1.5805722 ]
[layer8_k_norm_out] Token 2 First 3: [ 2.242245   -0.6902195   0.23182806]
[layer8_k_norm_out] Token 2 Last 3: [-1.9825714 -0.8466011 -2.3222327]
--------------------
[layer8_attention_out_core] Shape: (1, 3, 768)
[layer8_attention_out_core] Token 0 First 3: [0.39619702 0.15365066 0.8085    ]
[layer8_attention_out_core] Token 0 Last 3: [-0.66727686 -0.2604775  -0.33671972]
[layer8_attention_out_core] Token 1 First 3: [0.46182555 0.14727663 1.0468745 ]
[layer8_attention_out_core] Token 1 Last 3: [-0.06124663 -0.65142137 -0.0238639 ]
[layer8_attention_out_core] Token 2 First 3: [0.27751356 0.14323673 0.20039299]
[layer8_attention_out_core] Token 2 Last 3: [-0.133582   -0.6046446  -0.19700621]
--------------------
[layer8_wo_weight] Shape: (768, 768)
[layer8_wo_weight] First 3: [ 0.00589645  0.00586515 -0.00348742]
[layer8_wo_weight] Last 3: [-0.0016676  -0.0041287  -0.01261117]
--------------------
[layer8_attention_out_proj] Shape: (1, 3, 768)
[layer8_attention_out_proj] Token 0 First 3: [0.23494251 0.22958249 1.0778512 ]
[layer8_attention_out_proj] Token 0 Last 3: [0.01381793 0.12469696 0.16391869]
[layer8_attention_out_proj] Token 1 First 3: [0.01940455 0.2340375  1.2207086 ]
[layer8_attention_out_proj] Token 1 Last 3: [-0.04170741  0.00470692  0.14730787]
[layer8_attention_out_proj] Token 2 First 3: [0.00347464 0.10864522 1.015947  ]
[layer8_attention_out_proj] Token 2 Last 3: [ 0.00379393 -0.03819664  0.17723426]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.43684983 0.42688346 2.004146  ]
[RMSNorm(raw)] Token 0 Last 3: [0.02569293 0.23186032 0.30478883]
[RMSNorm(raw)] Token 1 First 3: [0.03603748 0.43464664 2.2670593 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.07745761  0.00874153  0.27357528]
[RMSNorm(raw)] Token 2 First 3: [0.00734377 0.22962527 2.1472375 ]
[RMSNorm(raw)] Token 2 Last 3: [ 0.00801859 -0.08072986  0.37459046]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [11.299615  19.38775   -0.9683548]
[RMSNorm(weight)] Last 3: [ 8.903624   7.9920654 21.086636 ]
--------------------
[layer8_ffn_norm] Shape: (1, 3, 768)
[layer8_ffn_norm] Token 0 First 3: [5.3730845  8.703194   0.06342156]
[layer8_ffn_norm] Token 0 Last 3: [0.25445312 2.0849032  6.7317595 ]
[layer8_ffn_norm] Token 1 First 3: [0.44324717 8.861467   0.0717415 ]
[layer8_ffn_norm] Token 1 Last 3: [-0.76711106  0.07860441  6.0423574 ]
[layer8_ffn_norm] Token 2 First 3: [0.09032549 4.681543   0.06794971]
[layer8_ffn_norm] Token 2 Last 3: [ 0.07941306 -0.7259281   8.273443  ]
--------------------
[layer8_post_attention_norm] Shape: (1, 3, 768)
[layer8_post_attention_norm] Token 0 First 3: [5.3730845  8.703194   0.06342156]
[layer8_post_attention_norm] Token 0 Last 3: [0.25445312 2.0849032  6.7317595 ]
[layer8_post_attention_norm] Token 1 First 3: [0.44324717 8.861467   0.0717415 ]
[layer8_post_attention_norm] Token 1 Last 3: [-0.76711106  0.07860441  6.0423574 ]
[layer8_post_attention_norm] Token 2 First 3: [0.09032549 4.681543   0.06794971]
[layer8_post_attention_norm] Token 2 Last 3: [ 0.07941306 -0.7259281   8.273443  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.9220545  0.13280085 0.00503597]
[RMSNorm(raw)] Token 0 Last 3: [-0.24237467 -0.23377433 -0.27139354]
[RMSNorm(raw)] Token 1 First 3: [ 0.7650767  -0.02666102 -0.0425115 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.3472764  -0.28977576 -0.27461064]
[RMSNorm(raw)] Token 2 First 3: [ 1.3110834   0.06840634 -0.03798717]
[RMSNorm(raw)] Token 2 Last 3: [ 0.05043067 -0.04477311 -0.17787239]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 4.2954383 14.65959   58.16114  ]
[RMSNorm(weight)] Last 3: [13.058962 18.93444   9.931501]
--------------------
[layer8pre_ffn_norm] Shape: (1, 3, 768)
[layer8pre_ffn_norm] First 5 values: [10.178121566772461, 2.079606771469116, 0.2979338467121124, -0.5905562043190002, -0.26662731170654297]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.15912789106369019, -0.18338467180728912, -0.1424943208694458, 0.4699854850769043, -1.7773809432983398]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.2926299273967743, -0.005394302308559418, 0.1492111086845398, -0.4103964567184448, -1.5255850553512573]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.03605278581380844, 0.016192089766263962, 0.0318216010928154, 0.1679576188325882, -0.004522603005170822]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.0973197  0.49283013 0.96853733]
[RMSNorm(raw)] Token 0 Last 3: [ 0.7176764  -0.70686007 -0.55436337]
[RMSNorm(raw)] Token 1 First 3: [-0.9623729   1.3469499  -0.02374124]
[RMSNorm(raw)] Token 1 Last 3: [ 0.06243005 -0.3294303  -0.4489685 ]
[RMSNorm(raw)] Token 2 First 3: [1.1052252  0.24436341 0.60306615]
[RMSNorm(raw)] Token 2 Last 3: [-1.1735885  0.6505898  1.3921832]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [10.587617   6.7173166 -0.6914996]
[RMSNorm(weight)] Last 3: [ 6.526496  8.182114 13.799425]
--------------------
[layer8_post_ffn_norm] Shape: (1, 3, 768)
[layer8_post_ffn_norm] Token 0 First 3: [12.715321    3.8033261   0.29879415]
[layer8_post_ffn_norm] Token 0 Last 3: [ 5.4015884 -6.4904695 -8.204259 ]
[layer8_post_ffn_norm] Token 1 First 3: [-1.1151608e+01  1.0394839e+01 -7.3241810e-03]
[layer8_post_ffn_norm] Token 1 Last 3: [ 0.46987948 -3.0248666  -6.6444755 ]
[layer8_post_ffn_norm] Token 2 First 3: [12.806927    1.8858298   0.18604615]
[layer8_post_ffn_norm] Token 2 Last 3: [-8.833009   5.9737897 20.60351  ]
--------------------
[layer8_decoder_block_out] Shape: (1, 3, 768)
[layer8_decoder_block_out] Token 0 First 3: [137.63785     12.43462      0.62610346]
[layer8_decoder_block_out] Token 0 Last 3: [-10.351377 -21.684462 -25.843285]
[layer8_decoder_block_out] Token 1 First 3: [15.799481  9.455661 -1.504862]
[layer8_decoder_block_out] Token 1 Last 3: [-11.763505 -13.232697 -16.318089]
[layer8_decoder_block_out] Token 2 First 3: [78.99428    5.339183  -1.7316577]
[layer8_decoder_block_out] Token 2 Last 3: [-6.2871203  3.7135115 11.623989 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.4281263  0.12902126 0.00649643]
[RMSNorm(raw)] Token 0 Last 3: [-0.10740558 -0.22499734 -0.26814917]
[RMSNorm(raw)] Token 1 First 3: [ 0.3218312   0.19260927 -0.03065363]
[RMSNorm(raw)] Token 1 Last 3: [-0.23961943 -0.26954648 -0.33239508]
[RMSNorm(raw)] Token 2 First 3: [ 0.8852871   0.0598361  -0.01940665]
[RMSNorm(raw)] Token 2 Last 3: [-0.07045962  0.04161724  0.1302698 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.215448 14.686394 56.168465]
[RMSNorm(weight)] Last 3: [ 9.253189  11.453188   6.5596237]
--------------------
[layer9_attention_norm] Shape: (1, 3, 768)
[layer9_attention_norm] Token 0 First 3: [6.020192  2.0238783 0.371391 ]
[layer9_attention_norm] Token 0 Last 3: [-1.1012497 -2.8019342 -2.0271068]
[layer9_attention_norm] Token 1 First 3: [ 1.3566626  3.0213447 -1.7524211]
[layer9_attention_norm] Token 1 Last 3: [-2.4568634 -3.356713  -2.5127816]
[layer9_attention_norm] Token 2 First 3: [ 3.7318816  0.9386127 -1.1094484]
[layer9_attention_norm] Token 2 Last 3: [-0.7224358   0.51826733  0.9847906 ]
--------------------
[layer9_attention_norm] Shape: (1, 3, 768)
[layer9_attention_norm] Token 0 First 3: [6.020192  2.0238783 0.371391 ]
[layer9_attention_norm] Token 0 Last 3: [-1.1012497 -2.8019342 -2.0271068]
[layer9_attention_norm] Token 1 First 3: [ 1.3566626  3.0213447 -1.7524211]
[layer9_attention_norm] Token 1 Last 3: [-2.4568634 -3.356713  -2.5127816]
[layer9_attention_norm] Token 2 First 3: [ 3.7318816  0.9386127 -1.1094484]
[layer9_attention_norm] Token 2 Last 3: [-0.7224358   0.51826733  0.9847906 ]
--------------------
[layer9_wq_weight] Shape: (768, 768)
[layer9_wq_weight] First 3: [ 0.00333168  0.00979576 -0.00901843]
[layer9_wq_weight] Last 3: [-0.00689393 -0.0057532  -0.00282792]
--------------------
[layer9_wk_weight] Shape: (768, 256)
[layer9_wk_weight] First 3: [-0.00308929  0.00824316 -0.01089084]
[layer9_wk_weight] Last 3: [-9.0342874e-05 -1.0530296e-02 -5.5089886e-03]
--------------------
[layer9_wv_weight] Shape: (768, 256)
[layer9_wv_weight] First 3: [-0.0051037   0.01371631  0.00820035]
[layer9_wv_weight] Last 3: [-0.0035729  -0.0233551   0.01184719]
--------------------
[layer9_wq] Shape: (1, 3, 768)
[layer9_wq] Token 0 First 3: [-0.3728521  -0.19157052  0.6109768 ]
[layer9_wq] Token 0 Last 3: [-0.05031184 -0.22538884 -0.5577134 ]
[layer9_wq] Token 1 First 3: [-0.2639129  -0.36898774  0.451605  ]
[layer9_wq] Token 1 Last 3: [ 0.9174749  -1.363739   -0.47085997]
[layer9_wq] Token 2 First 3: [-0.45338392 -0.03860901  0.13883558]
[layer9_wq] Token 2 Last 3: [-0.08503281 -0.5867337  -0.39902067]
--------------------
[layer9_wk] Shape: (1, 3, 256)
[layer9_wk] Token 0 First 3: [ 0.07264699  0.19065773 -1.8375771 ]
[layer9_wk] Token 0 Last 3: [-0.78718865 -0.51240325 -0.6699846 ]
[layer9_wk] Token 1 First 3: [ 0.6755866   0.04212292 -0.4936011 ]
[layer9_wk] Token 1 Last 3: [ 0.15089959 -1.0867512  -0.47830248]
[layer9_wk] Token 2 First 3: [-0.14943077  0.02764793 -1.8973615 ]
[layer9_wk] Token 2 Last 3: [-0.3455023  -0.90480655 -1.0357568 ]
--------------------
[layer9_wv] Shape: (1, 3, 256)
[layer9_wv] Token 0 First 3: [-0.04652154  0.3443659   0.05182212]
[layer9_wv] Token 0 Last 3: [-0.00916395  0.1830126  -0.49642667]
[layer9_wv] Token 1 First 3: [ 0.40662104 -2.1050782   0.03916147]
[layer9_wv] Token 1 Last 3: [-0.4655459 -0.6462456 -0.9541379]
[layer9_wv] Token 2 First 3: [ 0.23552784  1.6601744  -0.1028242 ]
[layer9_wv] Token 2 Last 3: [-0.07317817 -0.39559698  0.05914639]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.51734024 -0.2658082   0.8477434 ]
[RMSNorm(raw)] Last 3: [-0.15508309 -1.0700867  -0.7277351 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.15561078  0.39126742 -0.255392  ]
[RMSNorm(weight)] Last 3: [ 0.732191   -0.13045217  0.28390315]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.1043919   0.27397037 -2.640552  ]
[RMSNorm(raw)] Last 3: [-0.27012095 -0.7073968  -0.8097764 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.28549507  0.26227978 -1.0103027 ]
[RMSNorm(weight)] Last 3: [0.73604375 2.2042427  0.9029487 ]
--------------------
[layer9_q_norm_out] Shape: (1, 3, 768)
[layer9_q_norm_out] Token 0 First 3: [-0.59784395 -0.36981028  0.63123655]
[layer9_q_norm_out] Token 0 Last 3: [-0.08406696 -0.18905373 -0.69072104]
[layer9_q_norm_out] Token 1 First 3: [-0.30848053 -0.519252    0.34012774]
[layer9_q_norm_out] Token 1 Last 3: [ 1.5072334  -1.1246444  -0.57334304]
[layer9_q_norm_out] Token 2 First 3: [-0.95229053 -0.09763174  0.18789718]
[layer9_q_norm_out] Token 2 Last 3: [-0.26863354 -0.9304916  -0.9343414 ]
--------------------
[layer9_k_norm_out] Shape: (1, 3, 256)
[layer9_k_norm_out] Token 0 First 3: [0.13419527 0.34582725 0.02720472]
[layer9_k_norm_out] Token 0 Last 3: [-1.963761  -2.3593178 -1.8320657]
[layer9_k_norm_out] Token 1 First 3: [0.78222716 0.04789118 0.00458044]
[layer9_k_norm_out] Token 1 Last 3: [ 0.23595554 -3.13644    -0.8198061 ]
[layer9_k_norm_out] Token 2 First 3: [-0.15018196  0.02728511  0.01528294]
[layer9_k_norm_out] Token 2 Last 3: [-0.46894178 -2.266671   -1.5409629 ]
--------------------
[layer9_attention_out_core] Shape: (1, 3, 768)
[layer9_attention_out_core] Token 0 First 3: [ 0.14148888  0.56568563 -0.01737849]
[layer9_attention_out_core] Token 0 Last 3: [-0.05714788 -0.15194598 -0.21237722]
[layer9_attention_out_core] Token 1 First 3: [ 0.16181916  1.1013451  -0.05130266]
[layer9_attention_out_core] Token 1 Last 3: [-0.1910971  -0.35178936 -0.40509644]
[layer9_attention_out_core] Token 2 First 3: [ 0.15476075  1.1898066  -0.05370488]
[layer9_attention_out_core] Token 2 Last 3: [-0.04932208 -0.14152552 -0.19943522]
--------------------
[layer9_wo_weight] Shape: (768, 768)
[layer9_wo_weight] First 3: [ 0.00870713  0.00794372 -0.0088894 ]
[layer9_wo_weight] Last 3: [0.00535692 0.01286296 0.0059447 ]
--------------------
[layer9_attention_out_proj] Shape: (1, 3, 768)
[layer9_attention_out_proj] Token 0 First 3: [ 0.13918303 -0.08142776  0.33315504]
[layer9_attention_out_proj] Token 0 Last 3: [-0.15900469  0.0480857   0.01364321]
[layer9_attention_out_proj] Token 1 First 3: [ 0.06590789 -0.09168594  0.3972999 ]
[layer9_attention_out_proj] Token 1 Last 3: [-0.11169861 -0.00986484  0.03157692]
[layer9_attention_out_proj] Token 2 First 3: [ 0.05886543 -0.04034378  0.40642822]
[layer9_attention_out_proj] Token 2 Last 3: [-0.10760944 -0.00776408  0.01188574]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.9097808 -0.532259   2.177694 ]
[RMSNorm(raw)] Token 0 Last 3: [-1.0393467   0.31431594  0.08917988]
[RMSNorm(raw)] Token 1 First 3: [ 0.4182891  -0.58189136  2.521492  ]
[RMSNorm(raw)] Token 1 Last 3: [-0.7089032  -0.06260794  0.20040514]
[RMSNorm(raw)] Token 2 First 3: [ 0.29707617 -0.20360297  2.0511212 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.5430726  -0.03918297  0.05998378]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 5.025497  12.507221  -0.9927248]
[RMSNorm(weight)] Last 3: [ 4.8727174  6.1008263 17.06646  ]
--------------------
[layer9_ffn_norm] Shape: (1, 3, 768)
[layer9_ffn_norm] Token 0 First 3: [ 5.4818816  -7.18934     0.01584321]
[layer9_ffn_norm] Token 0 Last 3: [-6.1037893  2.2319028  1.6111647]
[layer9_ffn_norm] Token 1 First 3: [ 2.5203996  -7.8597355   0.01834442]
[layer9_ffn_norm] Token 1 Last 3: [-4.163188   -0.44456807  3.6206112 ]
[layer9_ffn_norm] Token 2 First 3: [ 1.7900316  -2.7501104   0.01492237]
[layer9_ffn_norm] Token 2 Last 3: [-3.1893117  -0.27823147  1.0836946 ]
--------------------
[layer9_post_attention_norm] Shape: (1, 3, 768)
[layer9_post_attention_norm] Token 0 First 3: [ 5.4818816  -7.18934     0.01584321]
[layer9_post_attention_norm] Token 0 Last 3: [-6.1037893  2.2319028  1.6111647]
[layer9_post_attention_norm] Token 1 First 3: [ 2.5203996  -7.8597355   0.01834442]
[layer9_post_attention_norm] Token 1 Last 3: [-4.163188   -0.44456807  3.6206112 ]
[layer9_post_attention_norm] Token 2 First 3: [ 1.7900316  -2.7501104   0.01492237]
[layer9_post_attention_norm] Token 2 Last 3: [-3.1893117  -0.27823147  1.0836946 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.8442882  0.06759241 0.00827234]
[RMSNorm(raw)] Token 0 Last 3: [-0.21204671 -0.2506721  -0.3122631 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.45675436  0.03978988 -0.0370621 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.39708698 -0.34100387 -0.31657565]
[RMSNorm(raw)] Token 2 First 3: [ 1.0275178   0.03293112 -0.02183563]
[RMSNorm(raw)] Token 2 Last 3: [-0.12053334  0.04369427  0.16163251]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.6721458  8.344853  38.813496 ]
[RMSNorm(weight)] Last 3: [ 9.976711 11.055352  6.006896]
--------------------
[layer9pre_ffn_norm] Shape: (1, 3, 768)
[layer9pre_ffn_norm] First 5 values: [8.616783142089844, 0.6316412091255188, 0.32935065031051636, -0.20106542110443115, -0.42265230417251587]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.15218031406402588, -1.2116883993148804, -0.6622723937034607, -0.03691057488322258, 0.23184171319007874]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.2331811934709549, 0.1536952406167984, 0.21853306889533997, -0.5371149778366089, -0.03009451925754547]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.05252672731876373, -0.01144171692430973, 0.007072246167808771, -0.007675331085920334, -0.03404715284705162]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 2.2341454  -0.48665622  0.30080736]
[RMSNorm(raw)] Token 0 Last 3: [-1.3225032   0.13466395 -0.0400614 ]
[RMSNorm(raw)] Token 1 First 3: [-0.6733821  -0.4979807  -0.22649816]
[RMSNorm(raw)] Token 1 Last 3: [ 1.2009171  -0.00508112 -0.7488712 ]
[RMSNorm(raw)] Token 2 First 3: [ 0.2089835  -0.0407332  -0.91070175]
[RMSNorm(raw)] Token 2 Last 3: [-0.18683182  0.7537556   0.04570809]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [10.107888  13.628395  -0.8133999]
[RMSNorm(weight)] Last 3: [ 7.7243586 10.652802  22.004204 ]
--------------------
[layer9_post_ffn_norm] Shape: (1, 3, 768)
[layer9_post_ffn_norm] Token 0 First 3: [24.816637   -7.1189995   0.05613068]
[layer9_post_ffn_norm] Token 0 Last 3: [-11.5379925   1.5692124  -0.9215807]
[layer9_post_ffn_norm] Token 1 First 3: [-7.479853   -7.2846584  -0.04226458]
[layer9_post_ffn_norm] Token 1 Last 3: [ 10.477232    -0.05920924 -17.227186  ]
[layer9_post_ffn_norm] Token 2 First 3: [ 2.3213654  -0.5958614  -0.16993703]
[layer9_post_ffn_norm] Token 2 Last 3: [-1.6299877  8.783365   1.0514783]
--------------------
[layer9_decoder_block_out] Shape: (1, 3, 768)
[layer9_decoder_block_out] Token 0 First 3: [167.93637    -1.8737197   0.6980774]
[layer9_decoder_block_out] Token 0 Last 3: [-27.993158 -17.883347 -25.153702]
[layer9_decoder_block_out] Token 1 First 3: [10.840029  -5.688733  -1.5287821]
[layer9_decoder_block_out] Token 1 Last 3: [ -5.449461 -13.736473 -29.924664]
[layer9_decoder_block_out] Token 2 First 3: [83.105675   1.993211  -1.8866724]
[layer9_decoder_block_out] Token 2 Last 3: [-11.10642   12.218645  13.759162]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.2468253  -0.01391123  0.0051828 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.20783216 -0.13277297 -0.18675092]
[RMSNorm(raw)] Token 1 First 3: [ 0.15373011 -0.08067594 -0.02168074]
[RMSNorm(raw)] Token 1 Last 3: [-0.07728266 -0.19480664 -0.4243828 ]
[RMSNorm(raw)] Token 2 First 3: [ 0.69272447  0.01661434 -0.01572629]
[RMSNorm(raw)] Token 2 Last 3: [-0.09257717  0.1018481   0.11468902]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 6.7824016 11.958725  92.444466 ]
[RMSNorm(weight)] Last 3: [12.556173  13.103645   7.7772107]
--------------------
[layer10_attention_norm] Shape: (1, 3, 768)
[layer10_attention_norm] Token 0 First 3: [ 9.703296   -0.18027179  0.48430395]
[layer10_attention_norm] Token 0 Last 3: [-2.8174088 -1.8725828 -1.639152 ]
[layer10_attention_norm] Token 1 First 3: [ 1.1963894 -1.0454574 -2.0259452]
[layer10_attention_norm] Token 1 Last 3: [-1.0476571 -2.7474837 -3.7248971]
[layer10_attention_norm] Token 2 First 3: [ 5.39106    0.2153007 -1.469535 ]
[layer10_attention_norm] Token 2 Last 3: [-1.2549922  1.4364294  1.0066496]
--------------------
[layer10_attention_norm] Shape: (1, 3, 768)
[layer10_attention_norm] Token 0 First 3: [ 9.703296   -0.18027179  0.48430395]
[layer10_attention_norm] Token 0 Last 3: [-2.8174088 -1.8725828 -1.639152 ]
[layer10_attention_norm] Token 1 First 3: [ 1.1963894 -1.0454574 -2.0259452]
[layer10_attention_norm] Token 1 Last 3: [-1.0476571 -2.7474837 -3.7248971]
[layer10_attention_norm] Token 2 First 3: [ 5.39106    0.2153007 -1.469535 ]
[layer10_attention_norm] Token 2 Last 3: [-1.2549922  1.4364294  1.0066496]
--------------------
[layer10_wq_weight] Shape: (768, 768)
[layer10_wq_weight] First 3: [ 0.00682145 -0.00191117 -0.00692999]
[layer10_wq_weight] Last 3: [-0.00441789  0.00442306 -0.03297099]
--------------------
[layer10_wk_weight] Shape: (768, 256)
[layer10_wk_weight] First 3: [0.01083375 0.01825745 0.00082624]
[layer10_wk_weight] Last 3: [ 0.01270958 -0.01471543 -0.00466373]
--------------------
[layer10_wv_weight] Shape: (768, 256)
[layer10_wv_weight] First 3: [0.00010905 0.00312905 0.00265395]
[layer10_wv_weight] Last 3: [ 0.00187692 -0.00496043  0.01308208]
--------------------
[layer10_wq] Shape: (1, 3, 768)
[layer10_wq] Token 0 First 3: [-0.60002077  0.00406742 -0.02660704]
[layer10_wq] Token 0 Last 3: [-0.27164423 -0.3868243  -0.32406333]
[layer10_wq] Token 1 First 3: [-1.5796078  -0.2178607  -0.25851554]
[layer10_wq] Token 1 Last 3: [-0.2840562   0.5019231   0.15008579]
[layer10_wq] Token 2 First 3: [-0.68810487  0.00406291 -0.14311923]
[layer10_wq] Token 2 Last 3: [ 0.23574811  0.18382996 -0.5203766 ]
--------------------
[layer10_wk] Shape: (1, 3, 256)
[layer10_wk] Token 0 First 3: [0.523789  0.2085333 0.1100249]
[layer10_wk] Token 0 Last 3: [-0.04479328 -0.12983613  2.8758607 ]
[layer10_wk] Token 1 First 3: [ 1.28636   -1.5340905  1.0031751]
[layer10_wk] Token 1 Last 3: [-0.74454665  1.0741552   2.0539315 ]
[layer10_wk] Token 2 First 3: [ 1.2008142  -0.05396044  0.24041843]
[layer10_wk] Token 2 Last 3: [-0.20797609  0.15636061  2.7795672 ]
--------------------
[layer10_wv] Shape: (1, 3, 256)
[layer10_wv] Token 0 First 3: [-0.75484633  1.0426419  -0.04264751]
[layer10_wv] Token 0 Last 3: [-0.09363024 -0.05097757  0.53633046]
[layer10_wv] Token 1 First 3: [0.40721744 1.0223572  0.07532953]
[layer10_wv] Token 1 Last 3: [0.36873925 0.00829506 0.5237063 ]
[layer10_wv] Token 2 First 3: [-0.05179857  0.7157886  -0.08894718]
[layer10_wv] Token 2 Last 3: [ 0.01586518  0.06619748 -0.03839392]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.9775501   0.00662662 -0.04334802]
[RMSNorm(raw)] Last 3: [ 0.22637597  0.17652182 -0.4996891 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.7557517 0.7799647 0.3991747]
[RMSNorm(weight)] Last 3: [-0.24636751 -0.10252715 -0.41360655]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [0.36423653 0.14501153 0.07650998]
[RMSNorm(raw)] Last 3: [-0.16532153  0.12429205  2.2094958 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.3763944   0.10132386  0.09831153]
[RMSNorm(weight)] Last 3: [0.8793564 0.6444137 1.5776932]
--------------------
[layer10_q_norm_out] Shape: (1, 3, 768)
[layer10_q_norm_out] Token 0 First 3: [-1.7163353   0.01179514 -0.06065145]
[layer10_q_norm_out] Token 0 Last 3: [-0.22020891 -0.3734306  -0.20440608]
[layer10_q_norm_out] Token 1 First 3: [-2.0520542  -0.2869239  -0.26763013]
[layer10_q_norm_out] Token 1 Last 3: [-0.12772816  0.26877034  0.05251115]
[layer10_q_norm_out] Token 2 First 3: [-1.6161742   0.00967428 -0.26788005]
[layer10_q_norm_out] Token 2 Last 3: [ 0.17060429  0.15842354 -0.29301444]
--------------------
[layer10_k_norm_out] Shape: (1, 3, 256)
[layer10_k_norm_out] Token 0 First 3: [0.22713995 0.15970466 0.0840318 ]
[layer10_k_norm_out] Token 0 Last 3: [-0.05853951 -0.14846832  5.1549706 ]
[layer10_k_norm_out] Token 1 First 3: [ 0.44699588 -0.9414494   0.6139504 ]
[layer10_k_norm_out] Token 1 Last 3: [-0.7797081  0.9842583  2.9501774]
[layer10_k_norm_out] Token 2 First 3: [ 0.59525335 -0.04723964  0.2098985 ]
[layer10_k_norm_out] Token 2 Last 3: [-0.31069806  0.20438756  5.695402  ]
--------------------
[layer10_attention_out_core] Shape: (1, 3, 768)
[layer10_attention_out_core] Token 0 First 3: [-0.26205477  0.92103744 -0.03488843]
[layer10_attention_out_core] Token 0 Last 3: [0.00390054 0.02219605 0.1973467 ]
[layer10_attention_out_core] Token 1 First 3: [-0.4060133   1.0079123  -0.01794624]
[layer10_attention_out_core] Token 1 Last 3: [0.09526204 0.00529404 0.35346982]
[layer10_attention_out_core] Token 2 First 3: [-0.05379371  1.0009009   0.01748947]
[layer10_attention_out_core] Token 2 Last 3: [0.07744932 0.01724979 0.27502295]
--------------------
[layer10_wo_weight] Shape: (768, 768)
[layer10_wo_weight] First 3: [-0.00791129  0.00038949 -0.01048809]
[layer10_wo_weight] Last 3: [-0.0098946  -0.01118408 -0.01479352]
--------------------
[layer10_attention_out_proj] Shape: (1, 3, 768)
[layer10_attention_out_proj] Token 0 First 3: [0.09260651 0.0895137  0.02584085]
[layer10_attention_out_proj] Token 0 Last 3: [-0.08563115 -0.20548022 -0.12003253]
[layer10_attention_out_proj] Token 1 First 3: [0.09882262 0.12559244 0.22152503]
[layer10_attention_out_proj] Token 1 Last 3: [-0.13900167 -0.16664857 -0.06332858]
[layer10_attention_out_proj] Token 2 First 3: [0.17258674 0.1464229  0.11190758]
[layer10_attention_out_proj] Token 2 Last 3: [-0.10529086 -0.18826886  0.07435525]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.53181857 0.51405716 0.14839825]
[RMSNorm(raw)] Token 0 Last 3: [-0.49176058 -1.180027   -0.68932   ]
[RMSNorm(raw)] Token 1 First 3: [0.4038828  0.51328963 0.90536106]
[RMSNorm(raw)] Token 1 Last 3: [-0.56809247 -0.68108386 -0.25882053]
[RMSNorm(raw)] Token 2 First 3: [0.68142396 0.5781213  0.44184452]
[RMSNorm(raw)] Token 2 Last 3: [-0.41571975 -0.7433416   0.29357672]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 7.257709  64.206406  -1.0824184]
[RMSNorm(weight)] Last 3: [ 7.69304  10.611586 27.44613 ]
--------------------
[layer10_ffn_norm] Shape: (1, 3, 768)
[layer10_ffn_norm] Token 0 First 3: [ 4.3916035e+00  3.3519821e+01 -1.2230753e-02]
[layer10_ffn_norm] Token 0 Last 3: [ -4.274894 -13.701984 -19.608488]
[layer10_ffn_norm] Token 1 First 3: [ 3.335147   33.469772   -0.07461844]
[layer10_ffn_norm] Token 1 Last 3: [-4.9384503 -7.9084635 -7.362443 ]
[layer10_ffn_norm] Token 2 First 3: [ 5.6270013e+00  3.7697212e+01 -3.6416136e-02]
[layer10_ffn_norm] Token 2 Last 3: [-3.6138682 -8.631375   8.351122 ]
--------------------
[layer10_post_attention_norm] Shape: (1, 3, 768)
[layer10_post_attention_norm] Token 0 First 3: [ 4.3916035e+00  3.3519821e+01 -1.2230753e-02]
[layer10_post_attention_norm] Token 0 Last 3: [ -4.274894 -13.701984 -19.608488]
[layer10_post_attention_norm] Token 1 First 3: [ 3.335147   33.469772   -0.07461844]
[layer10_post_attention_norm] Token 1 Last 3: [-4.9384503 -7.9084635 -7.362443 ]
[layer10_post_attention_norm] Token 2 First 3: [ 5.6270013e+00  3.7697212e+01 -3.6416136e-02]
[layer10_post_attention_norm] Token 2 Last 3: [-3.6138682 -8.631375   8.351122 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.7536685  0.32204157 0.00697941]
[RMSNorm(raw)] Token 0 Last 3: [-0.32837075 -0.32142317 -0.4555154 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.27895623  0.5467089  -0.03155366]
[RMSNorm(raw)] Token 1 Last 3: [-0.20442587 -0.4259552  -0.73378074]
[RMSNorm(raw)] Token 2 First 3: [ 0.95100886  0.42538947 -0.02061106]
[RMSNorm(raw)] Token 2 Last 3: [-0.1577674   0.03844723  0.23697105]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.9986422  1.2624083 30.873512 ]
[RMSNorm(weight)] Last 3: [4.746852  4.2521863 1.9122126]
--------------------
[layer10pre_ffn_norm] Shape: (1, 3, 768)
[layer10pre_ffn_norm] First 5 values: [5.25862455368042, 0.7285895347595215, 0.22245833277702332, -0.18816213309764862, -1.1144304275512695]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.1930128037929535, -0.21256554126739502, -0.0746002346277237, -0.06674733757972717, 0.15791378915309906]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.006384722888469696, -0.22403427958488464, 0.29253724217414856, -0.20258204638957977, -0.16475701332092285]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.014830234460532665, -0.006463808473199606, 0.002375656273216009, 0.02139781415462494, -0.0043297335505485535]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 2.0833657 -0.9080421  0.3337345]
[RMSNorm(raw)] Token 0 Last 3: [-0.7176773   0.71402967 -0.18319136]
[RMSNorm(raw)] Token 1 First 3: [ 0.22622304 -0.16283517 -0.42979676]
[RMSNorm(raw)] Token 1 Last 3: [-0.07508059 -1.2180837  -0.8557171 ]
[RMSNorm(raw)] Token 2 First 3: [3.2400303  0.04517794 0.4722239 ]
[RMSNorm(raw)] Token 2 Last 3: [0.07733942 0.74544984 0.25177166]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [14.40826   29.091774  -0.8462397]
[RMSNorm(weight)] Last 3: [11.329236 15.812626 35.816082]
--------------------
[layer10_post_ffn_norm] Shape: (1, 3, 768)
[layer10_post_ffn_norm] Token 0 First 3: [ 32.10104    -27.324596     0.05131513]
[layer10_post_ffn_norm] Token 0 Last 3: [-8.8484125 12.004714  -6.744388 ]
[layer10_post_ffn_norm] Token 1 First 3: [ 3.4857035  -4.899999   -0.06608568]
[layer10_post_ffn_norm] Token 1 Last 3: [ -0.9256863 -20.479187  -31.504152 ]
[layer10_post_ffn_norm] Token 2 First 3: [49.92323    1.3594844  0.0726093]
[layer10_post_ffn_norm] Token 2 Last 3: [ 0.9535359 12.532969   9.269246 ]
--------------------
[layer10_decoder_block_out] Shape: (1, 3, 768)
[layer10_decoder_block_out] Token 0 First 3: [204.42902      4.3215046    0.73716176]
[layer10_decoder_block_out] Token 0 Last 3: [-41.116463 -19.580616 -51.50658 ]
[layer10_decoder_block_out] Token 1 First 3: [17.66088   22.88104   -1.6694863]
[layer10_decoder_block_out] Token 1 Last 3: [-11.313597 -42.124123 -68.79126 ]
[layer10_decoder_block_out] Token 2 First 3: [138.6559     41.049908   -1.8504792]
[layer10_decoder_block_out] Token 2 Last 3: [-13.766751  16.12024   31.379528]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.4943649  0.03158996 0.00538861]
[RMSNorm(raw)] Token 0 Last 3: [-0.30055907 -0.14313322 -0.37651026]
[RMSNorm(raw)] Token 1 First 3: [ 0.3261622   0.42256847 -0.03083218]
[RMSNorm(raw)] Token 1 Last 3: [-0.2089402 -0.7779509 -1.2704412]
[RMSNorm(raw)] Token 2 First 3: [ 1.3206639   0.39099044 -0.01762537]
[RMSNorm(raw)] Token 2 Last 3: [-0.13112497  0.15354137  0.29888242]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 0.75084853  0.6974969  70.41298   ]
[RMSNorm(weight)] Last 3: [ 1.7740002   0.46909076 -0.07349639]
--------------------
[layer11_attention_norm] Shape: (1, 3, 768)
[layer11_attention_norm] Token 0 First 3: [2.6164064  0.05362386 0.38481683]
[layer11_attention_norm] Token 0 Last 3: [-0.8337509  -0.21027568 -0.34883812]
[layer11_attention_norm] Token 1 First 3: [ 0.5710606   0.71730864 -2.2018175 ]
[layer11_attention_norm] Token 1 Last 3: [-0.57960016 -1.1428804  -1.1770684 ]
[layer11_attention_norm] Token 2 First 3: [ 2.3122826   0.66370505 -1.25868   ]
[layer11_attention_norm] Token 2 Last 3: [-0.3637407   0.2255662   0.27691564]
--------------------
[layer11_attention_norm] Shape: (1, 3, 768)
[layer11_attention_norm] Token 0 First 3: [2.6164064  0.05362386 0.38481683]
[layer11_attention_norm] Token 0 Last 3: [-0.8337509  -0.21027568 -0.34883812]
[layer11_attention_norm] Token 1 First 3: [ 0.5710606   0.71730864 -2.2018175 ]
[layer11_attention_norm] Token 1 Last 3: [-0.57960016 -1.1428804  -1.1770684 ]
[layer11_attention_norm] Token 2 First 3: [ 2.3122826   0.66370505 -1.25868   ]
[layer11_attention_norm] Token 2 Last 3: [-0.3637407   0.2255662   0.27691564]
--------------------
[layer11_wq_weight] Shape: (768, 768)
[layer11_wq_weight] First 3: [ 0.01984897 -0.00417023  0.01980543]
[layer11_wq_weight] Last 3: [ 0.01283423 -0.01688497 -0.00440726]
--------------------
[layer11_wk_weight] Shape: (768, 256)
[layer11_wk_weight] First 3: [0.00788751 0.02006696 0.0086193 ]
[layer11_wk_weight] Last 3: [ 0.00217386 -0.02517292 -0.00269745]
--------------------
[layer11_wv_weight] Shape: (768, 256)
[layer11_wv_weight] First 3: [-0.00095714  0.0007542   0.0018174 ]
[layer11_wv_weight] Last 3: [-0.0082522  -0.01591713 -0.00465451]
--------------------
[layer11_wq] Shape: (1, 3, 768)
[layer11_wq] Token 0 First 3: [-0.20083183  0.38996178  0.08238561]
[layer11_wq] Token 0 Last 3: [0.12458809 0.12181173 0.11691204]
[layer11_wq] Token 1 First 3: [ 0.27137047  0.8592547  -1.0106616 ]
[layer11_wq] Token 1 Last 3: [0.17571186 1.4953036  0.59612954]
[layer11_wq] Token 2 First 3: [0.17132509 0.5823848  0.3136707 ]
[layer11_wq] Token 2 Last 3: [0.36990142 0.20723268 0.08653601]
--------------------
[layer11_wk] Shape: (1, 3, 256)
[layer11_wk] Token 0 First 3: [0.00317416 0.38587028 0.0451255 ]
[layer11_wk] Token 0 Last 3: [0.5036013 0.7364751 0.7174596]
[layer11_wk] Token 1 First 3: [0.27143714 1.4637089  0.50595844]
[layer11_wk] Token 1 Last 3: [0.946777  2.5916939 1.8090006]
[layer11_wk] Token 2 First 3: [0.22968194 0.33088827 0.00873917]
[layer11_wk] Token 2 Last 3: [0.7471177  0.8247405  0.82817745]
--------------------
[layer11_wv] Shape: (1, 3, 256)
[layer11_wv] Token 0 First 3: [-0.19824961  0.02574331 -0.02855024]
[layer11_wv] Token 0 Last 3: [ 0.24300386 -0.03743717 -0.00370003]
[layer11_wv] Token 1 First 3: [-0.17749093  0.51462233 -0.4788308 ]
[layer11_wv] Token 1 Last 3: [ 0.36826348 -0.6134853   0.06641678]
[layer11_wv] Token 2 First 3: [-0.13041615 -0.00135451  0.00701001]
[layer11_wv] Token 2 Last 3: [ 0.02529781  0.035781   -0.05534641]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.916037   1.7786993  0.3757784]
[RMSNorm(raw)] Last 3: [1.8739308 1.0498465 0.4383938]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.52399385 -1.0222895   3.1430721 ]
[RMSNorm(weight)] Last 3: [-0.7289952  -0.5534061  -0.56853163]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [0.01044634 1.2699227  0.14851078]
[RMSNorm(raw)] Last 3: [2.0809357 2.2971375 2.3067102]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.5159821  -0.995558    0.04091087]
[RMSNorm(weight)] Last 3: [10.000922   7.422613   7.4223375]
--------------------
[layer11_q_norm_out] Shape: (1, 3, 768)
[layer11_q_norm_out] Token 0 First 3: [-1.3960348  -0.03964634  1.556877  ]
[layer11_q_norm_out] Token 0 Last 3: [0.10268524 0.16544604 0.15341319]
[layer11_q_norm_out] Token 1 First 3: [ 0.6656697 -0.0308273 -6.739711 ]
[layer11_q_norm_out] Token 1 Last 3: [0.06619318 0.92827636 0.35754013]
[layer11_q_norm_out] Token 2 First 3: [ 0.88343734 -0.04392201  4.397117  ]
[layer11_q_norm_out] Token 2 Last 3: [0.5078442  0.46885502 0.18915306]
--------------------
[layer11_k_norm_out] Shape: (1, 3, 256)
[layer11_k_norm_out] Token 0 First 3: [0.01583647 0.00564097 0.15458648]
[layer11_k_norm_out] Token 0 Last 3: [18.232738 20.4146   19.886852]
[layer11_k_norm_out] Token 1 First 3: [0.54431957 0.00860046 0.6966569 ]
[layer11_k_norm_out] Token 1 Last 3: [13.777402 28.874943 20.15403 ]
[layer11_k_norm_out] Token 2 First 3: [0.9698188  0.00409381 0.02533689]
[layer11_k_norm_out] Token 2 Last 3: [22.892212 19.3479   19.427893]
--------------------
[layer11_attention_out_core] Shape: (1, 3, 768)
[layer11_attention_out_core] Token 0 First 3: [-0.19210184  0.04903574 -0.04921084]
[layer11_attention_out_core] Token 0 Last 3: [ 0.21932663 -0.08661966 -0.00499281]
[layer11_attention_out_core] Token 1 First 3: [-0.17747687  0.5110299  -0.4754964 ]
[layer11_attention_out_core] Token 1 Last 3: [ 0.35547605 -0.5782412   0.06104174]
[layer11_attention_out_core] Token 2 First 3: [-0.13412039  0.00377115  0.0016863 ]
[layer11_attention_out_core] Token 2 Last 3: [ 0.02779039  0.0344908  -0.05472091]
--------------------
[layer11_wo_weight] Shape: (768, 768)
[layer11_wo_weight] First 3: [-0.0044518  -0.00322494 -0.01788357]
[layer11_wo_weight] Last 3: [-0.00633536 -0.00575687  0.00069963]
--------------------
[layer11_attention_out_proj] Shape: (1, 3, 768)
[layer11_attention_out_proj] Token 0 First 3: [-0.00871602  0.00026889  0.06195281]
[layer11_attention_out_proj] Token 0 Last 3: [-0.02389732 -0.00614611 -0.01174895]
[layer11_attention_out_proj] Token 1 First 3: [-0.00534289  0.04641493  0.12035174]
[layer11_attention_out_proj] Token 1 Last 3: [ 0.02485041  0.01550835 -0.0630387 ]
[layer11_attention_out_proj] Token 2 First 3: [-0.03682915 -0.01560889  0.05145378]
[layer11_attention_out_proj] Token 2 Last 3: [-0.02883201  0.02128534  0.03220547]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.16756165  0.00516937  1.1910155 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.4594155  -0.11815615 -0.22586834]
[RMSNorm(raw)] Token 1 First 3: [-0.0564219  0.4901498  1.2709355]
[RMSNorm(raw)] Token 1 Last 3: [ 0.2624247  0.1637709 -0.6656998]
[RMSNorm(raw)] Token 2 First 3: [-0.4329291  -0.18348351  0.6048426 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.3389221   0.2502106   0.37857738]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [19.012539  62.648445  -0.9969826]
[RMSNorm(weight)] Last 3: [15.3810005 13.586559  39.473763 ]
--------------------
[layer11_ffn_norm] Shape: (1, 3, 768)
[layer11_ffn_norm] Token 0 First 3: [-3.353334    0.32902256  0.0035938 ]
[layer11_ffn_norm] Token 0 Last 3: [-7.5256853 -1.7234917 -9.141742 ]
[layer11_ffn_norm] Token 1 First 3: [-1.1291455e+00  3.1197273e+01  3.8349533e-03]
[layer11_ffn_norm] Token 1 Last 3: [  4.2987795   2.388854  -26.943375 ]
[layer11_ffn_norm] Token 2 First 3: [-8.6640100e+00 -1.1678440e+01  1.8250676e-03]
[layer11_ffn_norm] Token 2 Last 3: [-5.551883   3.6497118 15.322451 ]
--------------------
[layer11_post_attention_norm] Shape: (1, 3, 768)
[layer11_post_attention_norm] Token 0 First 3: [-3.353334    0.32902256  0.0035938 ]
[layer11_post_attention_norm] Token 0 Last 3: [-7.5256853 -1.7234917 -9.141742 ]
[layer11_post_attention_norm] Token 1 First 3: [-1.1291455e+00  3.1197273e+01  3.8349533e-03]
[layer11_post_attention_norm] Token 1 Last 3: [  4.2987795   2.388854  -26.943375 ]
[layer11_post_attention_norm] Token 2 First 3: [-8.6640100e+00 -1.1678440e+01  1.8250676e-03]
[layer11_post_attention_norm] Token 2 Last 3: [-5.551883   3.6497118 15.322451 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.4098779  0.03260799 0.00519394]
[RMSNorm(raw)] Token 0 Last 3: [-0.34106305 -0.14937754 -0.42524648]
[RMSNorm(raw)] Token 1 First 3: [ 0.24100581  0.78837395 -0.02428249]
[RMSNorm(raw)] Token 1 Last 3: [-0.10226463 -0.5792756  -1.3956553 ]
[RMSNorm(raw)] Token 2 First 3: [ 1.1774714   0.26604787 -0.01674518]
[RMSNorm(raw)] Token 2 Last 3: [-0.17498891  0.17907695  0.4230283 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.3369114   0.47163278 80.19588   ]
[RMSNorm(weight)] Last 3: [4.06371   4.0904408 1.0391889]
--------------------
[layer11pre_ffn_norm] Shape: (1, 3, 768)
[layer11pre_ffn_norm] First 5 values: [4.70463752746582, 0.047986991703510284, 0.42172643542289734, -0.26466426253318787, -1.2888596057891846]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.10028213262557983, 0.0349409282207489, 0.33825770020484924, -0.005447700619697571, 0.111436627805233]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.03846830129623413, -0.12632820010185242, 0.1515430212020874, -0.16157850623130798, 0.0885000228881836]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.004502653609961271, 0.0017190637299790978, 0.0013188703451305628, -0.005168379284441471, -0.0008508784230798483]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.81029224 0.30936068 0.23734234]
[RMSNorm(raw)] Token 0 Last 3: [-0.29471156 -0.04213374 -0.6985279 ]
[RMSNorm(raw)] Token 1 First 3: [-0.8321914   0.10122237  0.05379076]
[RMSNorm(raw)] Token 1 Last 3: [-0.27761135  0.04099591 -0.87747866]
[RMSNorm(raw)] Token 2 First 3: [-1.1566743  0.2548973  0.9509719]
[RMSNorm(raw)] Token 2 Last 3: [ 0.08532295 -0.12386868 -0.65685636]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [23.601564 50.55892   3.816435]
[RMSNorm(weight)] Last 3: [15.30019  17.90664  41.895638]
--------------------
[layer11_post_ffn_norm] Shape: (1, 3, 768)
[layer11_post_ffn_norm] Token 0 First 3: [19.934458  15.950303   1.1431439]
[layer11_post_ffn_norm] Token 0 Last 3: [ -4.8038545  -0.7966074 -29.963799 ]
[layer11_post_ffn_norm] Token 1 First 3: [-20.473211    5.218916    0.2590797]
[layer11_post_ffn_norm] Token 1 Last 3: [ -4.525118    0.7750948 -37.640007 ]
[layer11_post_ffn_norm] Token 2 First 3: [-28.455996  13.14223    4.580294]
[layer11_post_ffn_norm] Token 2 Last 3: [  1.3907802  -2.3419404 -28.176271 ]
--------------------
[layer11_decoder_block_out] Shape: (1, 3, 768)
[layer11_decoder_block_out] Token 0 First 3: [221.01015    20.60083     1.8838995]
[layer11_decoder_block_out] Token 0 Last 3: [-53.446003 -22.100716 -90.61212 ]
[layer11_decoder_block_out] Token 1 First 3: [-3.9414768 59.297234  -1.4065716]
[layer11_decoder_block_out] Token 1 Last 3: [ -11.539935  -38.960175 -133.37463 ]
[layer11_decoder_block_out] Token 2 First 3: [101.53589    42.5137      2.7316399]
[layer11_decoder_block_out] Token 2 Last 3: [-17.927855  17.42801   18.52571 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [1.1070218  0.10318787 0.0094363 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.26770666 -0.11070067 -0.45386872]
[RMSNorm(raw)] Token 1 First 3: [-0.03583075  0.5390529  -0.01278671]
[RMSNorm(raw)] Token 1 Last 3: [-0.10490599 -0.35417494 -1.2124677 ]
[RMSNorm(raw)] Token 2 First 3: [0.5828764  0.24405392 0.01568124]
[RMSNorm(raw)] Token 2 Last 3: [-0.10291655  0.10004715  0.10634859]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 6.6511087  6.931496  68.99245  ]
[RMSNorm(weight)] Last 3: [12.9576645 13.936573   5.96416  ]
--------------------
[layer12_attention_norm] Shape: (1, 3, 768)
[layer12_attention_norm] Token 0 First 3: [8.469944   0.81843424 0.6604696 ]
[layer12_attention_norm] Token 0 Last 3: [-3.7365599 -1.6534888 -3.1608143]
[layer12_attention_norm] Token 1 First 3: [-0.27414498  4.275496   -0.89497304]
[layer12_attention_norm] Token 1 Last 3: [-1.4642427 -5.2901597 -8.443819 ]
[layer12_attention_norm] Token 2 First 3: [4.4596505 1.9357127 1.0975682]
[layer12_attention_norm] Token 2 Last 3: [-1.4364747  1.4943615  0.7406286]
--------------------
[layer12_attention_norm] Shape: (1, 3, 768)
[layer12_attention_norm] Token 0 First 3: [8.469944   0.81843424 0.6604696 ]
[layer12_attention_norm] Token 0 Last 3: [-3.7365599 -1.6534888 -3.1608143]
[layer12_attention_norm] Token 1 First 3: [-0.27414498  4.275496   -0.89497304]
[layer12_attention_norm] Token 1 Last 3: [-1.4642427 -5.2901597 -8.443819 ]
[layer12_attention_norm] Token 2 First 3: [4.4596505 1.9357127 1.0975682]
[layer12_attention_norm] Token 2 Last 3: [-1.4364747  1.4943615  0.7406286]
--------------------
[layer12_wq_weight] Shape: (768, 768)
[layer12_wq_weight] First 3: [0.00894941 0.01685419 0.00193584]
[layer12_wq_weight] Last 3: [ 0.00802083 -0.00536757 -0.00534549]
--------------------
[layer12_wk_weight] Shape: (768, 256)
[layer12_wk_weight] First 3: [ 0.00174896 -0.01110266 -0.00045168]
[layer12_wk_weight] Last 3: [-0.0151768   0.00632126  0.0036681 ]
--------------------
[layer12_wv_weight] Shape: (768, 256)
[layer12_wv_weight] First 3: [ 0.00271251  0.00511753 -0.0037066 ]
[layer12_wv_weight] Last 3: [0.00559548 0.00376156 0.02437843]
--------------------
[layer12_wq] Shape: (1, 3, 768)
[layer12_wq] Token 0 First 3: [-1.4634261  0.715101  -1.3661261]
[layer12_wq] Token 0 Last 3: [ 0.84507143  0.9559308  -1.5265713 ]
[layer12_wq] Token 1 First 3: [-1.8098242  -0.00874099 -1.4548923 ]
[layer12_wq] Token 1 Last 3: [ 0.30391687  0.25063342 -1.6176763 ]
[layer12_wq] Token 2 First 3: [-0.23059045 -0.36846113 -0.63443136]
[layer12_wq] Token 2 Last 3: [ 0.47751078  1.084369   -1.8158125 ]
--------------------
[layer12_wk] Shape: (1, 3, 256)
[layer12_wk] Token 0 First 3: [ 0.8065671  -0.18638031  0.47285196]
[layer12_wk] Token 0 Last 3: [ 2.0869257   0.8930421  -0.36305952]
[layer12_wk] Token 1 First 3: [1.377888   0.50560343 0.86666554]
[layer12_wk] Token 1 Last 3: [2.915063   1.4324886  0.40380725]
[layer12_wk] Token 2 First 3: [-0.27955678  0.5441071   0.3697321 ]
[layer12_wk] Token 2 Last 3: [2.3841114 1.5777724 0.1540389]
--------------------
[layer12_wv] Shape: (1, 3, 256)
[layer12_wv] Token 0 First 3: [ 0.28186265 -0.46438313 -0.00307891]
[layer12_wv] Token 0 Last 3: [-0.61820936 -0.6447867  -0.47908077]
[layer12_wv] Token 1 First 3: [-0.44370687 -0.70714164 -0.10674173]
[layer12_wv] Token 1 Last 3: [-0.14053544 -1.37561     0.38591167]
[layer12_wv] Token 2 First 3: [ 0.16091284 -0.26706606  0.03909561]
[layer12_wv] Token 2 Last 3: [-0.0155412   0.40475878 -0.8930391 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-1.5050664  0.7354484 -1.4049977]
[RMSNorm(raw)] Last 3: [ 0.7041332  1.5990009 -2.677581 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.01649794 -0.22557619  1.0753927 ]
[RMSNorm(weight)] Last 3: [-0.58191305 -0.03485927  2.4374843 ]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.64898705 -0.14996696  0.38047028]
[RMSNorm(raw)] Last 3: [1.8617365  1.2320719  0.12028795]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.33229387  0.30332264 -0.38665205]
[RMSNorm(weight)] Last 3: [5.155809  1.6582788 0.4758687]
--------------------
[layer12_q_norm_out] Shape: (1, 3, 768)
[layer12_q_norm_out] Token 0 First 3: [-1.529897   0.5695488 -2.915922 ]
[layer12_q_norm_out] Token 0 Last 3: [ 0.31841987  0.8314904  -4.7293115 ]
[layer12_q_norm_out] Token 1 First 3: [-1.457992   -0.00536478 -2.3930035 ]
[layer12_q_norm_out] Token 1 Last 3: [ 0.10590415  0.20161425 -4.634724  ]
[layer12_q_norm_out] Token 2 First 3: [-0.2810419  -0.34213194 -1.5787312 ]
[layer12_q_norm_out] Token 2 Last 3: [ 0.2943889  1.5432609 -9.204143 ]
--------------------
[layer12_k_norm_out] Shape: (1, 3, 256)
[layer12_k_norm_out] Token 0 First 3: [ 0.43333262 -0.19545533  0.23336066]
[layer12_k_norm_out] Token 0 Last 3: [10.336837    1.9101523  -0.43114275]
[layer12_k_norm_out] Token 1 First 3: [0.6310982 0.4520221 0.3646331]
[layer12_k_norm_out] Token 1 Last 3: [12.309226   2.6120977  0.4088081]
[layer12_k_norm_out] Token 2 First 3: [-0.14576292  0.5537682   0.17708664]
[layer12_k_norm_out] Token 2 Last 3: [11.460494    3.2751908   0.17752922]
--------------------
[layer12_attention_out_core] Shape: (1, 3, 768)
[layer12_attention_out_core] Token 0 First 3: [ 0.03035532 -0.4613382  -0.01721046]
[layer12_attention_out_core] Token 0 Last 3: [-0.2362738  -0.4341584  -0.39440915]
[layer12_attention_out_core] Token 1 First 3: [-0.05762358 -0.4723657  -0.02517737]
[layer12_attention_out_core] Token 1 Last 3: [-0.15264376 -0.35688904 -0.39965132]
[layer12_attention_out_core] Token 2 First 3: [ 0.12665139 -0.4106785   0.00115846]
[layer12_attention_out_core] Token 2 Last 3: [-0.17123592 -0.30195898 -0.4535396 ]
--------------------
[layer12_wo_weight] Shape: (768, 768)
[layer12_wo_weight] First 3: [-0.00329454  0.00393142 -0.01674766]
[layer12_wo_weight] Last 3: [-0.00072924 -0.00140699 -0.00734983]
--------------------
[layer12_attention_out_proj] Shape: (1, 3, 768)
[layer12_attention_out_proj] Token 0 First 3: [-0.1159071  -0.1361003   0.08957519]
[layer12_attention_out_proj] Token 0 Last 3: [ 0.12117459 -0.03411723  0.05794188]
[layer12_attention_out_proj] Token 1 First 3: [-0.12237553 -0.13748613  0.05417354]
[layer12_attention_out_proj] Token 1 Last 3: [ 0.15523963 -0.06368618  0.0919148 ]
[layer12_attention_out_proj] Token 2 First 3: [-0.12336062 -0.1382825   0.09858945]
[layer12_attention_out_proj] Token 2 Last 3: [ 0.10859924 -0.04863004  0.06132096]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.5798244  -0.68084073  0.4480992 ]
[RMSNorm(raw)] Token 0 Last 3: [ 0.60617495 -0.17067118  0.2898538 ]
[RMSNorm(raw)] Token 1 First 3: [-0.5837341  -0.655812    0.25840908]
[RMSNorm(raw)] Token 1 Last 3: [ 0.74049664 -0.30378455  0.43843573]
[RMSNorm(raw)] Token 2 First 3: [-0.6169204  -0.69154394  0.49304098]
[RMSNorm(raw)] Token 2 Last 3: [ 0.54309946 -0.24319641  0.30666313]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 6.6681776 45.952663   2.8107808]
[RMSNorm(weight)] Last 3: [ 8.046097 14.579427 30.08053 ]
--------------------
[layer12_ffn_norm] Shape: (1, 3, 768)
[layer12_ffn_norm] Token 0 First 3: [ -4.4461966 -31.967285    1.7076077]
[layer12_ffn_norm] Token 0 Last 3: [ 5.483517  -2.6589592  9.00881  ]
[layer12_ffn_norm] Token 1 First 3: [ -4.4761767 -30.792122    0.9847404]
[layer12_ffn_norm] Token 1 Last 3: [ 6.698604 -4.732789 13.626815]
[layer12_ffn_norm] Token 2 First 3: [ -4.730655  -32.46983     1.8788711]
[layer12_ffn_norm] Token 2 Last 3: [ 4.9129305 -3.7888608  9.531253 ]
--------------------
[layer12_post_attention_norm] Shape: (1, 3, 768)
[layer12_post_attention_norm] Token 0 First 3: [ -4.4461966 -31.967285    1.7076077]
[layer12_post_attention_norm] Token 0 Last 3: [ 5.483517  -2.6589592  9.00881  ]
[layer12_post_attention_norm] Token 1 First 3: [ -4.4761767 -30.792122    0.9847404]
[layer12_post_attention_norm] Token 1 Last 3: [ 6.698604 -4.732789 13.626815]
[layer12_post_attention_norm] Token 2 First 3: [ -4.730655  -32.46983     1.8788711]
[layer12_post_attention_norm] Token 2 Last 3: [ 4.9129305 -3.7888608  9.531253 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.1392188  -0.05979241  0.01889286]
[RMSNorm(raw)] Token 0 Last 3: [-0.25230315 -0.13024646 -0.42926824]
[RMSNorm(raw)] Token 1 First 3: [-0.08063434  0.273056   -0.0040408 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.04637605 -0.41854337 -1.1470876 ]
[RMSNorm(raw)] Token 2 First 3: [0.59323937 0.06155058 0.02825401]
[RMSNorm(raw)] Token 2 Last 3: [-0.07975772  0.08358309  0.17193794]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.9541442   0.81514543 31.476116  ]
[RMSNorm(weight)] Last 3: [5.385081  5.25772   1.8378097]
--------------------
[layer12pre_ffn_norm] Shape: (1, 3, 768)
[layer12pre_ffn_norm] First 5 values: [4.504635334014893, -0.10853191465139389, 0.6135667562484741, -0.6615610122680664, -1.339154601097107]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.01714801788330078, -0.3118502199649811, 0.054763101041316986, -0.10854043066501617, -0.2630835771560669]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.036191873252391815, 0.038825444877147675, 0.021342583000659943, 0.08849871158599854, -0.1688358634710312]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.004787404555827379, -0.0018436318496242166, -0.005038297735154629, 0.0007318217540159822, 0.002279032487422228]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.6532218 -0.251556  -0.6874551]
[RMSNorm(raw)] Token 0 Last 3: [-0.40635258  0.06469434 -0.05496565]
[RMSNorm(raw)] Token 1 First 3: [-0.48471025 -0.7346024  -0.08448844]
[RMSNorm(raw)] Token 1 Last 3: [-0.16965665 -0.04610822  0.35421014]
[RMSNorm(raw)] Token 2 First 3: [ 0.33240923  0.9851947  -1.1959671 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.30993664 -0.13725634 -0.29035664]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [19.006289 52.930824  6.957819]
[RMSNorm(weight)] Last 3: [15.372909 23.86346  48.30945 ]
--------------------
[layer12_post_ffn_norm] Shape: (1, 3, 768)
[layer12_post_ffn_norm] Token 0 First 3: [ 13.068543  -13.566623   -5.4706435]
[layer12_post_ffn_norm] Token 0 Last 3: [-6.653174   1.6085253 -2.710326 ]
[layer12_post_ffn_norm] Token 1 First 3: [ -9.697253   -39.617714    -0.67234373]
[layer12_post_ffn_norm] Token 1 Last 3: [-2.777773 -1.14641  17.465906]
[layer12_post_ffn_norm] Token 2 First 3: [ 6.650275 53.132362 -9.517289]
[layer12_post_ffn_norm] Token 2 Last 3: [ -5.0745645  -3.4126675 -14.317326 ]
--------------------
[layer12_decoder_block_out] Shape: (1, 3, 768)
[layer12_decoder_block_out] Token 0 First 3: [229.63249   -24.933079   -1.8791363]
[layer12_decoder_block_out] Token 0 Last 3: [-54.61566 -23.15115 -84.31364]
[layer12_decoder_block_out] Token 1 First 3: [-18.114906 -11.112602  -1.094175]
[layer12_decoder_block_out] Token 1 Last 3: [  -7.619104  -44.83937  -102.28191 ]
[layer12_decoder_block_out] Token 2 First 3: [103.45551    63.17623    -4.9067783]
[layer12_decoder_block_out] Token 2 Last 3: [-18.089489  10.226483  13.739635]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.84392935 -0.09163231 -0.00690607]
[RMSNorm(raw)] Token 0 Last 3: [-0.20071968 -0.08508349 -0.30986363]
[RMSNorm(raw)] Token 1 First 3: [-0.11949258 -0.07330281 -0.00721758]
[RMSNorm(raw)] Token 1 Last 3: [-0.05025841 -0.29577696 -0.67468905]
[RMSNorm(raw)] Token 2 First 3: [ 0.27938315  0.17060836 -0.01325083]
[RMSNorm(raw)] Token 2 Last 3: [-0.04885093  0.02761677  0.03710409]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [11.752662   2.8299925 61.58631  ]
[RMSNorm(weight)] Last 3: [17.502111  13.423767   5.7483263]
--------------------
[layer13_attention_norm] Shape: (1, 3, 768)
[layer13_attention_norm] Token 0 First 3: [10.762345   -0.35095108 -0.43222553]
[layer13_attention_norm] Token 0 Last 3: [-3.713738  -1.2272245 -2.0910609]
[layer13_attention_norm] Token 1 First 3: [-1.5238484 -0.2807492 -0.4517217]
[layer13_attention_norm] Token 1 Last 3: [-0.9298867 -4.266218  -4.553022 ]
[layer13_attention_norm] Token 2 First 3: [ 3.5628788   0.65342873 -0.82932043]
[layer13_attention_norm] Token 2 Last 3: [-0.9038454   0.39833787  0.2503905 ]
--------------------
[layer13_attention_norm] Shape: (1, 3, 768)
[layer13_attention_norm] Token 0 First 3: [10.762345   -0.35095108 -0.43222553]
[layer13_attention_norm] Token 0 Last 3: [-3.713738  -1.2272245 -2.0910609]
[layer13_attention_norm] Token 1 First 3: [-1.5238484 -0.2807492 -0.4517217]
[layer13_attention_norm] Token 1 Last 3: [-0.9298867 -4.266218  -4.553022 ]
[layer13_attention_norm] Token 2 First 3: [ 3.5628788   0.65342873 -0.82932043]
[layer13_attention_norm] Token 2 Last 3: [-0.9038454   0.39833787  0.2503905 ]
--------------------
[layer13_wq_weight] Shape: (768, 768)
[layer13_wq_weight] First 3: [-0.01735401 -0.0141596  -0.00161491]
[layer13_wq_weight] Last 3: [-0.0065797  -0.00636051  0.00535873]
--------------------
[layer13_wk_weight] Shape: (768, 256)
[layer13_wk_weight] First 3: [-0.01751763  0.05057695 -0.00372174]
[layer13_wk_weight] Last 3: [ 0.0007507  -0.00328934 -0.01504608]
--------------------
[layer13_wv_weight] Shape: (768, 256)
[layer13_wv_weight] First 3: [ 0.00134092 -0.00367612 -0.00152158]
[layer13_wv_weight] Last 3: [-0.00473322 -0.00420514  0.00476151]
--------------------
[layer13_wq] Shape: (1, 3, 768)
[layer13_wq] Token 0 First 3: [ 1.116987   -0.6843818   0.35893807]
[layer13_wq] Token 0 Last 3: [-0.5647958   0.11698749  0.6870444 ]
[layer13_wq] Token 1 First 3: [ 2.578988  -0.2694134  1.5329947]
[layer13_wq] Token 1 Last 3: [-1.3787436   0.28191945  0.30571568]
[layer13_wq] Token 2 First 3: [-0.10979843 -0.4505747   1.3128335 ]
[layer13_wq] Token 2 Last 3: [0.02336895 0.0998226  0.77928394]
--------------------
[layer13_wk] Shape: (1, 3, 256)
[layer13_wk] Token 0 First 3: [-0.12366264  0.2591626   0.43848592]
[layer13_wk] Token 0 Last 3: [-1.9532629  1.4414148  1.4964163]
[layer13_wk] Token 1 First 3: [ 1.1720186 -1.0887735  0.7944645]
[layer13_wk] Token 1 Last 3: [-2.6513014   0.54866564  3.288924  ]
[layer13_wk] Token 2 First 3: [-0.42463842  0.4979536   0.97264457]
[layer13_wk] Token 2 Last 3: [-1.0342683   0.96522933  1.5381799 ]
--------------------
[layer13_wv] Shape: (1, 3, 256)
[layer13_wv] Token 0 First 3: [ 0.3966639  -0.34794703 -0.18133539]
[layer13_wv] Token 0 Last 3: [-0.5641141  -0.00410862  0.03481519]
[layer13_wv] Token 1 First 3: [-0.8206503  -0.13500682 -0.94671166]
[layer13_wv] Token 1 Last 3: [ 0.50408363 -0.313157    0.94879025]
[layer13_wv] Token 2 First 3: [0.4763515  0.21381745 0.35446933]
[layer13_wv] Token 2 Last 3: [-0.14288095 -0.47939906 -0.16420656]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 1.540509   -0.9438752   0.49503472]
[RMSNorm(raw)] Last 3: [0.04038014 0.17248741 1.3465555 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.37762254  0.60998744 -0.04647369]
[RMSNorm(weight)] Last 3: [-0.17724945 -0.35500157 -0.34038144]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.10563286  0.2213772   0.3745555 ]
[RMSNorm(raw)] Last 3: [-0.9757813  0.9106465  1.4511973]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.39989012  0.17218906  0.13528067]
[RMSNorm(weight)] Last 3: [1.5417032 1.8062105 2.2020447]
--------------------
[layer13_q_norm_out] Shape: (1, 3, 768)
[layer13_q_norm_out] Token 0 First 3: [ 2.12224    -1.5196272   0.47202864]
[layer13_q_norm_out] Token 0 Last 3: [-0.62201387  0.10100398  0.6066219 ]
[layer13_q_norm_out] Token 1 First 3: [ 2.57255    -0.31406963  1.0584189 ]
[layer13_q_norm_out] Token 1 Last 3: [-0.69902223  0.11205287  0.1242653 ]
[layer13_q_norm_out] Token 2 First 3: [-0.25241646 -1.2105441   2.088977  ]
[layer13_q_norm_out] Token 2 Last 3: [0.03322278 0.11125411 0.888213  ]
--------------------
[layer13_k_norm_out] Shape: (1, 3, 256)
[layer13_k_norm_out] Token 0 First 3: [-0.06339132  0.2594959   0.4252256 ]
[layer13_k_norm_out] Token 0 Last 3: [-4.240783  3.455173  4.092987]
[layer13_k_norm_out] Token 1 First 3: [ 0.38473976 -0.6981311   0.49337772]
[layer13_k_norm_out] Token 1 Last 3: [-3.686258    0.84222823  5.760803  ]
[layer13_k_norm_out] Token 2 First 3: [-0.24041931  0.55068827  1.0417817 ]
[layer13_k_norm_out] Token 2 Last 3: [-2.4801466  2.5554657  4.6467986]
--------------------
[layer13_attention_out_core] Shape: (1, 3, 768)
[layer13_attention_out_core] Token 0 First 3: [ 0.22186854  0.0258789  -0.00164851]
[layer13_attention_out_core] Token 0 Last 3: [ 0.00279327 -0.38485852  0.17680074]
[layer13_attention_out_core] Token 1 First 3: [ 0.2120398  -0.02396109 -0.05132705]
[layer13_attention_out_core] Token 1 Last 3: [-0.06649677 -0.40139756  0.05960177]
[layer13_attention_out_core] Token 2 First 3: [0.4314318  0.17885144 0.2900976 ]
[layer13_attention_out_core] Token 2 Last 3: [-0.20986393 -0.359999   -0.06319324]
--------------------
[layer13_wo_weight] Shape: (768, 768)
[layer13_wo_weight] First 3: [-0.0013225  -0.00461636  0.00393138]
[layer13_wo_weight] Last 3: [0.01668856 0.00212098 0.00336092]
--------------------
[layer13_attention_out_proj] Shape: (1, 3, 768)
[layer13_attention_out_proj] Token 0 First 3: [-0.01172312  0.08199421  0.01715293]
[layer13_attention_out_proj] Token 0 Last 3: [ 0.06838468 -0.09713826 -0.00297808]
[layer13_attention_out_proj] Token 1 First 3: [-0.04944004  0.07345577  0.02464356]
[layer13_attention_out_proj] Token 1 Last 3: [ 0.07868618 -0.09815462  0.01815677]
[layer13_attention_out_proj] Token 2 First 3: [-0.1184347   0.01463417  0.0038758 ]
[layer13_attention_out_proj] Token 2 Last 3: [ 0.167333   -0.11773536  0.03726007]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.05712304  0.39953184  0.0835808 ]
[RMSNorm(raw)] Token 0 Last 3: [ 0.33321694 -0.47332403 -0.01451126]
[RMSNorm(raw)] Token 1 First 3: [-0.24651623  0.3662626   0.12287685]
[RMSNorm(raw)] Token 1 Last 3: [ 0.3923423  -0.48941517  0.09053268]
[RMSNorm(raw)] Token 2 First 3: [-0.64155024  0.07927199  0.02099488]
[RMSNorm(raw)] Token 2 Last 3: [ 0.90642804 -0.63776195  0.20183451]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [13.889513  59.181454   6.7900896]
[RMSNorm(weight)] Last 3: [13.609806 19.198383 45.482452]
--------------------
[layer13_ffn_norm] Shape: (1, 3, 768)
[layer13_ffn_norm] Token 0 First 3: [-0.85053426 24.044407    0.6511019 ]
[layer13_ffn_norm] Token 0 Last 3: [ 4.8682346 -9.56038   -0.6745192]
[layer13_ffn_norm] Token 1 First 3: [-3.6705065 22.042217   0.9572217]
[layer13_ffn_norm] Token 1 Last 3: [ 5.7320447 -9.885395   4.208181 ]
[layer13_ffn_norm] Token 2 First 3: [-9.552371  4.770704  0.163552]
[layer13_ffn_norm] Token 2 Last 3: [ 13.242738 -12.881761   9.381763]
--------------------
[layer13_post_attention_norm] Shape: (1, 3, 768)
[layer13_post_attention_norm] Token 0 First 3: [-0.85053426 24.044407    0.6511019 ]
[layer13_post_attention_norm] Token 0 Last 3: [ 4.8682346 -9.56038   -0.6745192]
[layer13_post_attention_norm] Token 1 First 3: [-3.6705065 22.042217   0.9572217]
[layer13_post_attention_norm] Token 1 Last 3: [ 5.7320447 -9.885395   4.208181 ]
[layer13_post_attention_norm] Token 2 First 3: [-9.552371  4.770704  0.163552]
[layer13_post_attention_norm] Token 2 Last 3: [ 13.242738 -12.881761   9.381763]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.1499571  -0.00446685 -0.00617263]
[RMSNorm(raw)] Token 0 Last 3: [-0.2500521  -0.1644223  -0.42718726]
[RMSNorm(raw)] Token 1 First 3: [-0.22071952  0.11073371 -0.00138755]
[RMSNorm(raw)] Token 1 Last 3: [-0.0191188 -0.5544455 -0.9936368]
[RMSNorm(raw)] Token 2 First 3: [ 0.32925633  0.23824504 -0.01663136]
[RMSNorm(raw)] Token 2 Last 3: [-0.01699436 -0.0093103   0.08107147]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.7883453   0.23646596 19.645369  ]
[RMSNorm(weight)] Last 3: [5.126366  4.1751757 1.1994616]
--------------------
[layer13pre_ffn_norm] Shape: (1, 3, 768)
[layer13pre_ffn_norm] First 5 values: [4.356434345245361, -0.005523107014596462, -0.12743628025054932, -0.5819675326347351, -0.7687971591949463]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.030397865921258926, -0.1159665435552597, -0.12568342685699463, -0.07385608553886414, 0.10604067891836166]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.05830627679824829, 0.015296399593353271, 0.009341593831777573, 0.04236069321632385, -0.18435874581336975]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.004554400686174631, -0.0017612290102988482, -0.0005583729944191873, 0.00023781484924256802, 0.0012723434483632445]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.5807415  -0.22457813 -0.07119935]
[RMSNorm(raw)] Token 0 Last 3: [-0.2825685  -0.59328175  0.26239273]
[RMSNorm(raw)] Token 1 First 3: [-0.4050428  -0.14406674 -0.8590169 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.4312062   0.01422951  0.63779724]
[RMSNorm(raw)] Token 2 First 3: [ 1.4559954  -0.31612325  0.36724672]
[RMSNorm(raw)] Token 2 Last 3: [-1.2442989  -0.83175653  0.6657105 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [21.975958 59.16737  12.782576]
[RMSNorm(weight)] Last 3: [19.56664  30.995052 63.093292]
--------------------
[layer13_post_ffn_norm] Shape: (1, 3, 768)
[layer13_post_ffn_norm] Token 0 First 3: [ 13.343093  -13.512276   -0.9813104]
[layer13_post_ffn_norm] Token 0 Last 3: [ -5.8114853 -18.98208    16.817614 ]
[layer13_post_ffn_norm] Token 1 First 3: [ -9.306246  -8.668117 -11.839465]
[layer13_post_ffn_norm] Token 1 Last 3: [-8.868463   0.4552738 40.878525 ]
[layer13_post_ffn_norm] Token 2 First 3: [ 33.45289   -19.020304    5.0616055]
[layer13_post_ffn_norm] Token 2 Last 3: [-25.59105  -26.612093  42.66758 ]
--------------------
[layer13_decoder_block_out] Shape: (1, 3, 768)
[layer13_decoder_block_out] Token 0 First 3: [242.12505   -14.400948   -2.2093449]
[layer13_decoder_block_out] Token 0 Last 3: [-55.558914 -51.69361  -68.17055 ]
[layer13_decoder_block_out] Token 1 First 3: [-31.091658    2.2614985 -11.9764185]
[layer13_decoder_block_out] Token 1 Last 3: [-10.755522 -54.269493 -57.195206]
[layer13_decoder_block_out] Token 2 First 3: [127.35603     48.926636     0.31837893]
[layer13_decoder_block_out] Token 2 Last 3: [-30.437801 -29.26737   65.78898 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.9147184  -0.054405   -0.00834663]
[RMSNorm(raw)] Token 0 Last 3: [-0.20989469 -0.19529206 -0.25753987]
[RMSNorm(raw)] Token 1 First 3: [-0.27367476  0.01990614 -0.10541874]
[RMSNorm(raw)] Token 1 Last 3: [-0.09467217 -0.47769052 -0.5034432 ]
[RMSNorm(raw)] Token 2 First 3: [0.25857088 0.09933572 0.0006464 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.06179785 -0.05942153  0.13357133]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [11.148679   4.3551946 46.392693 ]
[RMSNorm(weight)] Last 3: [15.809414  13.68672    5.7913523]
--------------------
[layer14_attention_norm] Shape: (1, 3, 768)
[layer14_attention_norm] Token 0 First 3: [11.11262    -0.29134935 -0.39556932]
[layer14_attention_norm] Token 0 Last 3: [-3.5282066 -2.8681998 -1.749044 ]
[layer14_attention_norm] Token 1 First 3: [-3.3247867   0.10660128 -4.996078  ]
[layer14_attention_norm] Token 1 Last 3: [-1.5913837 -7.015707  -3.41906  ]
[layer14_attention_norm] Token 2 First 3: [3.1412945  0.5319621  0.03063485]
[layer14_attention_norm] Token 2 Last 3: [-1.0387857  -0.87270737  0.90712994]
--------------------
[layer14_attention_norm] Shape: (1, 3, 768)
[layer14_attention_norm] Token 0 First 3: [11.11262    -0.29134935 -0.39556932]
[layer14_attention_norm] Token 0 Last 3: [-3.5282066 -2.8681998 -1.749044 ]
[layer14_attention_norm] Token 1 First 3: [-3.3247867   0.10660128 -4.996078  ]
[layer14_attention_norm] Token 1 Last 3: [-1.5913837 -7.015707  -3.41906  ]
[layer14_attention_norm] Token 2 First 3: [3.1412945  0.5319621  0.03063485]
[layer14_attention_norm] Token 2 Last 3: [-1.0387857  -0.87270737  0.90712994]
--------------------
[layer14_wq_weight] Shape: (768, 768)
[layer14_wq_weight] First 3: [-0.00164959  0.00352377  0.00227595]
[layer14_wq_weight] Last 3: [-0.02160258 -0.00249741  0.00839174]
--------------------
[layer14_wk_weight] Shape: (768, 256)
[layer14_wk_weight] First 3: [ 0.0043328  -0.00350942  0.00561904]
[layer14_wk_weight] Last 3: [-0.02253719  0.00775027  0.00891551]
--------------------
[layer14_wv_weight] Shape: (768, 256)
[layer14_wv_weight] First 3: [ 0.00098341 -0.01752597  0.00522164]
[layer14_wv_weight] Last 3: [ 0.00095614 -0.01310675  0.0016848 ]
--------------------
[layer14_wq] Shape: (1, 3, 768)
[layer14_wq] Token 0 First 3: [0.20935951 0.508832   0.60566187]
[layer14_wq] Token 0 Last 3: [-0.11300933 -0.38164547  0.00594783]
[layer14_wq] Token 1 First 3: [-1.1646988  1.0995642  1.5161127]
[layer14_wq] Token 1 Last 3: [ 1.6397837 -1.267265   1.4524082]
[layer14_wq] Token 2 First 3: [-0.46647406 -0.08547185  0.10972172]
[layer14_wq] Token 2 Last 3: [ 0.34806177 -0.07200721  0.42397153]
--------------------
[layer14_wk] Shape: (1, 3, 256)
[layer14_wk] Token 0 First 3: [-0.49339068  0.04625388 -0.21420494]
[layer14_wk] Token 0 Last 3: [ 1.6942148  -3.1613107  -0.00460263]
[layer14_wk] Token 1 First 3: [ 0.34274954 -0.33944845 -0.2770074 ]
[layer14_wk] Token 1 Last 3: [ 4.586302   -3.9650247   0.14363614]
[layer14_wk] Token 2 First 3: [ 0.23563112 -0.02339411  0.04074557]
[layer14_wk] Token 2 Last 3: [ 2.0919223 -3.629566   0.4650371]
--------------------
[layer14_wv] Shape: (1, 3, 256)
[layer14_wv] Token 0 First 3: [-0.9923806   1.5597199   0.39561945]
[layer14_wv] Token 0 Last 3: [-0.09731144  0.5169384  -0.16002086]
[layer14_wv] Token 1 First 3: [-1.9075297  3.5001402 -0.8854724]
[layer14_wv] Token 1 Last 3: [-0.43050948  3.1343868  -0.72609144]
[layer14_wv] Token 2 First 3: [ 0.43625572 -0.622149    0.542329  ]
[layer14_wv] Token 2 Last 3: [-0.00482571 -0.9057857   0.1398297 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [0.29399693 0.71453667 0.8505118 ]
[RMSNorm(raw)] Last 3: [ 0.46939856 -0.09710943  0.571771  ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [1.1891922  0.44966984 1.07859   ]
[RMSNorm(weight)] Last 3: [-0.23487736  0.13122067  0.05690075]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.43183413  0.04048314 -0.18748024]
[RMSNorm(raw)] Last 3: [ 1.7388123 -3.0169065  0.3865403]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.03229205  0.08525848 -0.18564513]
[RMSNorm(weight)] Last 3: [1.8200898 0.7291109 1.1727434]
--------------------
[layer14_q_norm_out] Shape: (1, 3, 768)
[layer14_q_norm_out] Token 0 First 3: [0.64361584 1.0358423  1.7678652 ]
[layer14_q_norm_out] Token 0 Last 3: [-0.07960351 -0.3974608   0.00578735]
[layer14_q_norm_out] Token 1 First 3: [-1.456874    0.91078144  1.8006312 ]
[layer14_q_norm_out] Token 1 Last 3: [ 0.5315443  -0.60734665  0.65034646]
[layer14_q_norm_out] Token 2 First 3: [-2.2470257  -0.27263954  0.5018317 ]
[layer14_q_norm_out] Token 2 Last 3: [ 0.35914746 -0.10985219  0.6043052 ]
--------------------
[layer14_k_norm_out] Shape: (1, 3, 256)
[layer14_k_norm_out] Token 0 First 3: [-0.44577894  0.04393467 -0.15267545]
[layer14_k_norm_out] Token 0 Last 3: [ 4.1817436  -4.784274   -0.00875267]
[layer14_k_norm_out] Token 1 First 3: [ 0.15716265 -0.16363528 -0.10020167]
[layer14_k_norm_out] Token 1 Last 3: [ 5.745072   -3.0453603   0.13862514]
[layer14_k_norm_out] Token 2 First 3: [ 0.20218194 -0.02110313  0.02758044]
[layer14_k_norm_out] Token 2 Last 3: [ 4.903607   -5.216566    0.83985287]
--------------------
[layer14_attention_out_core] Shape: (1, 3, 768)
[layer14_attention_out_core] Token 0 First 3: [-0.24396285  0.516194    0.25488427]
[layer14_attention_out_core] Token 0 Last 3: [-0.1204894  0.5255724 -0.1638411]
[layer14_attention_out_core] Token 1 First 3: [-0.49003264  0.87029976  0.2770792 ]
[layer14_attention_out_core] Token 1 Last 3: [-0.19145411  1.0776062  -0.28328955]
[layer14_attention_out_core] Token 2 First 3: [-0.3794607   0.6908484   0.31157756]
[layer14_attention_out_core] Token 2 Last 3: [-0.09481322  0.10362557 -0.07506744]
--------------------
[layer14_wo_weight] Shape: (768, 768)
[layer14_wo_weight] First 3: [-0.00621829  0.00860628  0.00564968]
[layer14_wo_weight] Last 3: [0.01947846 0.00314107 0.01069485]
--------------------
[layer14_attention_out_proj] Shape: (1, 3, 768)
[layer14_attention_out_proj] Token 0 First 3: [ 0.1248583  -0.02695435  0.02885395]
[layer14_attention_out_proj] Token 0 Last 3: [-0.061467    0.06024617 -0.01896935]
[layer14_attention_out_proj] Token 1 First 3: [0.17788404 0.04828889 0.02475928]
[layer14_attention_out_proj] Token 1 Last 3: [-0.03332747  0.05876558 -0.03598286]
[layer14_attention_out_proj] Token 2 First 3: [ 0.17485484 -0.02345487 -0.0073435 ]
[layer14_attention_out_proj] Token 2 Last 3: [-0.0457564   0.00595677  0.00070522]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.5362636  -0.11576831  0.12392709]
[RMSNorm(raw)] Token 0 Last 3: [-0.2639994   0.25875598 -0.08147294]
[RMSNorm(raw)] Token 1 First 3: [0.6925316 0.1879965 0.0963919]
[RMSNorm(raw)] Token 1 Last 3: [-0.12974928  0.228784   -0.14008714]
[RMSNorm(raw)] Token 2 First 3: [ 0.7723704  -0.10360508 -0.03243778]
[RMSNorm(raw)] Token 2 Last 3: [-0.20211557  0.0263123   0.00311511]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [12.073427 62.935555 10.638491]
[RMSNorm(weight)] Last 3: [14.820974 27.288795 58.388824]
--------------------
[layer14_ffn_norm] Shape: (1, 3, 768)
[layer14_ffn_norm] Token 0 First 3: [ 7.0108027 -7.4017115  1.4423243]
[layer14_ffn_norm] Token 0 Last 3: [-4.176728   7.3198953 -4.838582 ]
[layer14_ffn_norm] Token 1 First 3: [ 9.0537615 12.019661   1.1218562]
[layer14_ffn_norm] Token 1 Last 3: [-2.0527601  6.4720235 -8.319611 ]
[layer14_ffn_norm] Token 2 First 3: [10.097528  -6.6240487 -0.3775268]
[layer14_ffn_norm] Token 2 Last 3: [-3.1976652   0.74434316  0.1850028 ]
--------------------
[layer14_post_attention_norm] Shape: (1, 3, 768)
[layer14_post_attention_norm] Token 0 First 3: [ 7.0108027 -7.4017115  1.4423243]
[layer14_post_attention_norm] Token 0 Last 3: [-4.176728   7.3198953 -4.838582 ]
[layer14_post_attention_norm] Token 1 First 3: [ 9.0537615 12.019661   1.1218562]
[layer14_post_attention_norm] Token 1 Last 3: [-2.0527601  6.4720235 -8.319611 ]
[layer14_post_attention_norm] Token 2 First 3: [10.097528  -6.6240487 -0.3775268]
[layer14_post_attention_norm] Token 2 Last 3: [-3.1976652   0.74434316  0.1850028 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.93199974 -0.08156222 -0.00286937]
[RMSNorm(raw)] Token 0 Last 3: [-0.22346686 -0.16599897 -0.27312204]
[RMSNorm(raw)] Token 1 First 3: [-0.18910357  0.1225443  -0.09314123]
[RMSNorm(raw)] Token 1 Last 3: [-0.10990577 -0.41014227 -0.56217194]
[RMSNorm(raw)] Token 2 First 3: [ 2.76688486e-01  8.51534009e-02 -1.19062264e-04]
[RMSNorm(raw)] Token 2 Last 3: [-0.06770684 -0.05741571  0.13280296]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.6971939  0.1546141 14.073864 ]
[RMSNorm(weight)] Last 3: [4.596885  3.3596582 1.0083199]
--------------------
[layer14pre_ffn_norm] Shape: (1, 3, 768)
[layer14pre_ffn_norm] First 5 values: [3.4457836151123047, -0.0941728875041008, -0.04325249791145325, -0.28897491097450256, -0.5962094664573669]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.0817030593752861, 0.18389186263084412, -0.03978937119245529, 0.053162261843681335, -0.05060163885354996]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.10520146787166595, 0.0007705837488174438, -0.10667077451944351, -0.004365850239992142, -0.09159719944000244]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-0.0021424328442662954, -0.0018790788017213345, 1.0122894309461117e-05, -0.004113711882382631, -0.0029899294022470713]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.5535873  -0.48553875  0.00261567]
[RMSNorm(raw)] Token 0 Last 3: [0.6355193  0.36051828 0.29508826]
[RMSNorm(raw)] Token 1 First 3: [-0.21721187  0.04499176  0.49209344]
[RMSNorm(raw)] Token 1 Last 3: [0.55233115 0.7002007  1.0562721 ]
[RMSNorm(raw)] Token 2 First 3: [-0.37590042  0.5929486   0.3313116 ]
[RMSNorm(raw)] Token 2 Last 3: [-1.3675895   0.4820899   0.39173096]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [24.122849 70.56612  22.654285]
[RMSNorm(weight)] Last 3: [22.614922 40.122776 80.75089 ]
--------------------
[layer14_post_ffn_norm] Shape: (1, 3, 768)
[layer14_post_ffn_norm] Token 0 First 3: [-13.90769   -34.748123    0.0618719]
[layer14_post_ffn_norm] Token 0 Last 3: [15.007739 14.825512 24.12373 ]
[layer14_post_ffn_norm] Token 1 First 3: [-5.456981   3.2198853 11.640119 ]
[layer14_post_ffn_norm] Token 1 Last 3: [13.043257 28.794195 86.35119 ]
[layer14_post_ffn_norm] Token 2 First 3: [-9.443689  42.435028   7.8369393]
[layer14_post_ffn_norm] Token 2 Last 3: [-32.295517  19.824875  32.024357]
--------------------
[layer14_decoder_block_out] Shape: (1, 3, 768)
[layer14_decoder_block_out] Token 0 First 3: [235.22816   -56.55078    -0.7051487]
[layer14_decoder_block_out] Token 0 Last 3: [-44.7279   -29.548203 -48.885403]
[layer14_decoder_block_out] Token 1 First 3: [-27.494877    17.501045     0.78555584]
[layer14_decoder_block_out] Token 1 Last 3: [  0.23497486 -19.003275    20.836372  ]
[layer14_decoder_block_out] Token 2 First 3: [128.00987    84.73761     7.7777915]
[layer14_decoder_block_out] Token 2 Last 3: [-65.930984  -8.698153  97.99834 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.84724885 -0.20368558 -0.00253982]
[RMSNorm(raw)] Token 0 Last 3: [-0.16110173 -0.10642722 -0.17607628]
[RMSNorm(raw)] Token 1 First 3: [-0.19956309  0.12702595  0.00570171]
[RMSNorm(raw)] Token 1 Last 3: [ 0.00170549 -0.13792941  0.15123439]
[RMSNorm(raw)] Token 2 First 3: [0.17801641 0.11784001 0.01081615]
[RMSNorm(raw)] Token 2 Last 3: [-0.09168666 -0.01209605  0.136281  ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [14.4535055  3.3346558 33.60772  ]
[RMSNorm(weight)] Last 3: [18.653864  11.115719   4.9955015]
--------------------
[layer15_attention_norm] Shape: (1, 3, 768)
[layer15_attention_norm] Token 0 First 3: [13.092965   -0.88290685 -0.08789726]
[layer15_attention_norm] Token 0 Last 3: [-3.1662714 -1.2894423 -1.0556656]
[layer15_attention_norm] Token 1 First 3: [-3.0839493   0.55061376  0.19732334]
[layer15_attention_norm] Token 1 Last 3: [ 0.03351952 -1.671114    0.906726  ]
[layer15_attention_norm] Token 2 First 3: [2.7509775 0.5107959 0.3743224]
[layer15_attention_norm] Token 2 Last 3: [-1.8019971  -0.14655235  0.8170729 ]
--------------------
[layer15_attention_norm] Shape: (1, 3, 768)
[layer15_attention_norm] Token 0 First 3: [13.092965   -0.88290685 -0.08789726]
[layer15_attention_norm] Token 0 Last 3: [-3.1662714 -1.2894423 -1.0556656]
[layer15_attention_norm] Token 1 First 3: [-3.0839493   0.55061376  0.19732334]
[layer15_attention_norm] Token 1 Last 3: [ 0.03351952 -1.671114    0.906726  ]
[layer15_attention_norm] Token 2 First 3: [2.7509775 0.5107959 0.3743224]
[layer15_attention_norm] Token 2 Last 3: [-1.8019971  -0.14655235  0.8170729 ]
--------------------
[layer15_wq_weight] Shape: (768, 768)
[layer15_wq_weight] First 3: [-0.00521574  0.0174554   0.0011504 ]
[layer15_wq_weight] Last 3: [-0.01904113  0.02101885  0.01005114]
--------------------
[layer15_wk_weight] Shape: (768, 256)
[layer15_wk_weight] First 3: [ 0.00375537 -0.02160019 -0.00292443]
[layer15_wk_weight] Last 3: [-0.00584284  0.01295495 -0.0033046 ]
--------------------
[layer15_wv_weight] Shape: (768, 256)
[layer15_wv_weight] First 3: [ 0.00080145  0.00784792 -0.00323226]
[layer15_wv_weight] Last 3: [0.00165266 0.01913369 0.00701328]
--------------------
[layer15_wq] Shape: (1, 3, 768)
[layer15_wq] Token 0 First 3: [ 0.46933812 -4.446855   -0.25982857]
[layer15_wq] Token 0 Last 3: [-0.12346368  1.7920358  -0.874297  ]
[layer15_wq] Token 1 First 3: [ 1.3768705 -7.2624946 -2.365495 ]
[layer15_wq] Token 1 Last 3: [0.05178565 1.8012874  1.7923315 ]
[layer15_wq] Token 2 First 3: [ 0.15370923 -1.2519969  -0.12898028]
[layer15_wq] Token 2 Last 3: [-0.13181826 -0.41594535 -0.21353433]
--------------------
[layer15_wk] Shape: (1, 3, 256)
[layer15_wk] Token 0 First 3: [-0.27643368  1.2929661  -0.0840964 ]
[layer15_wk] Token 0 Last 3: [-0.91301155  1.0817162   0.4105527 ]
[layer15_wk] Token 1 First 3: [-1.6056359   1.0452685   0.34092116]
[layer15_wk] Token 1 Last 3: [-2.5121765  2.2012568  3.7824385]
[layer15_wk] Token 2 First 3: [-0.08789042  0.34961927 -0.04629821]
[layer15_wk] Token 2 Last 3: [-0.7895143   0.10285681  0.3190547 ]
--------------------
[layer15_wv] Shape: (1, 3, 256)
[layer15_wv] Token 0 First 3: [-0.60703576 -0.36396745 -0.5576087 ]
[layer15_wv] Token 0 Last 3: [ 0.275785   -0.2279519  -0.06028163]
[layer15_wv] Token 1 First 3: [ 0.01153307 -0.7635382  -2.1346197 ]
[layer15_wv] Token 1 Last 3: [ 1.220364   -0.8835808  -0.31808022]
[layer15_wv] Token 2 First 3: [0.07814355 0.23357633 0.08874019]
[layer15_wv] Token 2 Last 3: [-0.08496048 -0.13636345  0.16750896]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 0.40193895 -3.8082654  -0.22251596]
[RMSNorm(raw)] Last 3: [-0.31657088 -0.9989221  -0.51281774]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.23191409 -1.1451862   0.48595387]
[RMSNorm(weight)] Last 3: [-0.411905    0.06014944 -0.5730084 ]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.2668389   1.2480884  -0.08117749]
[RMSNorm(raw)] Last 3: [-1.0586867   0.13792422  0.42783138]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.3191479  -1.1948917   0.23115927]
[RMSNorm(weight)] Last 3: [3.1287823 1.5244702 5.036957 ]
--------------------
[layer15_q_norm_out] Shape: (1, 3, 768)
[layer15_q_norm_out] Token 0 First 3: [ 0.49515423  0.5529075  -0.33064842]
[layer15_q_norm_out] Token 0 Last 3: [-0.07774819  2.0343108  -0.39974394]
[layer15_q_norm_out] Token 1 First 3: [ 0.6771463   0.42093995 -1.4032543 ]
[layer15_q_norm_out] Token 1 Last 3: [0.01304743 0.8181224  0.3278731 ]
[layer15_q_norm_out] Token 2 First 3: [ 0.35811067  0.343768   -0.36246458]
[layer15_q_norm_out] Token 2 Last 3: [-0.18617375 -1.0590067  -0.21896885]
--------------------
[layer15_k_norm_out] Shape: (1, 3, 256)
[layer15_k_norm_out] Token 0 First 3: [-0.352      -0.24324206 -0.09994241]
[layer15_k_norm_out] Token 0 Last 3: [-3.6387854  2.635978   2.3924627]
[layer15_k_norm_out] Token 1 First 3: [-0.8770202  -0.084351    0.17379498]
[layer15_k_norm_out] Token 1 Last 3: [-4.2947826  2.300965   9.454945 ]
[layer15_k_norm_out] Token 2 First 3: [-0.15546854 -0.09136843 -0.07643388]
[layer15_k_norm_out] Token 2 Last 3: [-4.371087   0.3481856  2.5827997]
--------------------
[layer15_attention_out_core] Shape: (1, 3, 768)
[layer15_attention_out_core] Token 0 First 3: [-0.15554805 -0.31138295 -0.91664904]
[layer15_attention_out_core] Token 0 Last 3: [ 0.3072603  -0.28731757 -0.03831564]
[layer15_attention_out_core] Token 1 First 3: [-0.1927392  -0.24732518 -0.72972155]
[layer15_attention_out_core] Token 1 Last 3: [ 0.22116311 -0.29243207  0.0380179 ]
[layer15_attention_out_core] Token 2 First 3: [-0.2335266  -0.07520425 -0.29033646]
[layer15_attention_out_core] Token 2 Last 3: [-0.01209348 -0.17574024  0.13850024]
--------------------
[layer15_wo_weight] Shape: (768, 768)
[layer15_wo_weight] First 3: [-0.00073182 -0.00764025 -0.00435154]
[layer15_wo_weight] Last 3: [0.00714437 0.00726864 0.00573115]
--------------------
[layer15_attention_out_proj] Shape: (1, 3, 768)
[layer15_attention_out_proj] Token 0 First 3: [ 0.05651864 -0.07170908  0.02566956]
[layer15_attention_out_proj] Token 0 Last 3: [-0.09811442 -0.01439482  0.00270273]
[layer15_attention_out_proj] Token 1 First 3: [0.02199077 0.00114506 0.06062199]
[layer15_attention_out_proj] Token 1 Last 3: [-0.07895418 -0.00278234  0.01794694]
[layer15_attention_out_proj] Token 2 First 3: [-0.02517214  0.03217394  0.05494705]
[layer15_attention_out_proj] Token 2 Last 3: [-0.00095218 -0.04168124  0.04063518]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.1657083  -0.2102455   0.07526116]
[RMSNorm(raw)] Token 0 Last 3: [-0.2876639 -0.0422045  0.0079242]
[RMSNorm(raw)] Token 1 First 3: [0.07434276 0.00387101 0.20494083]
[RMSNorm(raw)] Token 1 Last 3: [-0.26691526 -0.00940609  0.06067205]
[RMSNorm(raw)] Token 2 First 3: [-0.11643133  0.14881746  0.2541523 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.0044042  -0.19279256  0.18795411]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [26.85094  77.09018  28.967709]
[RMSNorm(weight)] Last 3: [ 32.831062  48.60054  100.469086]
--------------------
[layer15_ffn_norm] Shape: (1, 3, 768)
[layer15_ffn_norm] Token 0 First 3: [  4.6151323 -16.41811     2.2554045]
[layer15_ffn_norm] Token 0 Last 3: [-9.731976   -2.0933661   0.80406123]
[layer15_ffn_norm] Token 1 First 3: [2.0705159  0.30228823 6.141607  ]
[layer15_ffn_norm] Token 1 Last 3: [-9.030026   -0.46654728  6.1563373 ]
[layer15_ffn_norm] Token 2 First 3: [-3.2427223 11.621182   7.616362 ]
[layer15_ffn_norm] Token 2 Last 3: [-0.14899872 -9.562615   19.071531  ]
--------------------
[layer15_post_attention_norm] Shape: (1, 3, 768)
[layer15_post_attention_norm] Token 0 First 3: [  4.6151323 -16.41811     2.2554045]
[layer15_post_attention_norm] Token 0 Last 3: [-9.731976   -2.0933661   0.80406123]
[layer15_post_attention_norm] Token 1 First 3: [2.0705159  0.30228823 6.141607  ]
[layer15_post_attention_norm] Token 1 Last 3: [-9.030026   -0.46654728  6.1563373 ]
[layer15_post_attention_norm] Token 2 First 3: [-3.2427223 11.621182   7.616362 ]
[layer15_post_attention_norm] Token 2 Last 3: [-0.14899872 -9.562615   19.071531  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.92248946 -0.2806542   0.00596262]
[RMSNorm(raw)] Token 0 Last 3: [-0.20946452 -0.12170035 -0.1849313 ]
[RMSNorm(raw)] Token 1 First 3: [-0.2035985   0.14256924  0.05547278]
[RMSNorm(raw)] Token 1 Last 3: [-0.07043085 -0.1559145   0.21615785]
[RMSNorm(raw)] Token 2 First 3: [0.1788381  0.13811828 0.02206559]
[RMSNorm(raw)] Token 2 Last 3: [-0.0947174  -0.02617453  0.16780502]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [3.2200751  0.11012885 7.5697327 ]
[RMSNorm(weight)] Last 3: [4.251316  2.7998488 0.7698068]
--------------------
[layer15pre_ffn_norm] Shape: (1, 3, 768)
[layer15pre_ffn_norm] First 5 values: [3.892974853515625, -0.31156232953071594, 0.051098067313432693, -0.9187656044960022, -0.8062407970428467]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.06599777936935425, 0.37300509214401245, 0.12437936663627625, 0.032415468245744705, -0.5343989133834839]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.033435575664043427, -0.06913381814956665, 0.06337252259254456, 0.04841618612408638, -1.14522123336792]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.004537768661975861, 0.0018766431603580713, -0.0006078542210161686, -0.000658283126540482, -0.00443555461242795]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.3055551  0.5399264 -0.1748849]
[RMSNorm(raw)] Token 0 Last 3: [-0.16090149  0.2867184  -1.0081788 ]
[RMSNorm(raw)] Token 1 First 3: [ 1.6852087   0.26372978 -0.16843371]
[RMSNorm(raw)] Token 1 Last 3: [-0.6250281   0.2593514  -0.11453135]
[RMSNorm(raw)] Token 2 First 3: [ 0.11789109 -0.00868099 -0.10897465]
[RMSNorm(raw)] Token 2 Last 3: [-0.52682704  0.74004275 -0.395259  ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [37.311974 91.77649  42.376602]
[RMSNorm(weight)] Last 3: [ 42.114227  58.979828 120.2661  ]
--------------------
[layer15_post_ffn_norm] Shape: (1, 3, 768)
[layer15_post_ffn_norm] Token 0 First 3: [50.018394  50.092476  -7.5859127]
[layer15_post_ffn_norm] Token 0 Last 3: [  -6.9371433   17.19732   -122.25791  ]
[layer15_post_ffn_norm] Token 1 First 3: [64.56367   24.467924  -7.3060822]
[layer15_post_ffn_norm] Token 1 Last 3: [-26.947603  15.555853 -13.88877 ]
[layer15_post_ffn_norm] Token 2 First 3: [ 4.51664    -0.80539185 -4.72695   ]
[layer15_post_ffn_norm] Token 2 Last 3: [-22.713741  44.387638 -47.931515]
--------------------
[layer15_decoder_block_out] Shape: (1, 3, 768)
[layer15_decoder_block_out] Token 0 First 3: [289.8617   -22.876411  -6.035657]
[layer15_decoder_block_out] Token 0 Last 3: [ -61.39702   -14.444248 -170.33925 ]
[layer15_decoder_block_out] Token 1 First 3: [39.139305  42.271255  -0.3789196]
[layer15_decoder_block_out] Token 1 Last 3: [-35.742653  -3.913969  13.10394 ]
[layer15_decoder_block_out] Token 2 First 3: [129.2838    95.553406  10.667204]
[layer15_decoder_block_out] Token 2 Last 3: [-88.79373  26.12687  69.13835]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.0627272  -0.08387236 -0.02212868]
[RMSNorm(raw)] Token 0 Last 3: [-0.22510143 -0.05295731 -0.62451905]
[RMSNorm(raw)] Token 1 First 3: [ 0.260019    0.28082588 -0.00251732]
[RMSNorm(raw)] Token 1 Last 3: [-0.23745361 -0.02600216  0.08705503]
[RMSNorm(raw)] Token 2 First 3: [0.15829007 0.11699189 0.01306051]
[RMSNorm(raw)] Token 2 Last 3: [-0.1087156   0.03198873  0.08465032]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [11.184807   5.7263727 14.968947 ]
[RMSNorm(weight)] Last 3: [13.289328  8.725865  3.78974 ]
--------------------
[layer16_attention_norm] Shape: (1, 3, 768)
[layer16_attention_norm] Token 0 First 3: [12.949126   -0.5641568  -0.35337174]
[layer16_attention_norm] Token 0 Last 3: [-3.216548   -0.51505566 -2.991284  ]
[layer16_attention_norm] Token 1 First 3: [ 3.1682813   1.8889395  -0.04019901]
[layer16_attention_norm] Token 1 Last 3: [-3.3930523  -0.25289348  0.416971  ]
[layer16_attention_norm] Token 2 First 3: [1.928734   0.78693104 0.20856261]
[layer16_attention_norm] Token 2 Last 3: [-1.5534729   0.31111804  0.405453  ]
--------------------
[layer16_attention_norm] Shape: (1, 3, 768)
[layer16_attention_norm] Token 0 First 3: [12.949126   -0.5641568  -0.35337174]
[layer16_attention_norm] Token 0 Last 3: [-3.216548   -0.51505566 -2.991284  ]
[layer16_attention_norm] Token 1 First 3: [ 3.1682813   1.8889395  -0.04019901]
[layer16_attention_norm] Token 1 Last 3: [-3.3930523  -0.25289348  0.416971  ]
[layer16_attention_norm] Token 2 First 3: [1.928734   0.78693104 0.20856261]
[layer16_attention_norm] Token 2 Last 3: [-1.5534729   0.31111804  0.405453  ]
--------------------
[layer16_wq_weight] Shape: (768, 768)
[layer16_wq_weight] First 3: [ 0.00756079 -0.00976691  0.0259007 ]
[layer16_wq_weight] Last 3: [ 0.0052072   0.00457251 -0.00834888]
--------------------
[layer16_wk_weight] Shape: (768, 256)
[layer16_wk_weight] First 3: [-0.00166151  0.01050884 -0.00615557]
[layer16_wk_weight] Last 3: [ 0.00557434 -0.00692926  0.00394461]
--------------------
[layer16_wv_weight] Shape: (768, 256)
[layer16_wv_weight] First 3: [ 0.00627374 -0.01111705  0.00308275]
[layer16_wv_weight] Last 3: [-0.00076443  0.00161612 -0.00157658]
--------------------
[layer16_wq] Shape: (1, 3, 768)
[layer16_wq] Token 0 First 3: [-0.05584548 -0.09279642  1.6218427 ]
[layer16_wq] Token 0 Last 3: [-0.666085    0.06781733 -0.1700991 ]
[layer16_wq] Token 1 First 3: [-0.67636156  0.69909894  6.7534223 ]
[layer16_wq] Token 1 Last 3: [ 0.8721723  -0.16553634 -0.22216149]
[layer16_wq] Token 2 First 3: [-0.04603821  0.04660828  1.6920171 ]
[layer16_wq] Token 2 Last 3: [ 0.33183283  0.02464087 -0.17310724]
--------------------
[layer16_wk] Shape: (1, 3, 256)
[layer16_wk] Token 0 First 3: [-1.3329954  -1.0290661   0.14328742]
[layer16_wk] Token 0 Last 3: [ 1.3282213  -0.13664299 -0.9411249 ]
[layer16_wk] Token 1 First 3: [-2.2266037 -1.3702816  2.506196 ]
[layer16_wk] Token 1 Last 3: [2.4339128  0.79256886 0.05025518]
[layer16_wk] Token 2 First 3: [-0.1365323  -0.19145668 -0.00021942]
[layer16_wk] Token 2 Last 3: [ 1.0866916   0.01532096 -0.20252581]
--------------------
[layer16_wv] Shape: (1, 3, 256)
[layer16_wv] Token 0 First 3: [-0.7652937 -0.5964846  1.3464437]
[layer16_wv] Token 0 Last 3: [ 0.26234066 -0.36455446  0.59741455]
[layer16_wv] Token 1 First 3: [-0.4860834  -0.09354514  1.2690114 ]
[layer16_wv] Token 1 Last 3: [-0.88600135 -0.88883233  1.1286881 ]
[layer16_wv] Token 2 First 3: [ 0.28575367 -0.16961643 -0.32158694]
[layer16_wv] Token 2 Last 3: [ 0.11797333 -0.08483815  0.02002973]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.04743291 -0.07881756  1.3775283 ]
[RMSNorm(raw)] Last 3: [ 0.79863644  0.05930426 -0.41662467]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.8264874   0.59563935 -0.9961759 ]
[RMSNorm(weight)] Last 3: [-0.19248559  0.4042759  -0.04153791]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-1.3157563  -1.0157576   0.14143434]
[RMSNorm(raw)] Last 3: [ 1.700484    0.02397465 -0.3169178 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.94640535  0.6155737  -0.99329007]
[RMSNorm(weight)] Last 3: [2.659808  1.1988102 2.057114 ]
--------------------
[layer16_q_norm_out] Shape: (1, 3, 768)
[layer16_q_norm_out] Token 0 First 3: [-0.08663562 -0.1257644   0.00526783]
[layer16_q_norm_out] Token 0 Last 3: [-0.43176958  0.07644784 -0.1308727 ]
[layer16_q_norm_out] Token 1 First 3: [-0.62667376  0.5658734   0.01310089]
[layer16_q_norm_out] Token 1 Last 3: [ 0.45156866 -0.14904486 -0.13652587]
[layer16_q_norm_out] Token 2 First 3: [-0.17761888  0.15709117  0.01366752]
[layer16_q_norm_out] Token 2 Last 3: [ 0.64491045  0.08327954 -0.39931896]
--------------------
[layer16_k_norm_out] Shape: (1, 3, 256)
[layer16_k_norm_out] Token 0 First 3: [-2.5609953e+00 -1.6410311e+00  9.4901497e-04]
[layer16_k_norm_out] Token 0 Last 3: [ 4.798169   -0.29656637 -2.8399172 ]
[layer16_k_norm_out] Token 1 First 3: [-2.508819   -1.2815328   0.00973478]
[layer16_k_norm_out] Token 1 Last 3: [5.1565166  1.0088296  0.08893763]
[layer16_k_norm_out] Token 2 First 3: [-4.1584837e-01 -4.8402023e-01 -2.3038801e-06]
[layer16_k_norm_out] Token 2 Last 3: [ 6.223445    0.05271571 -0.96885383]
--------------------
[layer16_attention_out_core] Shape: (1, 3, 768)
[layer16_attention_out_core] Token 0 First 3: [-0.14458007 -0.22193515  0.4763141 ]
[layer16_attention_out_core] Token 0 Last 3: [-0.03115233 -0.4526005   0.6475586 ]
[layer16_attention_out_core] Token 1 First 3: [ 0.06906256 -0.17692216  0.09806235]
[layer16_attention_out_core] Token 1 Last 3: [-0.7911472  -0.81637436  1.0304711 ]
[layer16_attention_out_core] Token 2 First 3: [ 0.24076544 -0.17584595 -0.23888567]
[layer16_attention_out_core] Token 2 Last 3: [ 0.1124976  -0.08954619  0.02667843]
--------------------
[layer16_wo_weight] Shape: (768, 768)
[layer16_wo_weight] First 3: [ 0.00069981 -0.00923346  0.0056288 ]
[layer16_wo_weight] Last 3: [-0.00144535  0.00050439  0.01375542]
--------------------
[layer16_attention_out_proj] Shape: (1, 3, 768)
[layer16_attention_out_proj] Token 0 First 3: [-0.09411157 -0.0109355  -0.01514605]
[layer16_attention_out_proj] Token 0 Last 3: [-0.03536347  0.10594936  0.11351616]
[layer16_attention_out_proj] Token 1 First 3: [-0.02973265 -0.03592481 -0.06374303]
[layer16_attention_out_proj] Token 1 Last 3: [ 0.03038153  0.04565841 -0.05104243]
[layer16_attention_out_proj] Token 2 First 3: [-0.00296791 -0.04963747 -0.00477874]
[layer16_attention_out_proj] Token 2 Last 3: [ 0.00943569 -0.02918866  0.06695876]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.7709944  -0.08958741 -0.12408166]
[RMSNorm(raw)] Token 0 Last 3: [-0.28970972  0.8679736   0.9299635 ]
[RMSNorm(raw)] Token 1 First 3: [-0.15738738 -0.19016509 -0.33741853]
[RMSNorm(raw)] Token 1 Last 3: [ 0.16082217  0.2416891  -0.27018896]
[RMSNorm(raw)] Token 2 First 3: [-0.02830918 -0.47346327 -0.04558161]
[RMSNorm(raw)] Token 2 Last 3: [ 0.09000158 -0.27841386  0.6386811 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 20.260683 102.71538   32.69524 ]
[RMSNorm(weight)] Last 3: [45.605392 44.845192 80.55164 ]
--------------------
[layer16_ffn_norm] Shape: (1, 3, 768)
[layer16_ffn_norm] Token 0 First 3: [-16.391869   -9.291592   -4.1809616]
[layer16_ffn_norm] Token 0 Last 3: [-13.502035  39.792416  75.84006 ]
[layer16_ffn_norm] Token 1 First 3: [ -3.346163 -19.723043 -11.369398]
[layer16_ffn_norm] Token 1 Last 3: [  7.49518   11.080283 -22.034353]
[layer16_ffn_norm] Token 2 First 3: [ -0.60187244 -49.105423    -1.5358833 ]
[layer16_ffn_norm] Token 2 Last 3: [  4.194559 -12.763937  52.085495]
--------------------
[layer16_post_attention_norm] Shape: (1, 3, 768)
[layer16_post_attention_norm] Token 0 First 3: [-16.391869   -9.291592   -4.1809616]
[layer16_post_attention_norm] Token 0 Last 3: [-13.502035  39.792416  75.84006 ]
[layer16_post_attention_norm] Token 1 First 3: [ -3.346163 -19.723043 -11.369398]
[layer16_post_attention_norm] Token 1 Last 3: [  7.49518   11.080283 -22.034353]
[layer16_post_attention_norm] Token 2 First 3: [ -0.60187244 -49.105423    -1.5358833 ]
[layer16_post_attention_norm] Token 2 Last 3: [  4.194559 -12.763937  52.085495]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.4976075  -0.1761622  -0.05594945]
[RMSNorm(raw)] Token 0 Last 3: [-0.410171    0.13881461 -0.51750755]
[RMSNorm(raw)] Token 1 First 3: [ 0.32144228  0.20249547 -0.10550642]
[RMSNorm(raw)] Token 1 Last 3: [-0.253678    0.06435748 -0.08020007]
[RMSNorm(raw)] Token 2 First 3: [0.18786928 0.06781176 0.01333128]
[RMSNorm(raw)] Token 2 Last 3: [-0.12351062  0.01950922  0.17698084]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [4.4398685  0.30943304 5.165595  ]
[RMSNorm(weight)] Last 3: [4.2973065  2.723905   0.79187036]
--------------------
[layer16pre_ffn_norm] Shape: (1, 3, 768)
[layer16pre_ffn_norm] First 5 values: [8.146787643432617, -0.23067259788513184, -0.34496161341667175, -2.1509547233581543, -2.9464941024780273]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.12667468190193176, 0.03640130162239075, -0.18567538261413574, 0.5477908849716187, -0.23380085825920105]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.05013115704059601, 0.2097051590681076, -0.451668381690979, 0.23735930025577545, -0.264560341835022]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.02443506568670273, 0.014471922069787979, 0.0002717450261116028, 0.013451379723846912, 0.023720741271972656]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.4867885  0.28830555 0.00541363]
[RMSNorm(raw)] Token 0 Last 3: [-0.6828436  -0.08024258 -0.07928751]
[RMSNorm(raw)] Token 1 First 3: [ 0.45166034  0.43919414 -0.6084254 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.32498708 -0.15814735 -0.18951526]
[RMSNorm(raw)] Token 2 First 3: [ 0.93124455 -0.11500491 -2.0245907 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.7558125  -0.01241586  0.33989418]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 56.14236 180.01659  84.52588]
[RMSNorm(weight)] Last 3: [ 79.32777  99.73871 195.3443 ]
--------------------
[layer16_post_ffn_norm] Shape: (1, 3, 768)
[layer16_post_ffn_norm] Token 0 First 3: [27.816244   52.188087    0.46300527]
[layer16_post_ffn_norm] Token 0 Last 3: [-54.851303  -8.083534 -15.56765 ]
[layer16_post_ffn_norm] Token 1 First 3: [ 25.808937  79.50143  -52.036114]
[layer16_post_ffn_norm] Token 1 Last 3: [-26.105486 -15.93156  -37.210243]
[layer16_post_ffn_norm] Token 2 First 3: [  53.213512  -20.817797 -173.1549  ]
[layer16_post_ffn_norm] Token 2 Last 3: [-60.71273    -1.2507572  66.73628  ]
--------------------
[layer16_decoder_block_out] Shape: (1, 3, 768)
[layer16_decoder_block_out] Token 0 First 3: [301.28607   20.020084  -9.753613]
[layer16_decoder_block_out] Token 0 Last 3: [-129.75037    17.264633 -110.06684 ]
[layer16_decoder_block_out] Token 1 First 3: [ 61.602077 102.04964  -63.78443 ]
[layer16_decoder_block_out] Token 1 Last 3: [-54.35296   -8.765245 -46.140656]
[layer16_decoder_block_out] Token 2 First 3: [ 181.89545    25.630186 -164.02359 ]
[layer16_decoder_block_out] Token 2 Last 3: [-145.3119     12.112175  187.96013 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.0234134   0.06800455 -0.03313123]
[RMSNorm(raw)] Token 0 Last 3: [-0.44073817  0.05864479 -0.37387684]
[RMSNorm(raw)] Token 1 First 3: [ 0.39900863  0.6609953  -0.41314417]
[RMSNorm(raw)] Token 1 Last 3: [-0.3520547  -0.0567742  -0.29886198]
[RMSNorm(raw)] Token 2 First 3: [ 0.27135235  0.03823521 -0.24469106]
[RMSNorm(raw)] Token 2 Last 3: [-0.21677688  0.01806899  0.28039968]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [20.282627   7.8308077 13.503637 ]
[RMSNorm(weight)] Last 3: [11.488137  9.119809  4.745205]
--------------------
[layer17_attention_norm] Shape: (1, 3, 768)
[layer17_attention_norm] Token 0 First 3: [21.780926   0.6005351 -0.4805234]
[layer17_attention_norm] Token 0 Last 3: [-5.5039988   0.59347403 -2.147999  ]
[layer17_attention_norm] Token 1 First 3: [ 8.491952   5.8371224 -5.992093 ]
[layer17_attention_norm] Token 1 Last 3: [-4.3965073 -0.5745441 -1.7170234]
[layer17_attention_norm] Token 2 First 3: [ 5.7750907   0.33764783 -3.5489104 ]
[layer17_attention_norm] Token 2 Last 3: [-2.7071395   0.18285474  1.6109536 ]
--------------------
[layer17_attention_norm] Shape: (1, 3, 768)
[layer17_attention_norm] Token 0 First 3: [21.780926   0.6005351 -0.4805234]
[layer17_attention_norm] Token 0 Last 3: [-5.5039988   0.59347403 -2.147999  ]
[layer17_attention_norm] Token 1 First 3: [ 8.491952   5.8371224 -5.992093 ]
[layer17_attention_norm] Token 1 Last 3: [-4.3965073 -0.5745441 -1.7170234]
[layer17_attention_norm] Token 2 First 3: [ 5.7750907   0.33764783 -3.5489104 ]
[layer17_attention_norm] Token 2 Last 3: [-2.7071395   0.18285474  1.6109536 ]
--------------------
[layer17_wq_weight] Shape: (768, 768)
[layer17_wq_weight] First 3: [ 0.00619663 -0.00096319 -0.0017183 ]
[layer17_wq_weight] Last 3: [0.00261576 0.00727451 0.00051118]
--------------------
[layer17_wk_weight] Shape: (768, 256)
[layer17_wk_weight] First 3: [-0.00595938 -0.00122833  0.00386595]
[layer17_wk_weight] Last 3: [-0.00189477  0.00473258  0.00159939]
--------------------
[layer17_wv_weight] Shape: (768, 256)
[layer17_wv_weight] First 3: [-0.01076225 -0.00677671  0.00768865]
[layer17_wv_weight] Last 3: [-0.01856973 -0.00054755  0.00865621]
--------------------
[layer17_wq] Shape: (1, 3, 768)
[layer17_wq] Token 0 First 3: [ -0.30857778 -10.700049     0.01765931]
[layer17_wq] Token 0 Last 3: [ 3.4459085 -1.3816866  1.304321 ]
[layer17_wq] Token 1 First 3: [  2.1983817 -16.09266    -3.3615875]
[layer17_wq] Token 1 Last 3: [ 3.719739  -3.1100225  4.7007265]
[layer17_wq] Token 2 First 3: [-0.2553776  -5.458723   -0.01172562]
[layer17_wq] Token 2 Last 3: [ 1.5904212  -0.40129393  2.0389357 ]
--------------------
[layer17_wk] Shape: (1, 3, 256)
[layer17_wk] Token 0 First 3: [ 0.26039767 -4.0374556   0.19484164]
[layer17_wk] Token 0 Last 3: [ 3.9745092 -1.4236047 -0.4491325]
[layer17_wk] Token 1 First 3: [-2.920578  -3.5798638  2.738386 ]
[layer17_wk] Token 1 Last 3: [ 8.070779  -4.6639423 -0.4044124]
[layer17_wk] Token 2 First 3: [ 0.35724372 -1.0464993   0.07751504]
[layer17_wk] Token 2 Last 3: [ 8.99271    -0.23591049  5.027509  ]
--------------------
[layer17_wv] Shape: (1, 3, 256)
[layer17_wv] Token 0 First 3: [ 1.9441452  -0.70285314 -0.6648321 ]
[layer17_wv] Token 0 Last 3: [-1.4691548   0.16101842 -0.5930693 ]
[layer17_wv] Token 1 First 3: [ 3.4552007 -0.9172323  2.6330223]
[layer17_wv] Token 1 Last 3: [ 1.743232   -0.56670856  1.5027884 ]
[layer17_wv] Token 2 First 3: [-1.1206344 -0.9040363 -0.1432075]
[layer17_wv] Token 2 Last 3: [-0.2134583   0.14661019 -1.0926028 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.08909316 -3.0893385   0.00509863]
[RMSNorm(raw)] Last 3: [ 1.0228138  -0.25807565  1.3112575 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 2.762426  -0.9910213  5.276599 ]
[RMSNorm(weight)] Last 3: [-0.78543645 -0.64819896 -0.31449136]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.12858286 -1.9936723   0.09621168]
[RMSNorm(raw)] Last 3: [ 2.317506   -0.06079635  1.2956364 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.3125555  -0.98870504 -0.63281465]
[RMSNorm(weight)] Last 3: [12.046265  8.503749  8.398319]
--------------------
[layer17_q_norm_out] Shape: (1, 3, 768)
[layer17_q_norm_out] Token 0 First 3: [-0.3352064  -0.02773832  0.03200205]
[layer17_q_norm_out] Token 0 Last 3: [ 0.2985004  -0.19624196  0.36097956]
[layer17_q_norm_out] Token 1 First 3: [ 1.6232146  -0.02835616 -4.1406994 ]
[layer17_q_norm_out] Token 1 Last 3: [ 0.21255438 -0.29138175  0.8581823 ]
[layer17_q_norm_out] Token 2 First 3: [-0.5680308  -0.02897523 -0.04350922]
[layer17_q_norm_out] Token 2 Last 3: [ 0.21945857 -0.09079129  0.8988783 ]
--------------------
[layer17_k_norm_out] Shape: (1, 3, 256)
[layer17_k_norm_out] Token 0 First 3: [ 0.08839358 -0.02251845  0.03532752]
[layer17_k_norm_out] Token 0 Last 3: [25.604465  -6.6808295 -2.08435  ]
[layer17_k_norm_out] Token 1 First 3: [-0.5687488  -0.01145421  0.28483543]
[layer17_k_norm_out] Token 1 Last 3: [ 29.827415  -12.5563135  -1.076685 ]
[layer17_k_norm_out] Token 2 First 3: [ 0.06328963 -0.00304617  0.00733502]
[layer17_k_norm_out] Token 2 Last 3: [30.234798  -0.5777933 12.176805 ]
--------------------
[layer17_attention_out_core] Shape: (1, 3, 768)
[layer17_attention_out_core] Token 0 First 3: [ 2.1032786  -0.88425374  1.4831034 ]
[layer17_attention_out_core] Token 0 Last 3: [ 0.09566075 -0.10446893 -0.00677262]
[layer17_attention_out_core] Token 1 First 3: [-0.5545034 -0.8848394 -0.0358779]
[layer17_attention_out_core] Token 1 Last 3: [ 0.43346065 -0.10471539 -0.1588787 ]
[layer17_attention_out_core] Token 2 First 3: [ 0.86529154 -0.9022668   0.9766939 ]
[layer17_attention_out_core] Token 2 Last 3: [-0.2716148   0.03061339 -0.49974832]
--------------------
[layer17_wo_weight] Shape: (768, 768)
[layer17_wo_weight] First 3: [ 0.00264585 -0.00069297 -0.00140631]
[layer17_wo_weight] Last 3: [ 0.00170465 -0.00694371  0.0127335 ]
--------------------
[layer17_attention_out_proj] Shape: (1, 3, 768)
[layer17_attention_out_proj] Token 0 First 3: [-0.0207601  -0.06008777  0.04317281]
[layer17_attention_out_proj] Token 0 Last 3: [ 0.47598127 -0.19327413  0.04136052]
[layer17_attention_out_proj] Token 1 First 3: [-0.04489752 -0.1868844   0.14615923]
[layer17_attention_out_proj] Token 1 Last 3: [ 0.53437865 -0.3846663  -0.32686114]
[layer17_attention_out_proj] Token 2 First 3: [ 0.00216438 -0.08626108  0.01173882]
[layer17_attention_out_proj] Token 2 Last 3: [ 0.56637096 -0.31681016 -0.17804492]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.0213202  -0.06170894  0.04433761]
[RMSNorm(raw)] Token 0 Last 3: [ 0.4888232  -0.19848865  0.04247642]
[RMSNorm(raw)] Token 1 First 3: [-0.02396744 -0.09976368  0.07802354]
[RMSNorm(raw)] Token 1 Last 3: [ 0.285265   -0.2053447  -0.17448683]
[RMSNorm(raw)] Token 2 First 3: [ 0.00154411 -0.06154039  0.00837471]
[RMSNorm(raw)] Token 2 Last 3: [ 0.40406042 -0.22601874 -0.12702082]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 77.70776 532.7802  128.38306]
[RMSNorm(weight)] Last 3: [ 57.04822 123.5073  237.33994]
--------------------
[layer17_ffn_norm] Shape: (1, 3, 768)
[layer17_ffn_norm] Token 0 First 3: [ -1.6780655 -32.93901     5.736535 ]
[layer17_ffn_norm] Token 0 Last 3: [ 28.375319 -24.713287  10.123827]
[layer17_ffn_norm] Token 1 First 3: [ -1.886424 -53.251877  10.094924]
[layer17_ffn_norm] Token 1 Last 3: [ 16.559126 -25.566916 -41.58718 ]
[layer17_ffn_norm] Token 2 First 3: [  0.12153376 -32.84904      1.0835458 ]
[layer17_ffn_norm] Token 2 Last 3: [ 23.454988 -28.140984 -30.274134]
--------------------
[layer17_post_attention_norm] Shape: (1, 3, 768)
[layer17_post_attention_norm] Token 0 First 3: [ -1.6780655 -32.93901     5.736535 ]
[layer17_post_attention_norm] Token 0 Last 3: [ 28.375319 -24.713287  10.123827]
[layer17_post_attention_norm] Token 1 First 3: [ -1.886424 -53.251877  10.094924]
[layer17_post_attention_norm] Token 1 Last 3: [ 16.559126 -25.566916 -41.58718 ]
[layer17_post_attention_norm] Token 2 First 3: [  0.12153376 -32.84904      1.0835458 ]
[layer17_post_attention_norm] Token 2 Last 3: [ 23.454988 -28.140984 -30.274134]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.3424838  -0.05788713 -0.01799973]
[RMSNorm(raw)] Token 0 Last 3: [-0.45424137 -0.03337593 -0.44782472]
[RMSNorm(raw)] Token 1 First 3: [ 0.49765554  0.4066685  -0.44743514]
[RMSNorm(raw)] Token 1 Last 3: [-0.31496447 -0.28611577 -0.73110217]
[RMSNorm(raw)] Token 2 First 3: [ 0.30848753 -0.01223472 -0.2761554 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.20652655 -0.02716608  0.2672507 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 3.1536713  -0.07773094  2.3368325 ]
[RMSNorm(weight)] Last 3: [2.3575602  1.2181755  0.22123078]
--------------------
[layer17pre_ffn_norm] Shape: (1, 3, 768)
[layer17pre_ffn_norm] First 5 values: [5.576236248016357, -0.053387511521577835, -0.06006207689642906, -0.5912277698516846, -0.6970198750495911]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.14346139132976532, -0.33089885115623474, 0.04828687012195587, -0.21448582410812378, -0.34857070446014404]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.04092411696910858, 0.38014456629753113, -0.5509799718856812, -0.1850585639476776, 0.12390975654125214]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.03287913277745247, -0.006581593304872513, -0.040842387825250626, 0.022548142820596695, -0.013408761471509933]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.2003754  -0.24028562 -1.4911038 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.3786482   1.2749599  -0.83468896]
[RMSNorm(raw)] Token 1 First 3: [ 0.4295587 -1.0177978  1.4843123]
[RMSNorm(raw)] Token 1 Last 3: [ 1.008636   -0.07126052 -0.53253925]
[RMSNorm(raw)] Token 2 First 3: [0.14603308 0.5222574  0.2342776 ]
[RMSNorm(raw)] Token 2 Last 3: [ 0.5203626   0.49348775 -0.18829887]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 58.77116 265.8484  106.69724]
[RMSNorm(weight)] Last 3: [ 75.34173 106.66786 210.9994 ]
--------------------
[layer17_post_ffn_norm] Shape: (1, 3, 768)
[layer17_post_ffn_norm] Token 0 First 3: [  71.74783  -64.11983 -160.58777]
[layer17_post_ffn_norm] Token 0 Last 3: [ -28.906658  137.2722   -176.95357 ]
[layer17_post_ffn_norm] Token 1 First 3: [  25.675222 -271.59772   159.85634 ]
[layer17_post_ffn_norm] Token 1 Last 3: [  77.001015    -7.6724677 -112.898    ]
[layer17_post_ffn_norm] Token 2 First 3: [  8.728566 139.36354   25.231052]
[layer17_post_ffn_norm] Token 2 Last 3: [ 39.72538   53.13277  -39.919247]
--------------------
[layer17_decoder_block_out] Shape: (1, 3, 768)
[layer17_decoder_block_out] Token 0 First 3: [ 371.35583  -77.03876 -164.60484]
[layer17_decoder_block_out] Token 0 Last 3: [-130.28171  129.82355 -276.89658]
[layer17_decoder_block_out] Token 1 First 3: [  85.39088 -222.79996  106.16683]
[layer17_decoder_block_out] Token 1 Last 3: [  39.207184  -42.004627 -200.62584 ]
[layer17_decoder_block_out] Token 2 First 3: [ 190.74554  132.14468 -137.709  ]
[layer17_decoder_block_out] Token 2 Last 3: [-82.13154   37.103962 117.76674 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.0480931  -0.21742971 -0.46457115]
[RMSNorm(raw)] Token 0 Last 3: [-0.3676995   0.36640644 -0.7814968 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.3470141  -0.90542144  0.43144408]
[RMSNorm(raw)] Token 1 Last 3: [ 0.15933138 -0.17069972 -0.8153095 ]
[RMSNorm(raw)] Token 2 First 3: [ 0.1917558   0.13284457 -0.13843836]
[RMSNorm(raw)] Token 2 Last 3: [-0.08256654  0.03730048  0.11839047]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [22.370426  4.306779 10.856218]
[RMSNorm(weight)] Last 3: [22.198309 11.844152  5.762074]
--------------------
[layer18_attention_norm] Shape: (1, 3, 768)
[layer18_attention_norm] Token 0 First 3: [24.494383  -1.1538514 -5.508057 ]
[layer18_attention_norm] Token 0 Last 3: [-8.530006  4.70618  -5.284539]
[layer18_attention_norm] Token 1 First 3: [ 8.109867  -4.8048716  5.1152954]
[layer18_attention_norm] Token 1 Last 3: [ 3.6962185 -2.1924932 -5.513183 ]
[layer18_attention_norm] Token 2 First 3: [ 4.481415    0.70497674 -1.6413554 ]
[layer18_attention_norm] Token 2 Last 3: [-1.9154041   0.47909304  0.8005651 ]
--------------------
[layer18_attention_norm] Shape: (1, 3, 768)
[layer18_attention_norm] Token 0 First 3: [24.494383  -1.1538514 -5.508057 ]
[layer18_attention_norm] Token 0 Last 3: [-8.530006  4.70618  -5.284539]
[layer18_attention_norm] Token 1 First 3: [ 8.109867  -4.8048716  5.1152954]
[layer18_attention_norm] Token 1 Last 3: [ 3.6962185 -2.1924932 -5.513183 ]
[layer18_attention_norm] Token 2 First 3: [ 4.481415    0.70497674 -1.6413554 ]
[layer18_attention_norm] Token 2 Last 3: [-1.9154041   0.47909304  0.8005651 ]
--------------------
[layer18_wq_weight] Shape: (768, 768)
[layer18_wq_weight] First 3: [ 0.0103772  -0.01540585 -0.00664066]
[layer18_wq_weight] Last 3: [-0.00474295 -0.00462341  0.01180598]
--------------------
[layer18_wk_weight] Shape: (768, 256)
[layer18_wk_weight] First 3: [ 0.01858073  0.01739951 -0.00040876]
[layer18_wk_weight] Last 3: [-0.00310752 -0.00604692  0.0083899 ]
--------------------
[layer18_wv_weight] Shape: (768, 256)
[layer18_wv_weight] First 3: [ 0.00387182  0.00536057 -0.00820542]
[layer18_wv_weight] Last 3: [-0.02272612 -0.00776326 -0.0118178 ]
--------------------
[layer18_wq] Shape: (1, 3, 768)
[layer18_wq] Token 0 First 3: [-2.6237879  -0.77734196  9.329539  ]
[layer18_wq] Token 0 Last 3: [-7.282439   2.5112615 -1.0715005]
[layer18_wq] Token 1 First 3: [1.5928953 1.5802844 7.4785757]
[layer18_wq] Token 1 Last 3: [-6.49684    1.9824594  1.1389275]
[layer18_wq] Token 2 First 3: [-0.41456744  0.05913042  5.105102  ]
[layer18_wq] Token 2 Last 3: [-2.6295211   0.580973   -0.41543913]
--------------------
[layer18_wk] Shape: (1, 3, 256)
[layer18_wk] Token 0 First 3: [ 0.8126559  0.6658052 -0.5832272]
[layer18_wk] Token 0 Last 3: [4.239014   7.963404   0.07296762]
[layer18_wk] Token 1 First 3: [ 1.9287896  -2.1418717   0.43438518]
[layer18_wk] Token 1 Last 3: [1.4755616 4.6271615 2.9174685]
[layer18_wk] Token 2 First 3: [ 0.18064022 -0.76190203  0.09471926]
[layer18_wk] Token 2 Last 3: [-1.917356    4.5317035  -0.15025626]
--------------------
[layer18_wv] Shape: (1, 3, 256)
[layer18_wv] Token 0 First 3: [-3.5290215  3.2277095 -0.6629132]
[layer18_wv] Token 0 Last 3: [-1.0489008  0.5384139  0.6000042]
[layer18_wv] Token 1 First 3: [0.9580288 0.7405197 1.7509483]
[layer18_wv] Token 1 Last 3: [-0.6227201  -0.57951605 -0.55162054]
[layer18_wv] Token 2 First 3: [-0.2503869  -0.17544296  1.1511018 ]
[layer18_wv] Token 2 Last 3: [ 0.61852574  0.06439055 -0.17845419]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-1.1199815  -0.33181366  3.9823768 ]
[RMSNorm(raw)] Last 3: [-2.7677722   0.61151856 -0.4372815 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.70844215 -0.30532423 -1.036862  ]
[RMSNorm(weight)] Last 3: [0.4513839  0.44604492 0.18497476]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.22861716  0.18730499 -0.16407406]
[RMSNorm(raw)] Last 3: [-1.058107    2.5008538  -0.08292002]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.16107094 -0.39096642 -0.7638225 ]
[RMSNorm(weight)] Last 3: [1.0316675  0.449744   0.90952134]
--------------------
[layer18_q_norm_out] Shape: (1, 3, 768)
[layer18_q_norm_out] Token 0 First 3: [-1.9134237  -0.23050292 -0.14679843]
[layer18_q_norm_out] Token 0 Last 3: [-4.3667865   1.5002946  -0.52457106]
[layer18_q_norm_out] Token 1 First 3: [ 1.0677593   0.43072814 -0.10816427]
[layer18_q_norm_out] Token 1 Last 3: [-4.1774583   1.2700294   0.59790593]
[layer18_q_norm_out] Token 2 First 3: [-0.6184597   0.03586815 -0.1643234 ]
[layer18_q_norm_out] Token 2 Last 3: [-4.0171      0.8842833  -0.51816756]
--------------------
[layer18_k_norm_out] Shape: (1, 3, 256)
[layer18_k_norm_out] Token 0 First 3: [ 0.26544073  0.11407503 -0.0387506 ]
[layer18_k_norm_out] Token 0 Last 3: [2.4228115  3.247822   0.03919736]
[layer18_k_norm_out] Token 1 First 3: [ 0.8274816  -0.48200265  0.03790777]
[layer18_k_norm_out] Token 1 Last 3: [1.1077065 2.4786813 2.058474 ]
[layer18_k_norm_out] Token 2 First 3: [ 0.11574442 -0.25607502  0.01234536]
[layer18_k_norm_out] Token 2 Last 3: [-2.1497216   3.6255977  -0.15833755]
--------------------
[layer18_attention_out_core] Shape: (1, 3, 768)
[layer18_attention_out_core] Token 0 First 3: [-1.6836578   1.5146106   0.35168645]
[layer18_attention_out_core] Token 0 Last 3: [ 0.34089035 -0.00097749 -0.18674578]
[layer18_attention_out_core] Token 1 First 3: [-1.3808734  1.7699095  0.5011687]
[layer18_attention_out_core] Token 1 Last 3: [-0.01191208 -0.00408175 -0.12085974]
[layer18_attention_out_core] Token 2 First 3: [-0.41400215  0.06569004  1.0583175 ]
[layer18_attention_out_core] Token 2 Last 3: [ 0.30323747  0.02882561 -0.1509134 ]
--------------------
[layer18_wo_weight] Shape: (768, 768)
[layer18_wo_weight] First 3: [-0.00911111  0.02140694 -0.00170555]
[layer18_wo_weight] Last 3: [ 0.0029886   0.00912454 -0.01791053]
--------------------
[layer18_attention_out_proj] Shape: (1, 3, 768)
[layer18_attention_out_proj] Token 0 First 3: [ 0.07430665 -0.10289993  0.07126641]
[layer18_attention_out_proj] Token 0 Last 3: [-0.05043631 -0.00905066  0.05691002]
[layer18_attention_out_proj] Token 1 First 3: [ 0.07946466 -0.06092821 -0.00075226]
[layer18_attention_out_proj] Token 1 Last 3: [-0.10765229 -0.04302978  0.06247715]
[layer18_attention_out_proj] Token 2 First 3: [0.14689958 0.03998446 0.2634948 ]
[layer18_attention_out_proj] Token 2 Last 3: [ 0.001273    0.05719183 -0.01553181]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.15959999 -0.22101423  0.15306999]
[RMSNorm(raw)] Token 0 Last 3: [-0.10832992 -0.01943951  0.12223452]
[RMSNorm(raw)] Token 1 First 3: [ 0.1390788  -0.10663637 -0.00131661]
[RMSNorm(raw)] Token 1 Last 3: [-0.18841271 -0.07531059  0.10934731]
[RMSNorm(raw)] Token 2 First 3: [0.90256464 0.2456682  1.6189364 ]
[RMSNorm(raw)] Token 2 Last 3: [ 0.00782143  0.35139188 -0.09542885]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 40.56386  177.76491   71.209496]
[RMSNorm(weight)] Last 3: [ 90.100586  93.67041  163.17604 ]
--------------------
[layer18_ffn_norm] Shape: (1, 3, 768)
[layer18_ffn_norm] Token 0 First 3: [  6.633592 -39.50959   11.053106]
[layer18_ffn_norm] Token 0 Last 3: [-9.868919  -1.8403463 20.067978 ]
[layer18_ffn_norm] Token 1 First 3: [  5.780652   -19.06284     -0.09507161]
[layer18_ffn_norm] Token 1 Last 3: [-17.164509   -7.1296844  17.95221  ]
[layer18_ffn_norm] Token 2 First 3: [ 37.514072  43.916855 116.90258 ]
[layer18_ffn_norm] Token 2 Last 3: [  0.71253717  33.266415   -15.667131  ]
--------------------
[layer18_post_attention_norm] Shape: (1, 3, 768)
[layer18_post_attention_norm] Token 0 First 3: [  6.633592 -39.50959   11.053106]
[layer18_post_attention_norm] Token 0 Last 3: [-9.868919  -1.8403463 20.067978 ]
[layer18_post_attention_norm] Token 1 First 3: [  5.780652   -19.06284     -0.09507161]
[layer18_post_attention_norm] Token 1 Last 3: [-17.164509   -7.1296844  17.95221  ]
[layer18_post_attention_norm] Token 2 First 3: [ 37.514072  43.916855 116.90258 ]
[layer18_post_attention_norm] Token 2 Last 3: [  0.71253717  33.266415   -15.667131  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 1.179166   -0.36358115 -0.47901598]
[RMSNorm(raw)] Token 0 Last 3: [-0.43721023  0.399253   -0.8011958 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.3950219 -1.0479269  0.4595806]
[RMSNorm(raw)] Token 1 Last 3: [ 0.09550502 -0.21288584 -0.791476  ]
[RMSNorm(raw)] Token 2 First 3: [ 0.2607815   0.20114636 -0.02377087]
[RMSNorm(raw)] Token 2 Last 3: [-0.09301938  0.08039658  0.11664652]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.840872   -0.19522035  1.7864804 ]
[RMSNorm(weight)] Last 3: [2.3607156  1.1961608  0.08725069]
--------------------
[layer18pre_ffn_norm] Shape: (1, 3, 768)
[layer18pre_ffn_norm] First 5 values: [4.529025554656982, -0.2926027178764343, -1.3347686529159546, 0.21296341717243195, -0.5532665848731995]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.2507944703102112, -0.20742736756801605, -0.06172636151313782, 0.022627711296081543, -0.03531298041343689]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.03125428408384323, -0.0973237156867981, 0.026857495307922363, 0.2182871699333191, 0.18833786249160767]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.0017127019818872213, -0.002047589747235179, -0.0037347881589084864, -0.0003146969247609377, -0.0016115275211632252]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.10404749 -0.12439209 -0.22689024]
[RMSNorm(raw)] Token 0 Last 3: [0.09582718 0.46360052 0.3138463 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.6741235   0.43002254 -0.1212626 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.21619995 -0.53882927 -0.00885716]
[RMSNorm(raw)] Token 2 First 3: [-0.04964289  0.00823776 -0.1349419 ]
[RMSNorm(raw)] Token 2 Last 3: [ 0.04571923 -0.5184846  -0.79795295]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 58.987274 286.52585  105.40158 ]
[RMSNorm(weight)] Last 3: [135.91234 124.40582 236.99335]
--------------------
[layer18_post_ffn_norm] Shape: (1, 3, 768)
[layer18_post_ffn_norm] Token 0 First 3: [  6.2415257 -35.76594   -24.14148  ]
[layer18_post_ffn_norm] Token 0 Last 3: [13.119924 58.138203 74.69333 ]
[layer18_post_ffn_norm] Token 1 First 3: [ 40.43883  123.64259  -12.902533]
[layer18_post_ffn_norm] Token 1 Last 3: [-29.600441 -67.57233   -2.107944]
[layer18_post_ffn_norm] Token 2 First 3: [ -2.9779418   2.36857   -14.358032 ]
[layer18_post_ffn_norm] Token 2 Last 3: [   6.2595267  -65.02099   -189.90749  ]
--------------------
[layer18_decoder_block_out] Shape: (1, 3, 768)
[layer18_decoder_block_out] Token 0 First 3: [ 384.23096 -152.31429 -177.69322]
[layer18_decoder_block_out] Token 0 Last 3: [-127.03071  186.1214  -182.13528]
[layer18_decoder_block_out] Token 1 First 3: [ 131.61037 -118.2202    93.16923]
[layer18_decoder_block_out] Token 1 Last 3: [  -7.557766 -116.706635 -184.78157 ]
[layer18_decoder_block_out] Token 2 First 3: [225.28168 178.43011 -35.16445]
[layer18_decoder_block_out] Token 2 Last 3: [-75.15947    5.349388 -87.80788 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.70249534 -0.27847853 -0.32487923]
[RMSNorm(raw)] Token 0 Last 3: [-0.2322522   0.3402886  -0.33300072]
[RMSNorm(raw)] Token 1 First 3: [ 0.3975806  -0.35713035  0.28145412]
[RMSNorm(raw)] Token 1 Last 3: [-0.02283119 -0.35255805 -0.558205  ]
[RMSNorm(raw)] Token 2 First 3: [ 0.21328752  0.16893037 -0.03329227]
[RMSNorm(raw)] Token 2 Last 3: [-0.07115792  0.00506458 -0.08313292]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [19.15802    1.5586424  7.8029623]
[RMSNorm(weight)] Last 3: [10.080261   5.2016478  2.6866612]
--------------------
[layer19_attention_norm] Shape: (1, 3, 768)
[layer19_attention_norm] Token 0 First 3: [14.160915  -0.712527  -2.8598995]
[layer19_attention_norm] Token 0 Last 3: [-2.573415   2.1103501 -1.2276609]
[layer19_attention_norm] Token 1 First 3: [ 8.014438  -0.9137688  2.47763  ]
[layer19_attention_norm] Token 1 Last 3: [-0.25297552 -2.1864407  -2.0579128 ]
[layer19_attention_norm] Token 2 First 3: [ 4.299454   0.4322324 -0.2930706]
[layer19_attention_norm] Token 2 Last 3: [-0.7884484   0.03140876 -0.3064829 ]
--------------------
[layer19_attention_norm] Shape: (1, 3, 768)
[layer19_attention_norm] Token 0 First 3: [14.160915  -0.712527  -2.8598995]
[layer19_attention_norm] Token 0 Last 3: [-2.573415   2.1103501 -1.2276609]
[layer19_attention_norm] Token 1 First 3: [ 8.014438  -0.9137688  2.47763  ]
[layer19_attention_norm] Token 1 Last 3: [-0.25297552 -2.1864407  -2.0579128 ]
[layer19_attention_norm] Token 2 First 3: [ 4.299454   0.4322324 -0.2930706]
[layer19_attention_norm] Token 2 Last 3: [-0.7884484   0.03140876 -0.3064829 ]
--------------------
[layer19_wq_weight] Shape: (768, 768)
[layer19_wq_weight] First 3: [-0.01370892  0.01172108 -0.00010845]
[layer19_wq_weight] Last 3: [ 0.00482905 -0.000675    0.00520969]
--------------------
[layer19_wk_weight] Shape: (768, 256)
[layer19_wk_weight] First 3: [0.00554922 0.00176914 0.01002873]
[layer19_wk_weight] Last 3: [ 0.01858493  0.00298501 -0.01419112]
--------------------
[layer19_wv_weight] Shape: (768, 256)
[layer19_wv_weight] First 3: [0.00372817 0.00040711 0.0085875 ]
[layer19_wv_weight] Last 3: [-0.00371776  0.00586323  0.01470996]
--------------------
[layer19_wq] Shape: (1, 3, 768)
[layer19_wq] Token 0 First 3: [ 0.9673833 -0.733907   1.0553243]
[layer19_wq] Token 0 Last 3: [-0.9217547 -0.6949342 -1.5030521]
[layer19_wq] Token 1 First 3: [ 2.6622107 -2.5102553  1.7397691]
[layer19_wq] Token 1 Last 3: [-0.31234425  0.08024722 -2.8441896 ]
[layer19_wq] Token 2 First 3: [ 0.2906366  -0.20967786  0.40994358]
[layer19_wq] Token 2 Last 3: [-0.64869255 -0.66223365 -1.8210301 ]
--------------------
[layer19_wk] Shape: (1, 3, 256)
[layer19_wk] Token 0 First 3: [ 1.5814353  -1.7036374   0.14788271]
[layer19_wk] Token 0 Last 3: [-1.903109    0.31719118 -0.7371165 ]
[layer19_wk] Token 1 First 3: [-0.14657816 -2.3307483  -0.5873952 ]
[layer19_wk] Token 1 Last 3: [-2.3103397  2.5122442  2.5757015]
[layer19_wk] Token 2 First 3: [ 0.09891426 -0.06620525  0.3920842 ]
[layer19_wk] Token 2 Last 3: [-0.891527    0.72328764 -2.9605932 ]
--------------------
[layer19_wv] Shape: (1, 3, 256)
[layer19_wv] Token 0 First 3: [ 0.19206057 -0.79181695 -0.21752933]
[layer19_wv] Token 0 Last 3: [0.20382977 1.2798901  0.43635017]
[layer19_wv] Token 1 First 3: [-0.8522157 -1.4407899 -1.4471827]
[layer19_wv] Token 1 Last 3: [ 1.5830879 -1.10996    0.8121672]
[layer19_wv] Token 2 First 3: [ 0.15487088 -2.5829325   0.55415136]
[layer19_wv] Token 2 Last 3: [ 0.25510016  0.27594972 -0.14657244]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [ 0.8511254 -0.6457077  0.9284979]
[RMSNorm(raw)] Last 3: [-0.67688024 -0.69100976 -1.9001596 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.82630646 -0.08959949  0.09378414]
[RMSNorm(weight)] Last 3: [ 0.21708441  0.21454243 -0.16823736]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.8445574  -0.90981877  0.07897601]
[RMSNorm(raw)] Last 3: [-0.6733546  0.5462864 -2.236084 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.34037745  2.1879792  -1.3269696 ]
[RMSNorm(weight)] Last 3: [0.44357133 0.7104132  0.8359356 ]
--------------------
[layer19_q_norm_out] Shape: (1, 3, 768)
[layer19_q_norm_out] Token 0 First 3: [ 1.5544158  -0.58785266  1.0155762 ]
[layer19_q_norm_out] Token 0 Last 3: [-1.1643294 -0.8759839 -1.2975175]
[layer19_q_norm_out] Token 1 First 3: [ 3.4505668 -1.6219026  1.3505093]
[layer19_q_norm_out] Token 1 Last 3: [-0.25747     0.06601082 -1.6022505 ]
[layer19_q_norm_out] Token 2 First 3: [ 0.68416584 -0.24604951  0.5779538 ]
[layer19_q_norm_out] Token 2 Last 3: [-0.8238204  -0.83926064 -1.5804818 ]
--------------------
[layer19_k_norm_out] Shape: (1, 3, 256)
[layer19_k_norm_out] Token 0 First 3: [ 1.1320257  -2.9004834  -0.02582275]
[layer19_k_norm_out] Token 0 Last 3: [-1.4671673   0.2897343  -0.72272205]
[layer19_k_norm_out] Token 1 First 3: [-0.08861421 -3.351335    0.0866253 ]
[layer19_k_norm_out] Token 1 Last 3: [-1.5042537  1.938072   2.1328483]
[layer19_k_norm_out] Token 2 First 3: [ 0.10013719 -0.15941063 -0.09682692]
[layer19_k_norm_out] Token 2 Last 3: [-0.9720354   0.93437546 -4.105306  ]
--------------------
[layer19_attention_out_core] Shape: (1, 3, 768)
[layer19_attention_out_core] Token 0 First 3: [ 0.15413263 -1.1832536  -0.09251601]
[layer19_attention_out_core] Token 0 Last 3: [ 0.9189729  -0.30743262  0.4040981 ]
[layer19_attention_out_core] Token 1 First 3: [ 0.11848403 -1.1937933  -0.13984978]
[layer19_attention_out_core] Token 1 Last 3: [ 1.385734  -0.8986787  0.6731575]
[layer19_attention_out_core] Token 2 First 3: [ 0.0911003  -1.2582047  -0.15023494]
[layer19_attention_out_core] Token 2 Last 3: [ 0.30190784  0.31176183 -0.05755781]
--------------------
[layer19_wo_weight] Shape: (768, 768)
[layer19_wo_weight] First 3: [ 0.00792203 -0.00710257  0.00048166]
[layer19_wo_weight] Last 3: [0.00841813 0.00688555 0.01122191]
--------------------
[layer19_attention_out_proj] Shape: (1, 3, 768)
[layer19_attention_out_proj] Token 0 First 3: [-0.14046621  0.20228146  0.03329007]
[layer19_attention_out_proj] Token 0 Last 3: [-0.03947163  0.19491304  0.23991674]
[layer19_attention_out_proj] Token 1 First 3: [-0.12458949  0.2022002  -0.01321887]
[layer19_attention_out_proj] Token 1 Last 3: [-0.05073652  0.27183908  0.2709024 ]
[layer19_attention_out_proj] Token 2 First 3: [-0.20989001  0.09209088  0.03168915]
[layer19_attention_out_proj] Token 2 Last 3: [-0.03966963  0.17288667  0.09688738]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.7996412   1.1515409   0.18951255]
[RMSNorm(raw)] Token 0 Last 3: [-0.22470275  1.1095942   1.3657897 ]
[RMSNorm(raw)] Token 1 First 3: [-0.56430936  0.91583544 -0.0598729 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.22980343  1.2312543   1.2270117 ]
[RMSNorm(raw)] Token 2 First 3: [-0.8961886   0.39320976  0.13530637]
[RMSNorm(raw)] Token 2 Last 3: [-0.16938141  0.7381917   0.41368985]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 37.827003 202.164    100.94521 ]
[RMSNorm(weight)] Last 3: [ 46.10025  74.07974 150.01508]
--------------------
[layer19_ffn_norm] Shape: (1, 3, 768)
[layer19_ffn_norm] Token 0 First 3: [-31.047672 233.95164   19.319897]
[layer19_ffn_norm] Token 0 Last 3: [-10.583555  83.30805  206.25482 ]
[layer19_ffn_norm] Token 1 First 3: [-21.910442 186.06479   -6.103755]
[layer19_ffn_norm] Token 1 Last 3: [-10.823799  92.44226  185.29726 ]
[layer19_ffn_norm] Token 2 First 3: [-34.796318  79.88607   13.793838]
[layer19_ffn_norm] Token 2 Last 3: [-7.9779067 55.423244  62.473404 ]
--------------------
[layer19_post_attention_norm] Shape: (1, 3, 768)
[layer19_post_attention_norm] Token 0 First 3: [-31.047672 233.95164   19.319897]
[layer19_post_attention_norm] Token 0 Last 3: [-10.583555  83.30805  206.25482 ]
[layer19_post_attention_norm] Token 1 First 3: [-21.910442 186.06479   -6.103755]
[layer19_post_attention_norm] Token 1 Last 3: [-10.823799  92.44226  185.29726 ]
[layer19_post_attention_norm] Token 2 First 3: [-34.796318  79.88607   13.793838]
[layer19_post_attention_norm] Token 2 Last 3: [-7.9779067 55.423244  62.473404 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.70932937  0.16395955 -0.3180752 ]
[RMSNorm(raw)] Token 0 Last 3: [-0.27638292  0.54111904  0.04844141]
[RMSNorm(raw)] Token 1 First 3: [0.33476457 0.2070372  0.2656924 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.0560939  -0.07404611  0.00157369]
[RMSNorm(raw)] Token 2 First 3: [ 0.19607668  0.26589856 -0.0219979 ]
[RMSNorm(raw)] Token 2 Last 3: [-0.0855777   0.06255649 -0.02607812]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.9934881 -0.3211005  1.2296655]
[RMSNorm(weight)] Last 3: [ 1.8168049   0.7242998  -0.06967454]
--------------------
[layer19pre_ffn_norm] Shape: (1, 3, 768)
[layer19pre_ffn_norm] First 5 values: [2.123368978500366, 0.11131206154823303, -0.7092013359069824, 0.26088476181030273, -0.009637878276407719]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.0649341493844986, -0.0980147272348404, 0.1994689404964447, -0.04619999974966049, -0.185452401638031]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.08254067599773407, -0.03921135514974594, 0.07523462176322937, -0.04967895895242691, 0.07276424020528793]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-0.002153795910999179, -0.0008562167058698833, 0.004671384580433369, 0.0027162607293576, 0.0043287682346999645]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.23958018 -0.09524234  0.51962733]
[RMSNorm(raw)] Token 0 Last 3: [-0.06071986 -0.06386267 -0.05862664]
[RMSNorm(raw)] Token 1 First 3: [-0.3826512  -0.09850408  0.7210335 ]
[RMSNorm(raw)] Token 1 Last 3: [ 0.1384596  -0.0175446  -0.14381333]
[RMSNorm(raw)] Token 2 First 3: [0.04451871 0.35525653 0.47997755]
[RMSNorm(raw)] Token 2 Last 3: [ 0.7866249  -0.04410965 -0.73236686]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 69.924286 355.27313  117.79923 ]
[RMSNorm(weight)] Last 3: [ 83.721466 140.03055  265.70892 ]
--------------------
[layer19_post_ffn_norm] Shape: (1, 3, 768)
[layer19_post_ffn_norm] Token 0 First 3: [-16.992054 -33.932285  61.731327]
[layer19_post_ffn_norm] Token 0 Last 3: [ -5.1442757  -9.006588  -15.63625  ]
[layer19_post_ffn_norm] Token 1 First 3: [-27.139263 -35.094357  85.658226]
[layer19_post_ffn_norm] Token 1 Last 3: [ 11.730499  -2.474325 -38.356297]
[layer19_post_ffn_norm] Token 2 First 3: [  3.1574578 126.56836    57.020966 ]
[layer19_post_ffn_norm] Token 2 Last 3: [  66.64401    -6.220808 -195.32878 ]
--------------------
[layer19_decoder_block_out] Shape: (1, 3, 768)
[layer19_decoder_block_out] Token 0 First 3: [336.19122   47.705074 -96.642   ]
[layer19_decoder_block_out] Token 0 Last 3: [-142.75853   260.42285     8.483288]
[layer19_decoder_block_out] Token 1 First 3: [ 82.56065   32.750233 172.7237  ]
[layer19_decoder_block_out] Token 1 Last 3: [ -6.651066 -26.738699 -37.84061 ]
[layer19_decoder_block_out] Token 2 First 3: [193.6428   384.88455   35.650352]
[layer19_decoder_block_out] Token 2 Last 3: [ -16.493362   54.551826 -220.66325 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.5759854   0.08173154 -0.16557357]
[RMSNorm(raw)] Token 0 Last 3: [-0.2445835   0.44617394  0.01453414]
[RMSNorm(raw)] Token 1 First 3: [0.20615554 0.08177796 0.43129438]
[RMSNorm(raw)] Token 1 Last 3: [-0.01660784 -0.06676704 -0.09448873]
[RMSNorm(raw)] Token 2 First 3: [0.18719149 0.3720619  0.03446264]
[RMSNorm(raw)] Token 2 Last 3: [-0.01594388  0.0527344  -0.21331173]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [26.267141  3.677062 11.897902]
[RMSNorm(weight)] Last 3: [16.373379 11.050137  5.60744 ]
--------------------
[layer20_attention_norm] Shape: (1, 3, 768)
[layer20_attention_norm] Token 0 First 3: [15.705475    0.38226345 -2.1355515 ]
[layer20_attention_norm] Token 0 Last 3: [-4.249242    5.3764567   0.09603345]
[layer20_attention_norm] Token 1 First 3: [5.621272  0.3824806 5.5627923]
[layer20_attention_norm] Token 1 Last 3: [-0.28853428 -0.804552   -0.6243286 ]
[layer20_attention_norm] Token 2 First 3: [5.1041765  1.7401567  0.44449577]
[layer20_attention_norm] Token 2 Last 3: [-0.27699903  0.63545674 -1.4094445 ]
--------------------
[layer20_attention_norm] Shape: (1, 3, 768)
[layer20_attention_norm] Token 0 First 3: [15.705475    0.38226345 -2.1355515 ]
[layer20_attention_norm] Token 0 Last 3: [-4.249242    5.3764567   0.09603345]
[layer20_attention_norm] Token 1 First 3: [5.621272  0.3824806 5.5627923]
[layer20_attention_norm] Token 1 Last 3: [-0.28853428 -0.804552   -0.6243286 ]
[layer20_attention_norm] Token 2 First 3: [5.1041765  1.7401567  0.44449577]
[layer20_attention_norm] Token 2 Last 3: [-0.27699903  0.63545674 -1.4094445 ]
--------------------
[layer20_wq_weight] Shape: (768, 768)
[layer20_wq_weight] First 3: [ 0.00537252 -0.0076702   0.0188872 ]
[layer20_wq_weight] Last 3: [0.0031123  0.0112827  0.00410936]
--------------------
[layer20_wk_weight] Shape: (768, 256)
[layer20_wk_weight] First 3: [-0.0095862   0.00192273  0.01168069]
[layer20_wk_weight] Last 3: [ 0.00679196 -0.00643631  0.01144467]
--------------------
[layer20_wv_weight] Shape: (768, 256)
[layer20_wv_weight] First 3: [-0.00054885  0.00021523  0.00588722]
[layer20_wv_weight] Last 3: [-0.00567457  0.00434222 -0.01124263]
--------------------
[layer20_wq] Shape: (1, 3, 768)
[layer20_wq] Token 0 First 3: [-1.2469292 -0.7237126 -1.3804164]
[layer20_wq] Token 0 Last 3: [ 1.6838254  -2.0550175  -0.58224607]
[layer20_wq] Token 1 First 3: [-3.4226217 -5.3962636  4.1855497]
[layer20_wq] Token 1 Last 3: [ 2.5240262  -0.87806726  0.97507316]
[layer20_wq] Token 2 First 3: [-0.8602497  -0.47968176 -0.08465129]
[layer20_wq] Token 2 Last 3: [ 0.9455406  -0.85126436  1.3178593 ]
--------------------
[layer20_wk] Shape: (1, 3, 256)
[layer20_wk] Token 0 First 3: [-1.9557936  0.6142071  0.877946 ]
[layer20_wk] Token 0 Last 3: [ 6.2692466 -4.9474764  3.256005 ]
[layer20_wk] Token 1 First 3: [-2.2003963 -2.8607354  1.6430596]
[layer20_wk] Token 1 Last 3: [ 6.995719 -5.06111   4.746641]
[layer20_wk] Token 2 First 3: [-0.60561657 -0.58580834  0.5893411 ]
[layer20_wk] Token 2 Last 3: [ 4.8232594 -4.377595   2.2222872]
--------------------
[layer20_wv] Shape: (1, 3, 256)
[layer20_wv] Token 0 First 3: [ 0.57610524  0.7016928  -0.6881095 ]
[layer20_wv] Token 0 Last 3: [-0.12823276 -2.2267714   0.99528515]
[layer20_wv] Token 1 First 3: [-0.4261197  -2.669892   -0.69913906]
[layer20_wv] Token 1 Last 3: [-0.9766886 -0.6378468 -1.8184447]
[layer20_wv] Token 2 First 3: [-0.37489617 -0.31043017 -0.04328991]
[layer20_wv] Token 2 Last 3: [-0.23333451  1.247051    0.19881964]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.44307393 -0.2571583  -0.49050623]
[RMSNorm(raw)] Last 3: [ 0.42104253 -0.379062    0.5868334 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.209554   0.09367584 0.33890516]
[RMSNorm(weight)] Last 3: [-0.06012288  0.27688462  0.22026294]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.6886223   0.21625835  0.30911914]
[RMSNorm(raw)] Last 3: [ 2.061642  -1.8711483  0.9498889]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.22093116 1.7380621  0.18617955]
[RMSNorm(weight)] Last 3: [1.6237683 0.817338  0.9974488]
--------------------
[layer20_q_norm_out] Shape: (1, 3, 768)
[layer20_q_norm_out] Token 0 First 3: [-0.5359218  -0.28124782 -0.6567413 ]
[layer20_q_norm_out] Token 0 Last 3: [ 0.47013718 -0.7795134  -0.2110651 ]
[layer20_q_norm_out] Token 1 First 3: [-2.0122669 -2.8686874  2.723979 ]
[layer20_q_norm_out] Token 1 Last 3: [ 0.7619895  -0.36013347  0.38218594]
[layer20_q_norm_out] Token 2 First 3: [-0.4970166  -0.25058955 -0.05413828]
[layer20_q_norm_out] Token 2 Last 3: [ 0.39572826 -0.48401842  0.7160911 ]
--------------------
[layer20_k_norm_out] Shape: (1, 3, 256)
[layer20_k_norm_out] Token 0 First 3: [-0.8407604  0.5921288  0.3666708]
[layer20_k_norm_out] Token 0 Last 3: [ 5.7916045 -3.1657565  2.289912 ]
[layer20_k_norm_out] Token 1 First 3: [-0.9019508 -2.6297336  0.6543265]
[layer20_k_norm_out] Token 1 Last 3: [ 6.1623816 -3.087964   3.1831186]
[layer20_k_norm_out] Token 2 First 3: [-0.3160542  -0.68560106  0.2988063 ]
[layer20_k_norm_out] Token 2 Last 3: [ 5.409271  -3.4005089  1.8973544]
--------------------
[layer20_attention_out_core] Shape: (1, 3, 768)
[layer20_attention_out_core] Token 0 First 3: [-0.11660429 -1.0419894  -0.5199641 ]
[layer20_attention_out_core] Token 0 Last 3: [-3.5489309e-01 -1.8225120e-02 -2.4396041e-04]
[layer20_attention_out_core] Token 1 First 3: [-0.2505471  -2.0026195  -0.67424816]
[layer20_attention_out_core] Token 1 Last 3: [-0.33636424 -0.01531741  0.05606283]
[layer20_attention_out_core] Token 2 First 3: [-0.2876599  -1.2739531  -0.41893575]
[layer20_attention_out_core] Token 2 Last 3: [-0.35699892 -0.65142095  0.0798601 ]
--------------------
[layer20_wo_weight] Shape: (768, 768)
[layer20_wo_weight] First 3: [-0.00226221 -0.00604948 -0.00714985]
[layer20_wo_weight] Last 3: [ 0.00111354 -0.01273769  0.00859827]
--------------------
[layer20_attention_out_proj] Shape: (1, 3, 768)
[layer20_attention_out_proj] Token 0 First 3: [0.12149796 0.2205335  0.137319  ]
[layer20_attention_out_proj] Token 0 Last 3: [0.05466928 0.09485672 0.11296213]
[layer20_attention_out_proj] Token 1 First 3: [0.17790958 0.08240897 0.02561201]
[layer20_attention_out_proj] Token 1 Last 3: [0.18731344 0.04744454 0.02007806]
[layer20_attention_out_proj] Token 2 First 3: [0.09930757 0.2739651  0.08624642]
[layer20_attention_out_proj] Token 2 Last 3: [0.11724538 0.00780102 0.11088219]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.298685   0.5421495  0.33757874]
[RMSNorm(raw)] Token 0 Last 3: [0.13439645 0.23319142 0.27770093]
[RMSNorm(raw)] Token 1 First 3: [0.35696808 0.16535012 0.05138942]
[RMSNorm(raw)] Token 1 Last 3: [0.37583652 0.09519548 0.04028578]
[RMSNorm(raw)] Token 2 First 3: [0.30536523 0.8424274  0.2652029 ]
[RMSNorm(raw)] Token 2 Last 3: [0.360523   0.02398771 0.34095654]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 41.59246 233.1387   96.00752]
[RMSNorm(weight)] Last 3: [ 44.94208  93.65396 168.46146]
--------------------
[layer20_ffn_norm] Shape: (1, 3, 768)
[layer20_ffn_norm] Token 0 First 3: [ 12.721729 126.93818   32.747677]
[layer20_ffn_norm] Token 0 Last 3: [ 6.174453 22.07249  47.059605]
[layer20_ffn_norm] Token 1 First 3: [15.204148  38.714863   4.9851604]
[layer20_ffn_norm] Token 1 Last 3: [17.266712   9.01063    6.8268876]
[layer20_ffn_norm] Token 2 First 3: [ 13.006257 197.24486   25.726677]
[layer20_ffn_norm] Token 2 Last 3: [16.563177   2.2705317 57.77899  ]
--------------------
[layer20_post_attention_norm] Shape: (1, 3, 768)
[layer20_post_attention_norm] Token 0 First 3: [ 12.721729 126.93818   32.747677]
[layer20_post_attention_norm] Token 0 Last 3: [ 6.174453 22.07249  47.059605]
[layer20_post_attention_norm] Token 1 First 3: [15.204148  38.714863   4.9851604]
[layer20_post_attention_norm] Token 1 Last 3: [17.266712   9.01063    6.8268876]
[layer20_post_attention_norm] Token 2 First 3: [ 13.006257 197.24486   25.726677]
[layer20_post_attention_norm] Token 2 Last 3: [16.563177   2.2705317 57.77899  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.58260506  0.29161438 -0.10668894]
[RMSNorm(raw)] Token 0 Last 3: [-0.22806424  0.47170275  0.09274396]
[RMSNorm(raw)] Token 1 First 3: [0.22447366 0.16408801 0.40802982]
[RMSNorm(raw)] Token 1 Last 3: [ 0.02437414 -0.04070468 -0.0712093 ]
[RMSNorm(raw)] Token 2 First 3: [0.19712971 0.5553134  0.05854968]
[RMSNorm(raw)] Token 2 Last 3: [ 6.6598644e-05  5.4204818e-02 -1.5538095e-01]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.161914  -0.5200888  0.5859457]
[RMSNorm(weight)] Last 3: [ 1.1635602   0.18831004 -0.28844598]
--------------------
[layer20pre_ffn_norm] Shape: (1, 3, 768)
[layer20pre_ffn_norm] First 5 values: [1.2595419883728027, 0.1399490088224411, -0.16920286417007446, 0.478791207075119, 0.320618212223053]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.07588128745555878, -0.05889439582824707, 0.01043154951184988, -0.05512400344014168, -0.09202323853969574]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [0.015523657202720642, 0.09066285938024521, -0.03222488984465599, -0.010450415313243866, 0.006519787013530731]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [0.0007778970757499337, 0.001343764248304069, 0.001674665603786707, 0.0002935705706477165, -0.0019260477274656296]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [0.17454277 0.30151075 0.37575763]
[RMSNorm(raw)] Token 0 Last 3: [ 0.15069465 -0.132886   -0.36942774]
[RMSNorm(raw)] Token 1 First 3: [ 0.2912663  -0.35382983  0.31803393]
[RMSNorm(raw)] Token 1 Last 3: [ 0.5298234  -0.3502638  -0.00743479]
[RMSNorm(raw)] Token 2 First 3: [ 0.05773595  0.30989814 -0.16797028]
[RMSNorm(raw)] Token 2 Last 3: [-0.08911563 -0.07039282 -0.29280043]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 75.6014   470.43097  123.570465]
[RMSNorm(weight)] Last 3: [ 95.69098 150.05023 319.73267]
--------------------
[layer20_post_ffn_norm] Shape: (1, 3, 768)
[layer20_post_ffn_norm] Token 0 First 3: [ 13.370221 142.14151   46.808304]
[layer20_post_ffn_norm] Token 0 Last 3: [  14.570813  -20.072462 -118.48754 ]
[layer20_post_ffn_norm] Token 1 First 3: [  22.311407 -166.80634    39.617634]
[layer20_post_ffn_norm] Token 1 Last 3: [ 51.229145  -52.90743    -2.3845813]
[layer20_post_ffn_norm] Token 2 First 3: [  4.422655 146.09558  -20.924137]
[layer20_post_ffn_norm] Token 2 Last 3: [ -8.616678 -10.632852 -93.91066 ]
--------------------
[layer20_decoder_block_out] Shape: (1, 3, 768)
[layer20_decoder_block_out] Token 0 First 3: [362.28317  316.78476  -17.086018]
[layer20_decoder_block_out] Token 0 Last 3: [-122.01326  262.42288  -62.94465]
[layer20_decoder_block_out] Token 1 First 3: [120.07621 -95.34124 217.32648]
[layer20_decoder_block_out] Token 1 Last 3: [ 61.84479  -70.6355   -33.398304]
[layer20_decoder_block_out] Token 2 First 3: [211.07172  728.225     40.452892]
[layer20_decoder_block_out] Token 2 Last 3: [  -8.546864   46.189507 -256.79492 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.48255602  0.42195275 -0.02275833]
[RMSNorm(raw)] Token 0 Last 3: [-0.16251992  0.3495435  -0.08384137]
[RMSNorm(raw)] Token 1 First 3: [ 0.22566515 -0.1791795   0.40843236]
[RMSNorm(raw)] Token 1 Last 3: [ 0.11622797 -0.13274878 -0.06276708]
[RMSNorm(raw)] Token 2 First 3: [0.20109592 0.6938072  0.03854099]
[RMSNorm(raw)] Token 2 Last 3: [-0.00814292  0.04400647 -0.24465813]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [32.571526   3.2804701 13.30518  ]
[RMSNorm(weight)] Last 3: [23.126152  12.510199   6.2626505]
--------------------
[layer21_attention_norm] Shape: (1, 3, 768)
[layer21_attention_norm] Token 0 First 3: [16.200142  1.806156 -0.325562]
[layer21_attention_norm] Token 0 Last 3: [-3.9209802   4.722402   -0.60891056]
[layer21_attention_norm] Token 1 First 3: [ 7.5759234 -0.7669725  5.842698 ]
[layer21_attention_norm] Token 1 Last 3: [ 2.8041337  -1.7934624  -0.45585537]
[layer21_attention_norm] Token 2 First 3: [6.7510967 2.9698207 0.5513357]
[layer21_attention_norm] Token 2 Last 3: [-0.19645724  0.5945362  -1.7768664 ]
--------------------
[layer21_attention_norm] Shape: (1, 3, 768)
[layer21_attention_norm] Token 0 First 3: [16.200142  1.806156 -0.325562]
[layer21_attention_norm] Token 0 Last 3: [-3.9209802   4.722402   -0.60891056]
[layer21_attention_norm] Token 1 First 3: [ 7.5759234 -0.7669725  5.842698 ]
[layer21_attention_norm] Token 1 Last 3: [ 2.8041337  -1.7934624  -0.45585537]
[layer21_attention_norm] Token 2 First 3: [6.7510967 2.9698207 0.5513357]
[layer21_attention_norm] Token 2 Last 3: [-0.19645724  0.5945362  -1.7768664 ]
--------------------
[layer21_wq_weight] Shape: (768, 768)
[layer21_wq_weight] First 3: [-0.00775846  0.00723398  0.0048095 ]
[layer21_wq_weight] Last 3: [-0.00427708 -0.01222241  0.00126034]
--------------------
[layer21_wk_weight] Shape: (768, 256)
[layer21_wk_weight] First 3: [ 0.00520477 -0.01356536 -0.00043532]
[layer21_wk_weight] Last 3: [-0.00621499 -0.00371427 -0.00448637]
--------------------
[layer21_wv_weight] Shape: (768, 256)
[layer21_wv_weight] First 3: [ 0.00502245 -0.00625391 -0.00110819]
[layer21_wv_weight] Last 3: [-0.00070433 -0.00915811  0.00309912]
--------------------
[layer21_wq] Shape: (1, 3, 768)
[layer21_wq] Token 0 First 3: [-0.12578255 -0.4446342   0.06384146]
[layer21_wq] Token 0 Last 3: [ 1.2995508  -6.5283923  -0.95083404]
[layer21_wq] Token 1 First 3: [-0.58998805 -0.02266872  0.15927023]
[layer21_wq] Token 1 Last 3: [ 2.4872823 -6.450312  -1.7926251]
[layer21_wq] Token 2 First 3: [ 0.12726793 -0.44883695 -1.0357552 ]
[layer21_wq] Token 2 Last 3: [ 0.88842213 -4.2567525  -1.31304   ]
--------------------
[layer21_wk] Shape: (1, 3, 256)
[layer21_wk] Token 0 First 3: [-0.8982872  -0.69767964  0.08806272]
[layer21_wk] Token 0 Last 3: [ 0.71909535  1.1623063  -7.7260046 ]
[layer21_wk] Token 1 First 3: [-2.0842853 -1.3943328  1.0243591]
[layer21_wk] Token 1 Last 3: [ 1.6172934  0.0408628 -7.093998 ]
[layer21_wk] Token 2 First 3: [-0.23367772 -0.51799124  0.6973399 ]
[layer21_wk] Token 2 Last 3: [-0.1200949 -4.513333  -9.753326 ]
--------------------
[layer21_wv] Shape: (1, 3, 256)
[layer21_wv] Token 0 First 3: [ 0.22790954  0.12656626 -0.8302737 ]
[layer21_wv] Token 0 Last 3: [ 1.242168   -0.05191283 -0.8251142 ]
[layer21_wv] Token 1 First 3: [-1.5904137  -1.7331468  -0.86567557]
[layer21_wv] Token 1 Last 3: [-0.28725585  1.7621473  -0.54270077]
[layer21_wv] Token 2 First 3: [-1.2311184   0.33525866 -1.7818289 ]
[layer21_wv] Token 2 Last 3: [-0.37044016 -1.3070612  -0.41576475]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.04202117 -0.14854245  0.02132802]
[RMSNorm(raw)] Last 3: [ 0.32150948 -1.5404685  -0.47517368]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.96863604 0.27434042 0.35380924]
[RMSNorm(weight)] Last 3: [ 0.16472556 -0.34528124 -0.2558578 ]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.27305138 -0.21207292  0.02676833]
[RMSNorm(raw)] Last 3: [-0.02432516 -0.9141733  -1.9755315 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [ 0.02933722 -0.3351266  -0.42429316]
[RMSNorm(weight)] Last 3: [0.4791265 2.3389845 1.0179024]
--------------------
[layer21_q_norm_out] Shape: (1, 3, 768)
[layer21_q_norm_out] Token 0 First 3: [-0.08272438 -0.18929364  0.02887407]
[layer21_q_norm_out] Token 0 Last 3: [ 0.42374888 -1.1966103  -0.19808532]
[layer21_q_norm_out] Token 1 First 3: [-0.48775312 -0.0121312   0.09054897]
[layer21_q_norm_out] Token 1 Last 3: [ 0.907431   -1.3228191  -0.41784027]
[layer21_q_norm_out] Token 2 First 3: [ 0.10170862 -0.2321921  -0.5692302 ]
[layer21_q_norm_out] Token 2 Last 3: [ 0.3744703  -1.0085735  -0.35359678]
--------------------
[layer21_k_norm_out] Shape: (1, 3, 256)
[layer21_k_norm_out] Token 0 First 3: [-0.28106195 -0.14100164  0.01541071]
[layer21_k_norm_out] Token 0 Last 3: [ 0.32331136  1.1796799  -4.7389736 ]
[layer21_k_norm_out] Token 1 First 3: [-0.7753143  -0.33501816  0.21311626]
[layer21_k_norm_out] Token 1 Last 3: [ 0.8644843   0.04930665 -5.1731396 ]
[layer21_k_norm_out] Token 2 First 3: [-0.04871987 -0.06975776  0.0813162 ]
[layer21_k_norm_out] Token 2 Last 3: [-0.03597999 -3.0524106  -3.9864297 ]
--------------------
[layer21_attention_out_core] Shape: (1, 3, 768)
[layer21_attention_out_core] Token 0 First 3: [-1.0853612 -0.3532223 -1.3244233]
[layer21_attention_out_core] Token 0 Last 3: [ 0.37971613 -0.28766447 -0.62152636]
[layer21_attention_out_core] Token 1 First 3: [-0.61048347  0.12938476 -1.313506  ]
[layer21_attention_out_core] Token 1 Last 3: [ 0.04936966  0.24755265 -0.56557715]
[layer21_attention_out_core] Token 2 First 3: [-1.1051444  -0.18209316 -1.4286671 ]
[layer21_attention_out_core] Token 2 Last 3: [ 0.33285853  0.04638969 -0.6226821 ]
--------------------
[layer21_wo_weight] Shape: (768, 768)
[layer21_wo_weight] First 3: [-0.00692657 -0.00277807  0.01221741]
[layer21_wo_weight] Last 3: [ 0.01020437 -0.00652761  0.00804057]
--------------------
[layer21_attention_out_proj] Shape: (1, 3, 768)
[layer21_attention_out_proj] Token 0 First 3: [ 0.00180825  0.16457921 -0.00531016]
[layer21_attention_out_proj] Token 0 Last 3: [0.16606657 0.05738797 0.22367951]
[layer21_attention_out_proj] Token 1 First 3: [-0.04403924  0.03444718 -0.07451493]
[layer21_attention_out_proj] Token 1 Last 3: [ 0.19110696 -0.04908635  0.29620498]
[layer21_attention_out_proj] Token 2 First 3: [ 0.08840318  0.17627622 -0.00920619]
[layer21_attention_out_proj] Token 2 Last 3: [0.2390601  0.03348299 0.17440122]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.00238302  0.216892   -0.00699803]
[RMSNorm(raw)] Token 0 Last 3: [0.21885213 0.07562919 0.2947778 ]
[RMSNorm(raw)] Token 1 First 3: [-0.05478088  0.04284922 -0.09268991]
[RMSNorm(raw)] Token 1 Last 3: [ 0.23771998 -0.06105904  0.36845255]
[RMSNorm(raw)] Token 2 First 3: [ 0.12480269  0.24885696 -0.01299679]
[RMSNorm(raw)] Token 2 Last 3: [0.33749175 0.04726942 0.24620995]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 80.39817 358.19128 124.2218 ]
[RMSNorm(weight)] Last 3: [ 74.48212 152.52277 277.75674]
--------------------
[layer21_ffn_norm] Shape: (1, 3, 768)
[layer21_ffn_norm] Token 0 First 3: [ 0.1939734  77.905716   -0.87630594]
[layer21_ffn_norm] Token 0 Last 3: [16.519423 11.610803 82.1713  ]
[layer21_ffn_norm] Token 1 First 3: [ -4.4590635  15.391066  -11.606797 ]
[layer21_ffn_norm] Token 1 Last 3: [ 17.943607  -9.373953 102.70863 ]
[layer21_ffn_norm] Token 2 First 3: [10.1587105 89.38725   -1.6274812]
[layer21_ffn_norm] Token 2 Last 3: [25.474592   7.2569327 68.63268  ]
--------------------
[layer21_post_attention_norm] Shape: (1, 3, 768)
[layer21_post_attention_norm] Token 0 First 3: [ 0.1939734  77.905716   -0.87630594]
[layer21_post_attention_norm] Token 0 Last 3: [16.519423 11.610803 82.1713  ]
[layer21_post_attention_norm] Token 1 First 3: [ -4.4590635  15.391066  -11.606797 ]
[layer21_post_attention_norm] Token 1 Last 3: [ 17.943607  -9.373953 102.70863 ]
[layer21_post_attention_norm] Token 2 First 3: [10.1587105 89.38725   -1.6274812]
[layer21_post_attention_norm] Token 2 Last 3: [25.474592   7.2569327 68.63268  ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.47451615  0.5166864  -0.02351435]
[RMSNorm(raw)] Token 0 Last 3: [-0.1381012   0.35873547  0.02516947]
[RMSNorm(raw)] Token 1 First 3: [ 0.21286596 -0.1471985   0.37875623]
[RMSNorm(raw)] Token 1 Last 3: [ 0.14690064 -0.14730763  0.1276092 ]
[RMSNorm(raw)] Token 2 First 3: [0.20671317 0.76396006 0.03627767]
[RMSNorm(raw)] Token 2 Last 3: [ 0.01581692  0.04993925 -0.17581493]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 1.4397142  -0.54010946  0.58100027]
[RMSNorm(weight)] Last 3: [ 1.450721    0.21045631 -0.30723888]
--------------------
[layer21pre_ffn_norm] Shape: (1, 3, 768)
[layer21pre_ffn_norm] First 5 values: [1.1576838493347168, 0.23761917650699615, -0.037176188081502914, 0.3938247561454773, 0.21381114423274994]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.07610814273357391, -0.08249928802251816, -0.2042287439107895, 0.3213707208633423, 0.04018581658601761]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.019836479797959328, -0.061977893114089966, -0.12398272752761841, 0.038541655987501144, 0.04492095112800598]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-0.0006610194686800241, -0.00036404593265615404, -0.0012217267649248242, 0.0033167931251227856, -0.000867419526912272]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.1745946  -0.09615519 -0.3226938 ]
[RMSNorm(raw)] Token 0 Last 3: [ 0.59869343 -0.18433556  0.25294173]
[RMSNorm(raw)] Token 1 First 3: [ 0.02824491  0.48935395 -0.04449266]
[RMSNorm(raw)] Token 1 Last 3: [ 0.192205   -0.53647536 -0.45599705]
[RMSNorm(raw)] Token 2 First 3: [-0.7520076   0.53534496  0.57792336]
[RMSNorm(raw)] Token 2 Last 3: [-0.35335776  0.42748135  0.5142606 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [102.532486 537.2504   140.19856 ]
[RMSNorm(weight)] Last 3: [134.67728 180.09346 371.66437]
--------------------
[layer21_post_ffn_norm] Shape: (1, 3, 768)
[layer21_post_ffn_norm] Token 0 First 3: [-18.076212 -51.755573 -45.5639  ]
[layer21_post_ffn_norm] Token 0 Last 3: [ 81.229095 -33.381966  94.26237 ]
[layer21_post_ffn_norm] Token 1 First 3: [  2.9242654 263.395      -6.2823   ]
[layer21_post_ffn_norm] Token 1 Last 3: [  26.07785   -97.152176 -169.93385 ]
[layer21_post_ffn_norm] Token 2 First 3: [-77.857216 288.14966   81.601944]
[layer21_post_ffn_norm] Token 2 Last 3: [-47.94262  77.41408 191.64659]
--------------------
[layer21_decoder_block_out] Shape: (1, 3, 768)
[layer21_decoder_block_out] Token 0 First 3: [344.40094  342.9349   -63.526222]
[layer21_decoder_block_out] Token 0 Last 3: [-24.26474 240.65173 113.48902]
[layer21_decoder_block_out] Token 1 First 3: [118.54141 183.44482 199.43738]
[layer21_decoder_block_out] Token 1 Last 3: [ 105.86625 -177.16162 -100.62352]
[layer21_decoder_block_out] Token 2 First 3: [ 143.3732  1105.762    120.42735]
[layer21_decoder_block_out] Token 2 Last 3: [-31.01489   130.86052     3.4843597]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.37002698  0.36845186 -0.06825306]
[RMSNorm(raw)] Token 0 Last 3: [-0.02607022  0.25855806  0.12193347]
[RMSNorm(raw)] Token 1 First 3: [0.17556342 0.27168733 0.29537278]
[RMSNorm(raw)] Token 1 Last 3: [ 0.15679112 -0.26238173 -0.14902648]
[RMSNorm(raw)] Token 2 First 3: [0.10924079 0.84251666 0.09175759]
[RMSNorm(raw)] Token 2 Last 3: [-0.02363127  0.09970696  0.00265485]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [31.719904   3.0504928 15.652161 ]
[RMSNorm(weight)] Last 3: [22.705408 10.556819  5.938177]
--------------------
[layer22_attention_norm] Shape: (1, 3, 768)
[layer22_attention_norm] Token 0 First 3: [12.107246   1.4924116 -1.1365608]
[layer22_attention_norm] Token 0 Last 3: [-0.6180052  2.9881086  0.845996 ]
[layer22_attention_norm] Token 1 First 3: [5.744418  1.1004676 4.918595 ]
[layer22_attention_norm] Token 1 Last 3: [ 3.7167976 -3.032298  -1.0339721]
[layer22_attention_norm] Token 2 First 3: [3.5743477 3.4126077 1.5279621]
[layer22_attention_norm] Token 2 Last 3: [-0.56018895  1.1522954   0.01841981]
--------------------
[layer22_attention_norm] Shape: (1, 3, 768)
[layer22_attention_norm] Token 0 First 3: [12.107246   1.4924116 -1.1365608]
[layer22_attention_norm] Token 0 Last 3: [-0.6180052  2.9881086  0.845996 ]
[layer22_attention_norm] Token 1 First 3: [5.744418  1.1004676 4.918595 ]
[layer22_attention_norm] Token 1 Last 3: [ 3.7167976 -3.032298  -1.0339721]
[layer22_attention_norm] Token 2 First 3: [3.5743477 3.4126077 1.5279621]
[layer22_attention_norm] Token 2 Last 3: [-0.56018895  1.1522954   0.01841981]
--------------------
[layer22_wq_weight] Shape: (768, 768)
[layer22_wq_weight] First 3: [0.00172648 0.00083911 0.00413995]
[layer22_wq_weight] Last 3: [-0.00361077 -0.00197031  0.00095706]
--------------------
[layer22_wk_weight] Shape: (768, 256)
[layer22_wk_weight] First 3: [-0.00720579 -0.00067203  0.01526351]
[layer22_wk_weight] Last 3: [-0.00669905  0.00603476 -0.00897573]
--------------------
[layer22_wv_weight] Shape: (768, 256)
[layer22_wv_weight] First 3: [-0.00235797  0.00438762  0.00693382]
[layer22_wv_weight] Last 3: [ 0.00281052 -0.00337181  0.00183252]
--------------------
[layer22_wq] Shape: (1, 3, 768)
[layer22_wq] Token 0 First 3: [-0.6073047   0.706056    0.65902627]
[layer22_wq] Token 0 Last 3: [ 0.5966324  -0.49757725 -0.3435359 ]
[layer22_wq] Token 1 First 3: [-2.5535219 -0.4624589  2.424131 ]
[layer22_wq] Token 1 Last 3: [ 0.839143  -0.8029703 -1.881896 ]
[layer22_wq] Token 2 First 3: [-0.52088064  0.2638773   0.74059165]
[layer22_wq] Token 2 Last 3: [ 1.8164485  -0.02994482 -1.3605062 ]
--------------------
[layer22_wk] Shape: (1, 3, 256)
[layer22_wk] Token 0 First 3: [ 0.8725943  -0.7461369   0.74020886]
[layer22_wk] Token 0 Last 3: [ 3.029725  -5.89765   -1.2431774]
[layer22_wk] Token 1 First 3: [-1.4267106 -1.4533592  1.5571153]
[layer22_wk] Token 1 Last 3: [ 3.250073  -7.319911  -0.9678854]
[layer22_wk] Token 2 First 3: [-0.04223257 -1.6853877   0.5303884 ]
[layer22_wk] Token 2 Last 3: [ 0.64702135 -6.6724434  -0.8714667 ]
--------------------
[layer22_wv] Shape: (1, 3, 256)
[layer22_wv] Token 0 First 3: [1.1972616  0.9377328  0.44710177]
[layer22_wv] Token 0 Last 3: [-0.22311634 -0.4235346  -1.6012008 ]
[layer22_wv] Token 1 First 3: [ 0.79140675 -0.09388843  1.6481133 ]
[layer22_wv] Token 1 Last 3: [ 2.2812943 -1.6614032 -1.0473475]
[layer22_wv] Token 2 First 3: [ 0.78393096  1.0494668  -0.53724444]
[layer22_wv] Token 2 Last 3: [-0.3763768 -1.1173311 -0.6170007]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.19737063  0.22946426  0.21417986]
[RMSNorm(raw)] Last 3: [ 0.73564935 -0.01212745 -0.5509958 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.5809111  0.7846838  0.5567894]
[RMSNorm(weight)] Last 3: [ 0.17034213  0.5076706  -0.14071524]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [ 0.36630654 -0.31322098  0.31073242]
[RMSNorm(raw)] Last 3: [ 0.24726081 -2.5498908  -0.33303314]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [0.25873196 0.12361653 0.36913398]
[RMSNorm(weight)] Last 3: [0.3576802  0.12496684 1.215703  ]
--------------------
[layer22_q_norm_out] Shape: (1, 3, 768)
[layer22_q_norm_out] Token 0 First 3: [-0.08271584  0.40952116  0.33343294]
[layer22_q_norm_out] Token 0 Last 3: [ 0.22396594 -0.24061865 -0.0946829 ]
[layer22_q_norm_out] Token 1 First 3: [-0.63203305 -0.4874482   2.2288456 ]
[layer22_q_norm_out] Token 1 Last 3: [ 0.47871625 -0.59011316 -0.7882466 ]
[layer22_q_norm_out] Token 2 First 3: [-0.05529736  0.11929531  0.29205772]
[layer22_q_norm_out] Token 2 Last 3: [ 0.8609614 -0.0182842 -0.4734623]
--------------------
[layer22_k_norm_out] Shape: (1, 3, 256)
[layer22_k_norm_out] Token 0 First 3: [ 0.46108174 -0.35194027  0.42543432]
[layer22_k_norm_out] Token 0 Last 3: [ 1.7267641 -2.7851655 -1.1563171]
[layer22_k_norm_out] Token 1 First 3: [-0.7749346  -0.704672    0.91994655]
[layer22_k_norm_out] Token 1 Last 3: [ 1.9040856  -3.553378   -0.92540395]
[layer22_k_norm_out] Token 2 First 3: [-0.02031503 -0.72369343  0.27750874]
[layer22_k_norm_out] Token 2 Last 3: [ 0.3357011 -2.8685427 -0.7379025]
--------------------
[layer22_attention_out_core] Shape: (1, 3, 768)
[layer22_attention_out_core] Token 0 First 3: [0.9337074  0.42929977 0.920339  ]
[layer22_attention_out_core] Token 0 Last 3: [ 0.49813432 -1.0808271  -1.04375   ]
[layer22_attention_out_core] Token 1 First 3: [0.8074456  0.04101789 1.4218695 ]
[layer22_attention_out_core] Token 1 Last 3: [ 0.919284  -1.2168673 -1.0460303]
[layer22_attention_out_core] Token 2 First 3: [0.9584514 0.6388922 0.5685181]
[layer22_attention_out_core] Token 2 Last 3: [ 0.960289  -1.2665433 -0.9980556]
--------------------
[layer22_wo_weight] Shape: (768, 768)
[layer22_wo_weight] First 3: [ 0.00224497  0.00370765 -0.00653369]
[layer22_wo_weight] Last 3: [ 0.0047088  -0.01291969 -0.00917186]
--------------------
[layer22_attention_out_proj] Shape: (1, 3, 768)
[layer22_attention_out_proj] Token 0 First 3: [-0.05483348  0.08328874  0.04387619]
[layer22_attention_out_proj] Token 0 Last 3: [-0.12629674 -0.09425972  0.0415816 ]
[layer22_attention_out_proj] Token 1 First 3: [-0.10914481 -0.01502589  0.08745566]
[layer22_attention_out_proj] Token 1 Last 3: [-0.06741453 -0.12555896  0.02557273]
[layer22_attention_out_proj] Token 2 First 3: [-0.06741662  0.05990073  0.05495846]
[layer22_attention_out_proj] Token 2 Last 3: [-0.15699193 -0.02119951  0.07512805]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.11330572  0.17210455  0.09066401]
[RMSNorm(raw)] Token 0 Last 3: [-0.26097456 -0.19477454  0.08592256]
[RMSNorm(raw)] Token 1 First 3: [-0.27405348 -0.03772875  0.21959385]
[RMSNorm(raw)] Token 1 Last 3: [-0.16927226 -0.31526804  0.064211  ]
[RMSNorm(raw)] Token 2 First 3: [-0.14874601  0.1321632   0.12125871]
[RMSNorm(raw)] Token 2 Last 3: [-0.3463823  -0.04677396  0.16576028]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 67.24138 402.5561  174.5312 ]
[RMSNorm(weight)] Last 3: [ 84.20621 146.95882 297.19168]
--------------------
[layer22_ffn_norm] Shape: (1, 3, 768)
[layer22_ffn_norm] Token 0 First 3: [-7.7321386 69.45384   15.914364 ]
[layer22_ffn_norm] Token 0 Last 3: [-22.236652 -28.81861   25.621393]
[layer22_ffn_norm] Token 1 First 3: [-18.701788 -15.225667  38.545574]
[layer22_ffn_norm] Token 1 Last 3: [-14.423047 -46.646687  19.147184]
[layer22_ffn_norm] Token 2 First 3: [-10.150633  53.335262  21.284687]
[layer22_ffn_norm] Token 2 Last 3: [-29.513922  -6.92062   49.428337]
--------------------
[layer22_post_attention_norm] Shape: (1, 3, 768)
[layer22_post_attention_norm] Token 0 First 3: [-7.7321386 69.45384   15.914364 ]
[layer22_post_attention_norm] Token 0 Last 3: [-22.236652 -28.81861   25.621393]
[layer22_post_attention_norm] Token 1 First 3: [-18.701788 -15.225667  38.545574]
[layer22_post_attention_norm] Token 1 Last 3: [-14.423047 -46.646687  19.147184]
[layer22_post_attention_norm] Token 2 First 3: [-10.150633  53.335262  21.284687]
[layer22_post_attention_norm] Token 2 Last 3: [-29.513922  -6.92062   49.428337]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.34942663  0.42801592 -0.04941608]
[RMSNorm(raw)] Token 0 Last 3: [-0.04826353  0.21986039  0.1443819 ]
[RMSNorm(raw)] Token 1 First 3: [0.14113423 0.2377962  0.33641496]
[RMSNorm(raw)] Token 1 Last 3: [ 0.12926498 -0.31637755 -0.11517572]
[RMSNorm(raw)] Token 2 First 3: [0.09906352 0.86189795 0.10537625]
[RMSNorm(raw)] Token 2 Last 3: [-0.04500887  0.09216098  0.03934557]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 2.0594869  -0.58007634  0.1913726 ]
[RMSNorm(weight)] Last 3: [ 1.2495947   0.06436089 -0.39721328]
--------------------
[layer22pre_ffn_norm] Shape: (1, 3, 768)
[layer22pre_ffn_norm] First 5 values: [1.0690661668777466, 0.179734006524086, -0.05887296050786972, 0.37157177925109863, -0.0007706122123636305]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [0.13125769793987274, -0.027203457430005074, 0.05006292834877968, 0.05569440871477127, 0.05121511593461037]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.05025605112314224, 0.02421536296606064, -0.01701807975769043, -0.018434155732393265, -0.05170641094446182]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-0.00041085336124524474, 0.00032569520408287644, -0.0011080175172537565, 0.0012176502496004105, -0.0006157987518236041]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.16354798  0.12964915 -0.4410674 ]
[RMSNorm(raw)] Token 0 Last 3: [0.03635325 0.11335586 0.21074341]
[RMSNorm(raw)] Token 1 First 3: [-0.07098183  0.7038636  -1.2712792 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.09934144 -0.83021677  0.8681334 ]
[RMSNorm(raw)] Token 2 First 3: [-0.2212501  0.1531656 -0.5925378]
[RMSNorm(raw)] Token 2 Last 3: [-0.28549424 -0.36430517 -0.09871782]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [114.88185 645.06726 172.8834 ]
[RMSNorm(weight)] Last 3: [156.38005 211.73824 422.3818 ]
--------------------
[layer22_post_ffn_norm] Shape: (1, 3, 768)
[layer22_post_ffn_norm] Token 0 First 3: [-18.952242  83.76207  -76.694305]
[layer22_post_ffn_norm] Token 0 Last 3: [ 5.7212763 24.115126  89.22493  ]
[layer22_post_ffn_norm] Token 1 First 3: [  -8.225506  454.74326  -221.05437 ]
[layer22_post_ffn_norm] Token 1 Last 3: [ -15.63436 -176.61885  367.5519 ]
[layer22_post_ffn_norm] Token 2 First 3: [ -25.638872   98.95528  -103.03249 ]
[layer22_post_ffn_norm] Token 2 Last 3: [-44.9311   -77.50164  -41.795326]
--------------------
[layer22_decoder_block_out] Shape: (1, 3, 768)
[layer22_decoder_block_out] Token 0 First 3: [ 317.71655  496.15082 -124.30617]
[layer22_decoder_block_out] Token 0 Last 3: [-40.780117 235.94826  228.33534 ]
[layer22_decoder_block_out] Token 1 First 3: [ 91.61412  622.9624    16.928589]
[layer22_decoder_block_out] Token 1 Last 3: [  75.80884 -400.42715  286.07556]
[layer22_decoder_block_out] Token 2 First 3: [ 107.583694 1258.0525     38.679543]
[layer22_decoder_block_out] Token 2 Last 3: [-105.459915   46.438255   11.117371]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.24006231  0.3748848  -0.09392405]
[RMSNorm(raw)] Token 0 Last 3: [-0.0308129   0.1782793   0.17252709]
[RMSNorm(raw)] Token 1 First 3: [0.05789404 0.39367086 0.01069774]
[RMSNorm(raw)] Token 1 Last 3: [ 0.04790615 -0.25304335  0.18078075]
[RMSNorm(raw)] Token 2 First 3: [0.07211528 0.8432951  0.02592759]
[RMSNorm(raw)] Token 2 Last 3: [-0.07069167  0.03112839  0.00745217]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [12.184938   1.4571741  4.6383247]
[RMSNorm(weight)] Last 3: [8.493929  3.8986597 1.58603  ]
--------------------
[layer23_attention_norm] Shape: (1, 3, 768)
[layer23_attention_norm] Token 0 First 3: [ 3.165207    0.92115724 -0.52957433]
[layer23_attention_norm] Token 0 Last 3: [-0.2925355   0.8733296   0.44616023]
[layer23_attention_norm] Token 1 First 3: [0.7633293  0.9673178  0.06031735]
[layer23_attention_norm] Token 1 Last 3: [ 0.45481756 -1.2395732   0.46750444]
[layer23_attention_norm] Token 2 First 3: [0.9508355  2.0721228  0.14618817]
[layer23_attention_norm] Token 2 Last 3: [-0.6711417   0.15248741  0.01927154]
--------------------
[layer23_attention_norm] Shape: (1, 3, 768)
[layer23_attention_norm] Token 0 First 3: [ 3.165207    0.92115724 -0.52957433]
[layer23_attention_norm] Token 0 Last 3: [-0.2925355   0.8733296   0.44616023]
[layer23_attention_norm] Token 1 First 3: [0.7633293  0.9673178  0.06031735]
[layer23_attention_norm] Token 1 Last 3: [ 0.45481756 -1.2395732   0.46750444]
[layer23_attention_norm] Token 2 First 3: [0.9508355  2.0721228  0.14618817]
[layer23_attention_norm] Token 2 Last 3: [-0.6711417   0.15248741  0.01927154]
--------------------
[layer23_wq_weight] Shape: (768, 768)
[layer23_wq_weight] First 3: [ 0.00573669 -0.0052358   0.00516688]
[layer23_wq_weight] Last 3: [-0.00414325  0.00199415  0.00988872]
--------------------
[layer23_wk_weight] Shape: (768, 256)
[layer23_wk_weight] First 3: [-0.00714521  0.00807089 -0.00306184]
[layer23_wk_weight] Last 3: [-0.00273118 -0.0081204   0.00422632]
--------------------
[layer23_wv_weight] Shape: (768, 256)
[layer23_wv_weight] First 3: [-0.00055002 -0.0045282   0.0026544 ]
[layer23_wv_weight] Last 3: [-0.00013422 -0.01283893 -0.01317409]
--------------------
[layer23_wq] Shape: (1, 3, 768)
[layer23_wq] Token 0 First 3: [-0.67259616  4.3629684   1.1247003 ]
[layer23_wq] Token 0 Last 3: [-0.41803634  0.51997584 -0.25294358]
[layer23_wq] Token 1 First 3: [-0.07690689  2.6725175   1.1649565 ]
[layer23_wq] Token 1 Last 3: [-0.07684962  0.18152298  0.01097297]
[layer23_wq] Token 2 First 3: [-0.35869062  4.9257383   1.4425058 ]
[layer23_wq] Token 2 Last 3: [-0.25487024  1.4150785   0.78703946]
--------------------
[layer23_wk] Shape: (1, 3, 256)
[layer23_wk] Token 0 First 3: [-0.21602538 -0.06523576 -0.8155677 ]
[layer23_wk] Token 0 Last 3: [ 0.6389595   0.16067892 -0.47732618]
[layer23_wk] Token 1 First 3: [-0.3124535  -0.15598837 -0.527833  ]
[layer23_wk] Token 1 Last 3: [ 0.15546614  0.2013245  -0.47356337]
[layer23_wk] Token 2 First 3: [-1.1778358  -2.911584   -0.41167134]
[layer23_wk] Token 2 Last 3: [ 0.28261977  2.9059114  -0.42245275]
--------------------
[layer23_wv] Shape: (1, 3, 256)
[layer23_wv] Token 0 First 3: [0.11447704 0.14308333 0.7981745 ]
[layer23_wv] Token 0 Last 3: [ 0.00040384 -0.05459497  0.06259972]
[layer23_wv] Token 1 First 3: [0.08576626 0.12094739 0.1966562 ]
[layer23_wv] Token 1 Last 3: [-0.04621224 -0.18321198 -0.22783053]
[layer23_wv] Token 2 First 3: [-0.08566375 -0.13293207  1.3452986 ]
[layer23_wv] Token 2 Last 3: [0.852457   0.5599202  0.61645746]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 3, 256)
[RMSNorm(raw)] First 3: [-0.5305952   3.4418426   0.88724947]
[RMSNorm(raw)] Last 3: [-0.11361983  0.63083464  0.3508581 ]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.5068145 -1.0007226 -2.1336057]
[RMSNorm(weight)] Last 3: [-0.6250616  -0.37868643 -0.1368243 ]
--------------------
[RMSNorm(raw)] Shape: (1, 1, 3, 256)
[RMSNorm(raw)] First 3: [-0.35375074 -0.10682634 -1.3355267 ]
[RMSNorm(raw)] Last 3: [ 0.1886152   1.9393514  -0.28193712]
--------------------
[RMSNorm(weight)] Shape: (256,)
[RMSNorm(weight)] First 3: [-0.9934937  -0.98677754 -2.333774  ]
[RMSNorm(weight)] Last 3: [6.996092  2.610167  2.5946417]
--------------------
[layer23_q_norm_out] Shape: (1, 3, 768)
[layer23_q_norm_out] Token 0 First 3: [-0.26168185 -0.00248724 -1.0057911 ]
[layer23_q_norm_out] Token 0 Last 3: [-0.08596683  0.1771948  -0.11975119]
[layer23_q_norm_out] Token 1 First 3: [-0.05359515 -0.00272896 -1.866043  ]
[layer23_q_norm_out] Token 1 Last 3: [-0.03247109  0.1270977   0.01067378]
[layer23_q_norm_out] Token 2 First 3: [-0.10983782 -0.00221014 -1.0153158 ]
[layer23_q_norm_out] Token 2 Last 3: [-0.04260044  0.39194614  0.30285218]
--------------------
[layer23_k_norm_out] Shape: (1, 3, 256)
[layer23_k_norm_out] Token 0 First 3: [-2.3016168e-03 -1.4125066e-03  1.7812909e+00]
[layer23_k_norm_out] Token 0 Last 3: [ 8.366498    0.94990194 -2.8097227 ]
[layer23_k_norm_out] Token 1 First 3: [-0.00549448 -0.00557455  1.9027605 ]
[layer23_k_norm_out] Token 1 Last 3: [ 3.3598425  1.9643968 -4.60086  ]
[layer23_k_norm_out] Token 2 First 3: [-0.0051144  -0.02569305  0.36644354]
[layer23_k_norm_out] Token 2 Last 3: [ 1.5081844  7.001383  -1.0134629]
--------------------
[layer23_attention_out_core] Shape: (1, 3, 768)
[layer23_attention_out_core] Token 0 First 3: [-0.05892895 -0.09372918  1.1813571 ]
[layer23_attention_out_core] Token 0 Last 3: [0.5537992  0.31935838 0.3534134 ]
[layer23_attention_out_core] Token 1 First 3: [-0.03658403 -0.06079906  1.037933  ]
[layer23_attention_out_core] Token 1 Last 3: [0.40778267 0.19562186 0.20804037]
[layer23_attention_out_core] Token 2 First 3: [-0.05307314 -0.08591776  1.1756458 ]
[layer23_attention_out_core] Token 2 Last 3: [0.41810808 0.21060593 0.23539127]
--------------------
[layer23_wo_weight] Shape: (768, 768)
[layer23_wo_weight] First 3: [0.01093065 0.00519522 0.01659983]
[layer23_wo_weight] Last 3: [ 0.00792366 -0.00677993  0.00140562]
--------------------
[layer23_attention_out_proj] Shape: (1, 3, 768)
[layer23_attention_out_proj] Token 0 First 3: [-0.2506644  -0.04268064  0.13090184]
[layer23_attention_out_proj] Token 0 Last 3: [ 0.04341189 -0.01749859 -0.08397442]
[layer23_attention_out_proj] Token 1 First 3: [-0.1902889   0.00613045  0.10549422]
[layer23_attention_out_proj] Token 1 Last 3: [ 0.04066228 -0.02403223 -0.07721458]
[layer23_attention_out_proj] Token 2 First 3: [-0.21637116 -0.01802503  0.12441798]
[layer23_attention_out_proj] Token 2 Last 3: [ 0.0394342  -0.01977264 -0.07919166]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.5866169  -0.09988327  0.30634275]
[RMSNorm(raw)] Token 0 Last 3: [ 0.10159458 -0.04095105 -0.19652095]
[RMSNorm(raw)] Token 1 First 3: [-0.5457941   0.01758359  0.30258268]
[RMSNorm(raw)] Token 1 Last 3: [ 0.11662915 -0.06893018 -0.22146991]
[RMSNorm(raw)] Token 2 First 3: [-0.56839967 -0.04735113  0.32684177]
[RMSNorm(raw)] Token 2 Last 3: [ 0.10359229 -0.05194204 -0.20803379]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 79.86325  484.6373   111.579956]
[RMSNorm(weight)] Last 3: [ 97.70981 170.68561 309.0498 ]
--------------------
[layer23_ffn_norm] Shape: (1, 3, 768)
[layer23_ffn_norm] Token 0 First 3: [-47.43575  -48.50704   34.488052]
[layer23_ffn_norm] Token 0 Last 3: [ 10.028381   -7.0307055 -60.931282 ]
[layer23_ffn_norm] Token 1 First 3: [-44.13469    8.539246  34.064747]
[layer23_ffn_norm] Token 1 Last 3: [ 11.512442 -11.83432  -68.6667  ]
[layer23_ffn_norm] Token 2 First 3: [-45.962646 -22.995474  36.795834]
[layer23_ffn_norm] Token 2 Last 3: [ 10.225575  -8.9177   -64.50083 ]
--------------------
[layer23_post_attention_norm] Shape: (1, 3, 768)
[layer23_post_attention_norm] Token 0 First 3: [-47.43575  -48.50704   34.488052]
[layer23_post_attention_norm] Token 0 Last 3: [ 10.028381   -7.0307055 -60.931282 ]
[layer23_post_attention_norm] Token 1 First 3: [-44.13469    8.539246  34.064747]
[layer23_post_attention_norm] Token 1 Last 3: [ 11.512442 -11.83432  -68.6667  ]
[layer23_post_attention_norm] Token 2 First 3: [-45.962646 -22.995474  36.795834]
[layer23_post_attention_norm] Token 2 Last 3: [ 10.225575  -8.9177   -64.50083 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.1635874  0.2709363 -0.0543624]
[RMSNorm(raw)] Token 0 Last 3: [-0.01861248  0.13855231  0.10132127]
[RMSNorm(raw)] Token 1 First 3: [0.02461764 0.3274277  0.02643957]
[RMSNorm(raw)] Token 1 Last 3: [ 0.04527526 -0.2137537   0.11272445]
[RMSNorm(raw)] Token 2 First 3: [0.03366365 0.674713   0.04123228]
[RMSNorm(raw)] Token 2 Last 3: [-0.05202663  0.02049752 -0.02916344]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [ 6.9451942  -0.08098087  1.8713799 ]
[RMSNorm(weight)] Last 3: [7.6116157  1.4745073  0.38909027]
--------------------
[layer23pre_ffn_norm] Shape: (1, 3, 768)
[layer23pre_ffn_norm] First 5 values: [1.2997337579727173, 0.24899564683437347, -0.15609508752822876, 0.5299121737480164, -0.07163286954164505]
--------------------
[layer22_ffn_gate] Shape: (1, 3, 1152)
[layer22_ffn_gate] First 5 values: [-0.055039070546627045, -0.08699269592761993, -0.29643023014068604, -0.25320374965667725, 0.03003840520977974]
--------------------
[layer22_ffn_up] Shape: (1, 3, 1152)
[layer22_ffn_up] First 5 values: [-0.1211680918931961, -0.0533798448741436, -0.12133514881134033, -0.03925950825214386, -0.18314425647258759]
--------------------
[layer22_ffn_down] Shape: (1, 3, 768)
[layer22_ffn_down] First 5 values: [-8.999527199193835e-05, 0.0005256438162177801, -0.002841367619112134, -0.0010240223491564393, -0.002573207952082157]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [-0.01533972  0.08959614 -0.48431194]
[RMSNorm(raw)] Token 0 Last 3: [ 0.02761362 -0.70026577  0.83208114]
[RMSNorm(raw)] Token 1 First 3: [ 0.85207283  0.09769183 -1.2195091 ]
[RMSNorm(raw)] Token 1 Last 3: [-0.16545026 -2.3038228  -0.61764467]
[RMSNorm(raw)] Token 2 First 3: [ 0.17060852 -0.15069191 -0.08918975]
[RMSNorm(raw)] Token 2 Last 3: [ 0.24985196 -0.844056   -0.3847466 ]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [128.57861 473.8191  189.22139]
[RMSNorm(weight)] Last 3: [220.94635 192.51855 367.8862 ]
--------------------
[layer23_post_ffn_norm] Shape: (1, 3, 768)
[layer23_post_ffn_norm] Token 0 First 3: [ -1.9876996  42.541958  -92.12649  ]
[layer23_post_ffn_norm] Token 0 Last 3: [   6.1287417 -135.51442    306.94324  ]
[layer23_post_ffn_norm] Token 1 First 3: [ 110.410416   46.38595  -231.97672 ]
[layer23_post_ffn_norm] Token 1 Last 3: [ -36.72108 -445.83246 -227.84059]
[layer23_post_ffn_norm] Token 2 First 3: [ 22.107216 -71.5514   -16.965797]
[layer23_post_ffn_norm] Token 2 Last 3: [  55.45373 -163.3405  -141.92772]
--------------------
[layer23_decoder_block_out] Shape: (1, 3, 768)
[layer23_decoder_block_out] Token 0 First 3: [ 268.2931   490.18573 -181.94461]
[layer23_decoder_block_out] Token 0 Last 3: [-24.622993  93.40314  474.3473  ]
[layer23_decoder_block_out] Token 1 First 3: [ 157.88985  677.8876  -180.98338]
[layer23_decoder_block_out] Token 1 Last 3: [  50.6002   -858.09393   -10.431732]
[layer23_decoder_block_out] Token 2 First 3: [  83.728264 1163.5056     58.509575]
[layer23_decoder_block_out] Token 2 Last 3: [ -39.780605 -125.81995  -195.31119 ]
--------------------
[RMSNorm(raw)] Shape: (1, 3, 768)
[RMSNorm(raw)] Token 0 First 3: [ 0.15851781  0.28962046 -0.10749982]
[RMSNorm(raw)] Token 0 Last 3: [-0.0145482   0.05518614  0.2802625 ]
[RMSNorm(raw)] Token 1 First 3: [ 0.07188629  0.30863813 -0.08240064]
[RMSNorm(raw)] Token 1 Last 3: [ 0.02303796 -0.39068496 -0.0047495 ]
[RMSNorm(raw)] Token 2 First 3: [0.06234043 0.8662957  0.04356369]
[RMSNorm(raw)] Token 2 Last 3: [-0.02961891 -0.09368006 -0.14542022]
--------------------
[RMSNorm(weight)] Shape: (768,)
[RMSNorm(weight)] First 3: [33.01882   5.235485 13.479099]
[RMSNorm(weight)] Last 3: [43.47654   12.983885   5.8494883]
--------------------
[final_hidden_state] Shape: (1, 3, 768)
[final_hidden_state] First 5 values: [5.392589092254639, 1.8059240579605103, -1.5565005540847778, 2.511673927307129, -0.995944082736969]
--------------------
[[-1.83494970e-01 -4.96903760e-03  2.39115115e-02  1.90777201e-02
  -1.93582696e-03  2.29551061e-03 -1.44582754e-02  3.16047408e-02
   4.66694571e-02 -6.15337193e-02  1.60569616e-03 -6.01631328e-02
   8.58363882e-03 -3.27573493e-02  1.13080002e-01 -6.81588147e-03
   7.09389001e-02 -3.60211208e-02 -4.55887765e-02  8.66436679e-03
  -6.09680312e-03 -4.97012399e-03  1.63873117e-02 -1.06971990e-02
   9.28612053e-03  4.64199558e-02  3.35760675e-02  7.78251281e-03
  -4.53726910e-02 -4.28761877e-02  2.45373435e-02 -1.12845842e-02
   4.31205854e-02 -6.16904348e-03  7.84639828e-03  3.33573446e-02
   3.08745354e-03 -6.18394017e-02  6.42771497e-02 -2.27326080e-02
  -8.77355635e-02  6.03403710e-02 -1.89080797e-02  1.68430939e-04
   3.49192657e-02 -1.51296873e-02 -6.04290748e-03 -2.47156676e-02
   7.41978548e-03  4.30275798e-02  1.70557443e-02 -1.48411447e-04
  -6.33583963e-02  3.17869037e-02 -1.48674622e-02 -3.63792144e-02
  -2.17908658e-02 -9.16527864e-03 -5.39299175e-02  5.89228496e-02
  -3.69921923e-02  3.31476480e-02 -2.16231169e-03 -1.15768248e-02
   3.71706039e-02 -1.73696794e-03 -1.14303185e-02  3.75626679e-03
   1.06785465e-02  2.76120633e-01 -6.51978049e-03 -6.37181029e-02
   1.97329484e-02 -2.78389584e-02  2.31391057e-01  2.14603953e-02
  -2.74950285e-02 -3.17700244e-02  1.02393394e-02  3.91180767e-03
   1.53513011e-02  6.33925572e-03  2.61131618e-02 -1.54920667e-02
   8.36828351e-02 -3.47729685e-04 -1.35815516e-02  9.67972632e-03
  -2.18377262e-03 -3.20825316e-02  2.89892349e-02 -9.27629974e-03
  -1.29699998e-03 -5.90989776e-02  3.65850441e-02 -5.57723753e-02
  -4.15573306e-02  6.55247346e-02 -3.91457304e-02 -5.38855866e-02
   2.36145854e-02 -7.65713025e-03  4.03711013e-02  7.94330984e-02
  -1.16338059e-02 -4.31365520e-03 -2.85385139e-02  1.69993451e-04
  -2.46687490e-03  1.35509716e-02 -2.43985523e-02  3.06577538e-03
   1.75251551e-02 -9.69802123e-03  2.30523050e-02  3.76515873e-02
  -7.59897474e-03 -2.34199651e-02  3.27776149e-02  3.66283171e-02
   2.42306609e-02  2.42710710e-02 -2.83042789e-02  1.02359569e-02
   2.62694098e-02  3.64450030e-02  2.76689753e-02  4.74922583e-02
  -1.84503384e-02 -7.93922395e-02 -6.44592918e-04  3.73021811e-02
  -3.60514736e-03  3.84557247e-02 -1.75166223e-02  1.05011398e-02
   7.52687221e-03 -1.61466766e-02  1.11868925e-01  4.53499518e-02
   1.93524491e-02 -7.76909366e-02  1.43765062e-02 -3.10851242e-02
   2.43223216e-02  1.72889661e-02 -3.26949134e-02  1.84150785e-02
   3.68934348e-02 -1.91352461e-02  2.13233549e-02  6.32293057e-03
   2.54554655e-02 -7.00754859e-03 -3.76702257e-04 -5.04650436e-02
  -1.92936026e-02  8.11755564e-03 -5.30139878e-02 -1.71224456e-02
  -4.26838212e-02 -1.15245646e-02  3.62831983e-03  6.61484972e-02
  -8.31323327e-04  1.04902178e-01  3.35312374e-02  5.03791273e-02
  -9.13886912e-03 -3.10497936e-02 -1.79305281e-02 -8.52871835e-02
  -3.29330424e-03 -2.09747860e-03 -4.00591735e-03 -1.55473165e-02
  -6.38169516e-03 -6.73686201e-03  7.95700774e-02  1.50936283e-02
   6.75414130e-03  2.46769506e-02 -1.81108341e-02 -3.48795876e-02
  -2.30003372e-02  4.95423451e-02  4.92389910e-02  3.86536797e-03
  -2.04995107e-02  2.74899509e-03 -1.14359269e-02  3.04515846e-03
  -4.18825261e-03  4.11890028e-03  3.64246555e-02  3.49860787e-02
   8.87361392e-02  1.10648135e-02  3.59993684e-03  2.19792686e-02
   4.63389270e-02 -4.23849374e-02 -3.54283117e-03  6.09641895e-03
  -8.37339535e-02 -2.47658938e-02 -2.61302330e-02  2.02034134e-02
   1.72552485e-02 -3.07665616e-02  3.86432670e-02  2.89301071e-02
  -3.76878716e-02  1.15036592e-02  3.31042260e-02  4.38387394e-02
  -3.53772901e-02  8.02961458e-03  1.12878624e-03 -1.99360047e-02
  -2.10494827e-02  1.01177748e-02  7.07565388e-03  8.46903864e-03
  -9.17475577e-03  5.34166992e-02 -1.16449771e-02  2.20149476e-02
   1.72261316e-02 -2.25558337e-02  1.77413076e-02  2.23063957e-02
   2.33208947e-03  1.71788107e-03 -3.90937924e-02 -4.31910008e-02
  -8.40076245e-04 -2.32798140e-03  4.24381383e-02  2.85045244e-02
  -3.12312152e-02 -4.24132729e-03  1.53536042e-02  2.33364739e-02
  -1.07061490e-02 -1.42829260e-02  3.40862162e-02 -5.67770265e-02
   2.54376815e-03 -5.54824667e-03 -5.38673950e-03 -8.52323323e-03
  -2.21972750e-03 -1.38963554e-02 -4.73594898e-03  1.05060749e-02
   1.47792967e-02 -1.99205708e-02  3.02001480e-02 -1.77786499e-03
   9.18188784e-03 -8.23697820e-03 -1.23044476e-03 -2.91300509e-02
  -1.77936703e-02  6.29471689e-02  1.48452129e-02  4.96809967e-02
  -1.12825409e-01 -6.96642417e-03  4.00454476e-02 -2.25896388e-02
  -3.29710543e-02  1.07232407e-02 -1.62553098e-02  1.32592954e-02
  -1.04876552e-02  1.10097276e-02 -2.48004738e-02 -2.29616482e-02
   2.42405571e-02 -1.06926812e-02  1.06847472e-02  6.16882220e-02
   5.46379164e-02  2.34845076e-02 -3.00177764e-02  9.77988262e-03
   1.84758697e-02 -6.84417132e-03 -1.36940125e-02  3.52429263e-02
   3.42745770e-04  2.69113034e-02 -2.48001013e-02 -5.46759553e-02
  -7.85202906e-02  4.25567590e-02 -6.88300133e-02  2.87088170e-03
  -1.24629609e-01  2.95957252e-02 -1.26833618e-02 -4.75378260e-02
   1.99841708e-02  2.04368010e-02  6.28318414e-02  1.33848879e-02
  -3.59220840e-02  5.18665323e-03 -3.68184894e-02 -1.81364883e-02
   7.60253519e-04  7.86147546e-03 -5.24849910e-03 -2.69723479e-02
  -3.21432180e-03 -4.12183590e-02  5.44745568e-03  2.68392172e-02
   2.24380242e-03 -1.65028032e-02  5.30974902e-02  1.19480556e-02
  -7.72937248e-03  1.71830524e-02  8.75083432e-02  1.80149058e-04
  -1.17208801e-01  5.75510003e-02  1.07799675e-02 -2.02638656e-02
   7.18934685e-02  3.77700627e-02 -4.81395461e-02  2.87432503e-02
  -3.26493420e-02 -1.87017135e-02 -2.72532795e-02  1.70884188e-03
  -2.69968621e-02 -9.53838509e-03  1.51388096e-02  2.89607961e-02
   2.35056970e-03  4.48400006e-02 -1.58545561e-02  4.45432365e-02
  -2.06715800e-02 -4.01939079e-02 -1.70439277e-02 -2.34566107e-02
  -2.54704757e-03 -1.73688889e-03 -7.23019838e-02  9.20229498e-03
  -1.33701907e-02  2.47970875e-02  8.51319581e-02  5.62161580e-02
   3.58906835e-02 -1.14331506e-01  2.83512231e-02 -2.06093471e-02
   1.58290919e-02 -4.25276905e-02 -2.26837620e-02 -4.42109108e-02
   6.45688698e-02 -2.29901820e-02  1.16740679e-02 -3.84203643e-02
   3.76943760e-02  2.01197923e-03 -6.94035292e-02 -1.61217060e-02
   2.77738273e-02  2.15080101e-02  3.59435342e-02 -1.57287493e-02
  -1.05030062e-02 -3.79249677e-02 -2.97937971e-02 -4.79263207e-03
   4.99337055e-02  1.14020770e-02  4.23819460e-02  3.97817791e-02
  -4.98518907e-03  5.89548005e-03 -7.68479109e-02  5.52582443e-02
  -2.05393904e-03  1.28706535e-02  5.61970286e-03  5.45559858e-04
  -1.85925607e-02  4.59001260e-03 -5.06099090e-02 -3.43292207e-02
  -3.04955523e-02 -1.39099443e-02 -2.78664138e-02 -1.64409131e-02
   4.20405008e-02 -3.15697379e-02  2.55049411e-02 -1.10194162e-02
   1.75980311e-02  3.65927145e-02  2.20600003e-03 -5.16132414e-02
  -4.57120053e-02  2.17410754e-02  3.02754436e-02 -6.97852895e-02
  -2.58213952e-02 -2.64188126e-02 -1.14686228e-01  1.91856790e-02
   1.27356807e-02 -6.80520758e-03  3.13292630e-02  2.48406804e-03
   9.95015819e-03  1.79776829e-02  1.62826814e-02 -1.88730955e-02
   1.51788117e-02 -3.51669006e-02  4.53856997e-02 -3.92015884e-03
  -2.56215055e-02  2.25289147e-02  1.07976152e-02 -3.28299291e-02
  -1.32108014e-02  3.76680517e-03  3.31593230e-02  6.26065135e-02
  -5.81830516e-02 -4.05555889e-02 -2.72869132e-02  4.52717654e-02
  -2.76591275e-02  3.96287106e-02  7.96793215e-03  1.13037797e-02
  -2.25543473e-02  1.64272580e-02  2.49165297e-02  5.15125096e-02
   1.64779052e-02 -1.32404696e-02 -1.87189784e-02 -3.05924453e-02
   1.20981701e-03  2.18054876e-02 -2.41829082e-02 -1.38911353e-02
   9.45202727e-03 -9.40334424e-03 -8.61943420e-03 -4.73958738e-02
  -1.95287610e-03  3.56849702e-03  2.50870958e-02 -5.40383421e-02
  -4.51056473e-02  2.28926763e-02 -3.12975049e-02  1.76837128e-02
  -7.28565222e-03  1.69811994e-02 -2.30580866e-02 -1.80525705e-02
  -8.77147820e-03  7.96278100e-03  5.85302673e-02  2.09688153e-02
  -3.60236093e-02  1.99512634e-02 -1.31589277e-02 -5.34643531e-02
   1.39731234e-02  3.93738225e-03 -2.40567364e-02  4.04061638e-02
   9.17402841e-03  1.43790608e-02 -3.12954560e-02  5.51843038e-03
   3.07532120e-03 -2.00181128e-03 -1.04250631e-03  1.85192060e-02
   2.31502894e-02  7.25694373e-03 -7.48457834e-02  2.37750635e-02
  -9.75288101e-04  3.76997292e-02  5.17109521e-02  3.73957157e-02
  -2.34027277e-04  2.16083154e-02  7.08146673e-03 -3.39844972e-02
  -2.58890539e-02 -1.79616958e-02 -8.05371068e-03 -8.23486689e-03
  -2.13025156e-02  3.72929163e-02  4.93478309e-03  3.71128619e-02
  -8.60161632e-02  5.66495731e-02  2.41591744e-02  1.43266823e-02
  -3.58537324e-02  1.10103255e-02 -1.35136554e-02  2.41159052e-02
  -3.63663808e-02 -5.43866586e-03  7.45292194e-03  1.22503666e-02
   3.91295105e-02 -5.76941557e-02 -1.15639120e-02  2.44106147e-02
  -1.18625313e-02 -4.17215601e-02 -4.60332222e-02 -4.60338406e-02
   1.51515938e-02 -3.75456028e-02  4.68608830e-03  1.62381884e-02
   3.85335088e-02  1.29822111e-02  3.03396694e-02  1.88494697e-02
  -6.07817154e-03 -2.73829047e-02  3.58391888e-02 -6.64640963e-03
  -1.27695175e-02  6.63993508e-02  1.19590433e-02  5.79569116e-03
   1.61079224e-02  7.46768266e-02  4.45601232e-02  2.97183301e-02
  -1.89438108e-02  6.15926180e-03  1.47524904e-02  7.07984716e-03
   6.37079170e-03  1.85484067e-02 -4.93764784e-03 -2.99799368e-02
  -3.53840105e-02 -1.91009585e-02  1.69322304e-02 -4.89516482e-02
   3.41761694e-03  2.41503958e-02  2.58438126e-03  1.68491211e-02
   4.80894521e-02  1.97931845e-03  4.32031881e-03  9.80888754e-02
  -4.95843925e-02 -3.71172689e-02  1.84019580e-02  4.12352057e-03
  -6.24061748e-02 -7.01638358e-03  5.71817607e-02  1.94221511e-02
   8.66907649e-03  3.14209349e-02  4.67965659e-03  3.00117908e-03
   3.85692553e-03  1.61623731e-02 -6.02998808e-02  1.14214616e-02
  -2.49336939e-02  1.86677277e-02  2.95294430e-02  7.34545232e-04
   4.10311716e-03  2.62496397e-02  6.10853359e-02 -8.27219710e-03
  -1.18142189e-02 -3.31729092e-02 -1.62757766e-02 -3.16113457e-02
  -2.20587011e-02 -3.44425216e-02  1.08305328e-02  2.08670683e-02
   2.81738713e-02  1.92577504e-02 -8.10744707e-03  2.93368027e-02
  -2.56820340e-02 -1.21853105e-03 -6.68849656e-03 -2.73205470e-02
   2.81923749e-02 -1.37192393e-02  5.48821762e-02 -2.15410516e-02
   1.13418773e-02  9.94185824e-03 -4.70330380e-03 -6.12469167e-02
   2.42489087e-03 -2.46182196e-02 -1.81657709e-02 -5.98919056e-02
   1.43278111e-02  1.28391813e-02  1.11863501e-02  6.66257590e-02
   6.70445859e-02  2.88342889e-02  3.36853787e-02 -3.51937627e-03
  -7.16356933e-03  2.86297929e-02 -3.84764671e-02  3.41628641e-02
  -2.20649280e-02 -5.00597991e-02 -1.28464466e-02  4.04830724e-02
   4.23542447e-02 -4.60723862e-02  5.61660016e-03 -1.91032663e-02
  -6.60486845e-03 -3.20120179e-03  2.09510466e-03 -2.76207546e-04
  -1.69046328e-03 -2.68287398e-02 -3.32098566e-02  2.60803942e-02
   1.40863461e-02  1.49605377e-02  2.45364029e-02  2.31969263e-02
   3.85321751e-02 -2.58761924e-02  1.33119375e-02  3.64166461e-02
   3.99457663e-02  8.38883966e-03 -2.07908005e-02  1.39778794e-03
  -2.93476954e-02 -1.62525792e-02  3.10994107e-02  1.76365802e-03
   1.25996294e-02 -2.10441295e-02 -1.18308896e-02 -4.84983146e-04
  -4.20919200e-03 -2.54844148e-02  1.14018219e-02  5.86049892e-02
  -3.88671737e-03  7.33383745e-03  8.28576926e-03 -5.12874825e-03
   1.85979879e-03 -3.34732991e-04 -1.82378367e-02 -5.39028943e-02
  -3.43290321e-03  1.46905554e-03 -3.62555981e-02 -1.27120242e-01
   2.17789295e-03  1.53523730e-03  4.06763144e-03  2.56302413e-02
   4.28023301e-02 -5.48547134e-03  3.56276147e-02  4.45386134e-02
  -2.61277128e-02  1.06443586e-02  6.05508275e-02 -3.53677431e-03
   3.22236754e-02 -5.13898656e-02 -2.97756493e-02 -4.74328361e-03
   4.36271653e-02  1.60693079e-02 -4.32834923e-02 -3.00869327e-02
   2.05677673e-02 -2.67144442e-02 -7.39837391e-03  3.70496847e-02
   2.00951044e-02  1.39740855e-02  2.60199867e-02 -1.99377611e-02
  -4.20431569e-02 -1.82589777e-02  3.27555351e-02 -8.98620952e-03
  -7.79737672e-03  9.46527999e-03 -2.85717472e-02 -1.77287962e-02
  -2.28598602e-02 -2.56010834e-02  5.45435175e-02  1.32608982e-02
  -1.61516666e-02 -3.93149368e-02  1.00663602e-02 -1.48945581e-02
   3.42522040e-02 -7.44047994e-03 -1.01728563e-03 -3.17213647e-02
  -9.05592367e-03 -2.09522042e-02  2.52424181e-02 -4.63004187e-02
  -3.78187193e-04 -2.35580839e-02 -2.06076093e-02  4.20670398e-02
  -7.96777196e-04 -1.75883702e-03 -5.53979026e-03 -3.22954822e-03
  -1.05001451e-02  5.40583543e-02 -2.38274038e-02 -3.53760235e-02
  -6.71931282e-02  3.00009525e-03 -3.30021679e-02 -9.21017677e-03
   5.36011579e-03  2.61371378e-02  8.38148315e-03 -1.80365164e-02
   4.75491676e-03 -7.02815130e-02 -3.22867930e-03 -7.86596350e-03]]
